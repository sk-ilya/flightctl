{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FlightCtl Documentation","text":"<p>FlightCtl is a fleet management system for edge devices running ostree-based Linux images.</p> <p> </p>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li> <p> User Guide</p> <p>Installation, device management, and fleet operations</p> <p> Get Started</p> </li> <li> <p> Developer Guide</p> <p>Development setup and system architecture</p> <p> Development Setup</p> </li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Getting Started</li> <li>Managing Devices</li> <li>API Reference</li> <li>Troubleshooting</li> </ul>"},{"location":"#resources","title":"Resources","text":"<ul> <li>GitHub Repository</li> <li>Issues</li> <li>Contributing </li> </ul>"},{"location":"developer/","title":"Flight Control","text":"<p>Flight Control is a service for declarative, GitOps-driven management of edge device fleets running ostree-based Linux system images.</p> <p>[!NOTE] Flight Control is still in early stage development!</p>"},{"location":"developer/#building","title":"Building","text":"<p>Prerequisites: * <code>git</code>, <code>make</code>, and <code>go</code> (&gt;= 1.23), <code>openssl</code>, <code>openssl-devel</code>, <code>bubblewrap</code>, <code>podman-compose</code> and <code>go-rpm-macros</code> (in case one needs to build RPM's)</p> <p>Flightctl agent reports the status of running rootless containers. Ensure the podman socket is enabled:</p> <p><code>systemctl --user enable --now podman.socket</code></p> <p>Checkout the repo and from within the repo run:</p> <pre><code>make build\n</code></pre> <p>To run unit tests, use <code>make unit-test</code>.  This requires installing gotestsum:</p> <p><code>go install gotest.tools/gotestsum@latest</code></p> <p>To generate API code and mocks, use <code>make generate</code>  This requires installing mockgen:</p> <p><code>go install go.uber.org/mock/mockgen@v0.4.0</code></p>"},{"location":"developer/#running","title":"Running","text":"<p>Note: If you are developing with podman on an arm64 system (i.e. M1/M2 Mac) change the postgresql image with: <pre><code>export PGSQL_IMAGE=registry.redhat.io/rhel9/postgresql-16\npodman login registry.redhat.io\n</code></pre></p> <p>The service can be deployed locally in kind with the following command: <pre><code>make deploy\n</code></pre></p> <p>To deploy with auth enabled: <pre><code>AUTH=true make deploy\n</code></pre></p> <p>Note it stores its generated CA cert, server cert, and client-bootstrap cert in <code>$HOME/.flightctl/certs</code> and the client configuration in <code>$HOME/.flightctl/client.yaml</code>.</p> <p>Use the <code>flightctl</code> CLI to login and then apply, get, or delete resources:</p> <pre><code>bin/flightctl login $(cat ~/.flightctl/client.yaml | grep server | awk '{print $2}') --web --certificate-authority ~/.flightctl/certs/ca.crt\nbin/flightctl apply -f examples/fleet.yaml\nbin/flightctl get fleets\n</code></pre> <p>Note: If deployed without auth enabled, then there is no need to login.</p> <p>Use an agent VM to test a device interaction, an image is automatically created from hack/Containerfile.local and a qcow2 image is derived in output/qcow2/disk.qcow2, currently this only works on a Linux host.</p> <p>Note: An update to firewalld may need to be made if the agent is unable to connect to the api instance:</p> <pre><code>sudo firewall-cmd --zone=libvirt --add-rich-rule='rule family=\"ipv4\" source address=\"&lt;virbr0s subnet here&gt;\" accept' --permanent\nsudo firewall-cmd --reload\n</code></pre> <p>You can deploy a DB container of different sizes using a DB_VERSION variable for make command: * e2e (default) - minimal footprint for e2e testing * small-1k - recommended setting for a demo environment 1000 devices max * medium-10k - recommended setting for a demo environment 10k devices max</p> <pre><code># will create the cluster, and the agent config files in bin/agent which will be embedded in the image\n# this one will create a defailt `e2e DB container\nmake deploy\n# to create a small DB container use\n# make deploy DB_VERSION=small\nmake agent-vm agent-vm-console # user/password is user/user\n</code></pre> <p>The agent-vm target accepts multiple parameters: - VMNAME: the name of the VM to create (default: flightctl-device-default) - VMCPUS: the number of CPUs to allocate to the VM (default: 1) - VMMEM: the amount of memory to allocate to the VM (default: 512) - VMWAIT: the amount of minutes to wait on the console during first boot (default: 0)</p> <p>It is possible to create multiple VMs with different names:</p> <pre><code>make agent-vm VMNAME=flightctl-device-1\nmake agent-vm VMNAME=flightctl-device-2\nmake agent-vm VMNAME=flightctl-device-3\n</code></pre> <p>Those should appear on the root virsh list: <pre><code>$ sudo virsh list\n Id   Name                        State\n-------------------------------------------\n 13   flightctl-device-1          running\n 14   flightctl-device-2          running\n 15   flightctl-device-3          running\n````\n\nAnd you can log in the consoles with agent-vm-console:\n</code></pre> make agent-vm-console VMNAME=flightctl-device-1 <pre><code>NOTE: You can exit the console with Ctrl + ] , and `stty rows 80` and `stty columns 140` (for example) are useful to resize your console otherwise very small.\n\n\nIf you created individual devices you need to clean them one by one:\n</code></pre> make clean-agent-vm VMNAME=flightctl-device-1 make clean-agent-vm VMNAME=flightctl-device-2 make clean-agent-vm VMNAME=flightctl-device-3 <pre><code>To quickly create agent instances for testing/development in a containerized environment. This is particularly useful for testing lightweight agent deployments without setting up VMs.\n</code></pre> make agent-container make clean-agent-container <pre><code>Use the **[devicesimulator](devicesimulator.md)** to simulate load from devices\n</code></pre> bin/devicesimulator --count=100 <pre><code>## Metrics\n\nStart the observability stack:\n</code></pre> make deploy-e2e-extras ```</p> <p>The Prometheus web UI is then accessible on <code>http://localhost:9090</code></p>"},{"location":"developer/devicesimulator/","title":"Device Simulator","text":"<p><code>devicesimulator</code> is used to simulate the load generated by devices.</p>"},{"location":"developer/devicesimulator/#setup","title":"Setup","text":"<p>Copy the necessary setup files to run a <code>devicesimulator</code>.</p> <pre><code>mkdir -p ~/.flightctl/certs/ ~/.config/flightctl/\ncp bin/agent/etc/flightctl/certs/* ~/.flightctl/certs/\ncp bin/agent/etc/flightctl/config.yaml ~/.flightctl/agent.yaml\n</code></pre>"},{"location":"developer/devicesimulator/#running","title":"Running","text":"<pre><code>bin/devicesimulator --count=1\n</code></pre> <p>The device simulator will automatically create a fleet configuration named <code>simulator-disk-monitoring</code> if it doesn't already exist. This eliminates the disk usage errors that would occur with default monitoring configurations. The fleet uses the selector <code>created_by: device-simulator</code> to automatically match all devices created by the simulator.</p>"},{"location":"developer/devicesimulator/#remote-simulator","title":"Remote simulator","text":"<p>To simulate a large number of devices (10,000 for example) a <code>devicesimulator</code> has to be installed on a number of separate hosts to let it use more resources. Each remote host must be set up with the same files. Then you have to start simulator on each host.</p>"},{"location":"developer/devicesimulator/#remote-setup","title":"Remote setup","text":"<p>Run the same commands per each host. Note: some commands must be run remotely.</p> <pre><code># on remote host\nmkdir -p ~/.flightctl/certs/ ~/.config/flightctl ~/bin\nscp bin/agent/etc/flightctl/certs/* your_username@remotehost:~/.flightctl/certs/\nscp bin/agent/etc/flightctl/config.yaml your_username@remotehost:~/.flightctl/agent.yaml\nscp ~/.config/flightctl/client.yaml your_username@remotehost:~/.config/flightctl/client.yaml\nscp bin/devicesimulator your_username@remotehost:~/bin/\n# on remote host \nchmod -R 755 ~/.flightctl/ ~/.config/flightctl bin/devicesimulator\n</code></pre>"},{"location":"developer/devicesimulator/#remote-run","title":"Remote run","text":"<p>On each remote host run <code>devicesimulator</code> with at least two parameters: * count - number of devices to simulate on this host * initial-device-index - starting index for device name suffix. To simulate 600 devices on 3 hosts run:     &gt; bin/devicesimulator --count=200 # device-00000 to device-00199     &gt;      &gt; bin/devicesimulator --count=200 --initial-device-index=200 # device-00200 to device-00399     &gt;      &gt; bin/devicesimulator --count=200 --initial-device-index=400 # device-00400 to device-00599</p> <p>Per each device a <code>podman event</code> will be created to consume its events. These tasks will never finish and will consume a considerable amount of memory. As a workaround run the following script on each host:</p> <pre><code>#!/bin/bash\nwhile true; do\n  echo pkill -f -TERM 'podman events'\n  sudo pkill -f -TERM 'podman events'\n  sleep 30\ndone\n</code></pre> <p>You can also use <code>-v error</code> or <code>-v fatal</code> flag to limit a lower level of messages to be displayed.</p>"},{"location":"developer/metrics/","title":"Flight Control Prometheus Metrics","text":"<p>This document describes the Prometheus metrics exposed by various Flight Control components.</p>"},{"location":"developer/metrics/#alert-exporter-metrics","title":"Alert Exporter Metrics","text":"<p>The FlightCtl Alert Exporter exposes Prometheus metrics on port 8081 at the <code>/metrics</code> endpoint. </p> <p>Note: The metrics are exposed on the container port 8081, but there is no Kubernetes Service exposing this port externally. For external access to these metrics, you would need to either: - Use <code>kubectl port-forward</code> to forward the port locally - Create a Service to expose port 8081  - Access metrics through monitoring tools configured within the cluster</p>"},{"location":"developer/metrics/#processing-metrics","title":"Processing Metrics","text":"Metric Type Description <code>flightctl_alert_exporter_processing_cycles_total</code> Counter Total number of processing cycles completed <code>flightctl_alert_exporter_processing_duration_seconds</code> Histogram Time spent processing events in seconds <code>flightctl_alert_exporter_events_processed_total</code> Counter Total number of events processed <code>flightctl_alert_exporter_events_skipped_total</code> Counter Total number of events skipped, with <code>reason</code> label"},{"location":"developer/metrics/#alert-metrics","title":"Alert Metrics","text":"Metric Type Description <code>flightctl_alert_exporter_alerts_active_total</code> Gauge Current number of active alerts <code>flightctl_alert_exporter_alerts_created_total</code> Counter Total number of alerts created <code>flightctl_alert_exporter_alerts_resolved_total</code> Counter Total number of alerts resolved"},{"location":"developer/metrics/#alertmanager-interaction","title":"Alertmanager Interaction","text":"Metric Type Description <code>flightctl_alert_exporter_alertmanager_requests_total</code> Counter Total number of requests to Alertmanager, with <code>status</code> label <code>flightctl_alert_exporter_alertmanager_request_duration_seconds</code> Histogram Time spent sending requests to Alertmanager <code>flightctl_alert_exporter_alertmanager_retries_total</code> Counter Total number of retries when sending to Alertmanager"},{"location":"developer/metrics/#checkpoint-operations","title":"Checkpoint Operations","text":"Metric Type Description <code>flightctl_alert_exporter_checkpoint_operations_total</code> Counter Total number of checkpoint operations, with <code>operation</code> and <code>status</code> labels <code>flightctl_alert_exporter_checkpoint_size_bytes</code> Gauge Size of the checkpoint data in bytes"},{"location":"developer/metrics/#health-uptime","title":"Health &amp; Uptime","text":"Metric Type Description <code>flightctl_alert_exporter_uptime_seconds</code> Gauge Time since the alert exporter started in seconds <code>flightctl_alert_exporter_last_successful_processing_timestamp</code> Gauge Unix timestamp of the last successful processing cycle <code>flightctl_alert_exporter_errors_total</code> Counter Total number of errors encountered, with <code>component</code> and <code>type</code> labels"},{"location":"developer/service-quadlets/","title":"Flight Control service Quadlets","text":""},{"location":"developer/service-quadlets/#overview","title":"Overview","text":"<p>Flight Control services can be deployed as systemd-managed container Quadlets, providing a declarative way to manage containerized services using native systemd tooling.</p>"},{"location":"developer/service-quadlets/#what-are-quadlets","title":"What are Quadlets?","text":"<p>Quadlets are a systemd feature that allows you to define containerized services using systemd unit files. Instead of running containers manually with <code>podman run</code>, you define the container configuration in a <code>.container</code> file that systemd can manage directly.</p> <p>A Quadlet file uses the systemd unit file format with container-specific directives:</p> <pre><code>[Unit]\nDescription=A containerized service\n\n[Container]\nContainerName=some-service\nImage=quay.io/some-org/some-service:1.0.0\n</code></pre> <p>When systemd processes this file, it automatically generates the appropriate service unit and manages the container lifecycle.</p> <p>More info about systemd units using Podman Quadlet including definitions of fields available in the <code>.container</code> files can be found in the Podman systemd documentation</p> <p>Note Flight Control Quadlets are configured to run rootful containers and rootless is not supported</p>"},{"location":"developer/service-quadlets/#flight-control-service-architecture","title":"Flight Control Service Architecture","text":"<p>The Flight Control Quadlets are organized in the <code>deploy/podman/</code> directory with the following general structure:</p> <pre><code>deploy/podman/\n\u251c\u2500\u2500 flightctl-api/                      # Directory for each service\n\u2502   \u251c\u2500\u2500 flightctl-api.container         # API service definition\n\u2502   \u251c\u2500\u2500 flightctl-api-init.container    # Init container to manage creating application configuration\n\u2502   \u2514\u2500\u2500 flightctl-api-config/           # Configuration templates and scripts\n...\n\u251c\u2500\u2500 flightctl.network                   # Container network definition\n\u251c\u2500\u2500 flightctl.target                    # Service group definition\n\u2514\u2500\u2500 service-config.yaml                 # Global configuration template\n</code></pre>"},{"location":"developer/service-quadlets/#service-dependencies","title":"Service Dependencies","text":"<p>Services are configured with proper startup ordering through systemd dependencies:</p> <pre><code>[Unit]\nAfter=flightctl-db.service flightctl-kv.service\nRequires=flightctl-db.service flightctl-kv.service\n</code></pre> <p>The dependency graph is configured between the individual <code>.container</code> files.</p>"},{"location":"developer/service-quadlets/#configuration-management","title":"Configuration Management","text":""},{"location":"developer/service-quadlets/#global-configuration","title":"Global Configuration","text":"<p>All services share a common configuration file <code>service-config.yaml</code>:</p> <pre><code>global:\n  baseDomain: example.com\n  auth:\n    type: none # aap, oidc or none\n    insecureSkipTlsVerify: false\n    aap:\n      apiUrl: https://aap.example.com\n      # ... other AAP settings\n    oidc:\n      oidcAuthority: https://oidc.example.com\n      # ... other OIDC settings\n</code></pre>"},{"location":"developer/service-quadlets/#service-configuration","title":"Service Configuration","text":"<p>Services have configuration requirements such as files or env variables they need to run.  The config can largely be broken down into two buckets:</p> <ol> <li>Static configuration - Files that are the same for all instances of a service</li> <li>Dynamic configuration - Files that must be rendered based upon installation specific state or user provided config</li> </ol> <p>An example configuration directory for a service looks like:</p> <pre><code>deploy/podman/\n\u251c\u2500\u2500 flightctl-service-name/                      # Directory for each service\n\u2502   \u2514\u2500\u2500 flightctl-service-name-config/           # Configuration templates and scripts\n|       \u251c\u2500\u2500 env.template                         # Template for env variables the service needs\n|       \u251c\u2500\u2500 config.ini                           # Static .ini file for configuring the service\n|       \u2514\u2500\u2500 init.sh                              # Script that is run by the init-container\n</code></pre>"},{"location":"developer/service-quadlets/#static-configuration","title":"Static Configuration","text":"<p>Services such as <code>flightctl-kv</code> have static files like a <code>redis.conf</code> used for any running instances of the service.  The .conf file is installed to a standardized location (more on this further below) then referenced in the <code>.container</code> file like</p> <pre><code>Volume=/usr/share/flightctl/flightctl-kv/redis.conf:/usr/local/etc/redis/redis.conf\n</code></pre>"},{"location":"developer/service-quadlets/#dynamic-configuration","title":"Dynamic Configuration","text":"<p>Many services use init containers to template configuration files before the main service starts.  These init containers run configuration scripts, overlay values into rendered configuration the associated service needs, and are configured to run before the main service container starts.</p> <p>For example <code>flightctl-api</code> makes use of an init container to load values from the global <code>service-config.yaml</code> file and apply them to a <code>config.yaml</code> and an env file for populating variables needed by the service.  The resulting configuration is consumed like:</p> <pre><code># Load env variables written by the init service\nEnvironmentFile=/etc/flightctl/flightctl-api/env\n# Load config.yaml written by the init service\nVolume=/etc/flightctl/flightctl-api/config.yaml:/root/.flightctl/config.yaml:ro,z\n</code></pre>"},{"location":"developer/service-quadlets/#secrets","title":"Secrets","text":"<p>A subset of sensitive data is managed through Podman secrets:</p> <pre><code>[Container]\nSecret=flightctl-postgresql-master-password,type=env,target=DB_PASSWORD\n</code></pre> <p>Secrets are automatically generated during deployment and injected as environment variables to the running containers.</p>"},{"location":"developer/service-quadlets/#local-deployment","title":"Local Deployment","text":"<p>Deploy all services:</p> <pre><code>make deploy-quadlets\n</code></pre> <p>Deploy individual services:</p> <pre><code>make deploy-db\nmake deploy-kv\n</code></pre> <p>NOTE Deploying individual services makes use of service-name-standalone.container files The -standalone files are handled as a special case and currently used for integration testing </p>"},{"location":"developer/service-quadlets/#deployment-flow","title":"Deployment Flow","text":"<p>At a high level running <code>make deploy-quadlets</code> performs the following steps:</p> <ol> <li>Installs files in appropriate locations</li> <li>Generates underlying systemd units and config by running <code>systemctl daemon-reload</code></li> <li>Starts a <code>flightctl.target</code> systemd target that spins up all the services</li> </ol>"},{"location":"developer/service-quadlets/#installation","title":"Installation","text":"<p>Install in the context of the <code>make deploy-quadlets</code> involves taking files found in the Flight Control repository and moving them to various directories on the host system.  The directories in question are:</p> <ol> <li>A configuration directory intended for read-only use - namely predefined config files or scripts that should not be editable<ul> <li><code>/usr/share/flightctl/</code></li> </ul> </li> <li>A configuration directory intended for dynamic use and populated by init containers and containing application state generated by the running services.<ul> <li><code>/etc/flightctl/</code></li> </ul> </li> <li>A systemd directory where <code>.container</code> files should be placed so that systemd will generate the underlying units appropriately.<ul> <li><code>/usr/share/containers/systemd/</code></li> </ul> </li> <li>A systemd directory where native systemd (e.g. the <code>flightctl.target</code> file) should be placed<ul> <li><code>/usr/lib/systemd/system</code></li> </ul> </li> </ol>"},{"location":"developer/service-quadlets/#cleanup","title":"Cleanup","text":"<p>Remove all services and data:</p> <pre><code>make clean-quadlets\n</code></pre> <p>This stops services, removes configuration files, deletes volumes, and cleans up secrets.</p>"},{"location":"developer/service-quadlets/#service-management","title":"Service Management","text":""},{"location":"developer/service-quadlets/#startingstopping-services","title":"Starting/Stopping Services","text":"<pre><code># Start all services\nsudo systemctl start flightctl.target\n\n# Stop all services\nsudo systemctl stop flightctl.target\n\n# Restart individual service\nsudo systemctl restart flightctl-api.service\n\n# Check service status\nsudo systemctl status flightctl-api.service\n</code></pre>"},{"location":"developer/service-quadlets/#viewing-logs","title":"Viewing Logs","text":"<pre><code># View API service logs\nsudo journalctl -u flightctl-api.service -f\n\n# View all Flight Control logs\nsudo journalctl -u \"flightctl-*\" -f\n</code></pre> <p>The <code>--no-pager</code> option can also be helpful to wrap text depending on terminal settings.</p>"},{"location":"developer/service-quadlets/#container-management","title":"Container Management","text":"<pre><code># List running containers\nsudo podman ps\n\n# Execute command in container\nsudo podman exec -it flightctl-api ls\n\n# View container logs\nsudo podman logs flightctl-api\n</code></pre>"},{"location":"developer/service-quadlets/#rpm-installation-and-deployment","title":"RPM Installation and Deployment","text":"<p>The service Quadlets are also available to install via an RPM.  Installation steps for the latest release:</p> <pre><code>sudo dnf copr enable -y @redhat-et/flightctl\nsudo dnf install -y flightctl-services\nsudo systemctl start flightctl.target\nsudo systemctl enable flightctl.target # To enable starting on reboot\n</code></pre>"},{"location":"developer/service-quadlets/#contributing-adding-a-new-quadlet","title":"Contributing: Adding a New Quadlet","text":"<p>Follow these steps to add a new service to the Flight Control Quadlets:</p>"},{"location":"developer/service-quadlets/#1-create-service-directory","title":"1. Create Service Directory","text":"<pre><code>mkdir -p deploy/podman/flightctl-myservice/flightctl-myservice-config\n</code></pre>"},{"location":"developer/service-quadlets/#2-create-container-quadlet","title":"2. Create Container Quadlet","text":"<p>Create <code>deploy/podman/flightctl-myservice/flightctl-myservice.container</code>:</p> <pre><code>[Unit]\nDescription=Flight Control My Service\nPartOf=flightctl.target\n# Update After= and Requires= as needed for your needs\nAfter=\nRequires=\n\n[Container]\nContainerName=flightctl-myservice\nImage=quay.io/flightctl/flightctl-myservice:latest\nNetwork=flightctl.network\n# !Important!\n# Because the containers are run using rootful podman host port definitions\n# will by default will automatically bypass configured firewalls and expose the port to the outside world.\n# See https://access.redhat.com/solutions/7081860\nPublishPort=8080:8080\n\n# Add Volume / Secret / EnvironmentFile definitions as needed\nVolume=/etc/flightctl/flightctl-myservice/config.yaml:/root/.flightctl/config.yaml:ro,z\nSecret=flightctl-postgresql-master-password,type=env,target=DB_PASSWORD\nEnvironmentFile=/etc/flightctl/flightctl-myservice/env\n\n[Service]\nRestart=always\nRestartSec=30\n\n[Install]\nWantedBy=flightctl.target\n</code></pre>"},{"location":"developer/service-quadlets/#3-setup-configuration-optional","title":"3. Setup Configuration (Optional)","text":""},{"location":"developer/service-quadlets/#static-configuration_1","title":"Static Configuration","text":"<p>Add files to a <code>deploy/podman/flightctl-myservice/flightctl-myservice-config</code> directory.</p>"},{"location":"developer/service-quadlets/#dynamic-configuration_1","title":"Dynamic Configuration","text":"<p>Add a template to a <code>deploy/podman/flightctl-myservice/flightctl-myservice-config</code> directory.</p> <p><code>deploy/podman/flightctl-myservice/flightctl-myservice-config/config.yaml.template</code>:</p> <pre><code>database:\n  hostname: flightctl-db\n  port: 5432\nservice:\n  baseUrl: https://{{BASE_DOMAIN}}:8080/\n</code></pre> <p>Then write an <code>init.sh</code> file to also place in <code>deploy/podman/flightctl-myservice/flightctl-myservice-config</code>. <code>deploy/podman/flightctl-myservice/flightctl-myservice-config/init.sh</code>:</p> <pre><code>#!/usr/bin/env bash\nset -eo pipefail\n\nsource \"/utils/init_utils.sh\"\n\n# Write service specific initialization logic as needed\n</code></pre> <p>Create <code>deploy/podman/flightctl-myservice/flightctl-myservice-init.container</code>:</p> <pre><code>[Unit]\nPartOf=flightctl.target\nAfter=flightctl-db.service\nWants=flightctl-db.service\n\n[Container]\nImage=registry.access.redhat.com/ubi9/ubi-minimal\nContainerName=flightctl-myservice-init\nNetwork=flightctl.network\nVolume=/usr/share/flightctl/flightctl-myservice:/config-source:ro,z\nVolume=/usr/share/flightctl/init_utils.sh:/utils/init_utils.sh:ro,z\nVolume=/etc/flightctl/flightctl-myservice:/config-destination:rw,z\nVolume=/etc/flightctl/service-config.yaml:/service-config.yaml:ro,z\nExec=/bin/sh /config-source/init.sh\n\n[Service]\nType=oneshot\nRemainAfterExit=true\nRestart=on-failure\nRestartSec=5s\n\n[Install]\nWantedBy=flightctl.target\n</code></pre>"},{"location":"developer/service-quadlets/#4-add-volume-if-needed","title":"4. Add Volume (If Needed)","text":"<p>Create <code>deploy/podman/flightctl-myservice/flightctl-myservice.volume</code>:</p> <pre><code>[Volume]\nVolumeName=flightctl-myservice\n</code></pre>"},{"location":"developer/service-quadlets/#5-update-install-scripting","title":"5. Update Install Scripting","text":"<p>Edit <code>deploy/scripts/install.sh</code> to include your service in the <code>render_files()</code> function:</p> <pre><code>render_files() {\n    # ... existing services ...\n    render_service \"myservice\" \"${SOURCE_DIR}\"\n    # ... rest of function ...\n\n    # If the service writes config ensure the location where those files are placed exists\n    mkdir -p \"${CONFIG_WRITEABLE_DIR}/flightctl-cli-artifacts\"\n}\n</code></pre> <p>Edit <code>deploy/scripts/deploy_quadlets.sh</code> so the polling waits for the new service to spin up.</p> <p>If your service creates volume or other artifacts, edit <code>deploy/scripts/clean_quadlets.sh</code> so they are properly removed.</p>"},{"location":"developer/service-quadlets/#6-update-target-file","title":"6. Update Target File","text":"<p>Edit <code>deploy/podman/flightctl.target</code> to include your service:</p> <pre><code>[Unit]\n# ... existing content ...\nRequires=flightctl-myservice.service\n\nAfter=flightctl-myservice.service\n</code></pre>"},{"location":"developer/service-quadlets/#7-test-your-service","title":"7. Test Your Service","text":"<pre><code># Deploy and test\nmake deploy-quadlets\n\n# Check service status\nsudo systemctl status flightctl-myservice.service\n\n# View logs\nsudo journalctl -u flightctl-myservice.service -f --no-pager\n</code></pre> <p>After sufficient testing, move onto the RPM steps below.</p>"},{"location":"developer/service-quadlets/#contributing-updating-the-rpm","title":"Contributing: Updating the RPM","text":"<p>When adding new Quadlets to Flight Control, the RPM spec file needs to be updated to include the new service files in the <code>flightctl-services</code> sub-package. The spec file handles packaging and installation of Quadlet files through the system package manager.</p>"},{"location":"developer/service-quadlets/#1-update-the-files-services-section","title":"1. Update the %files services Section","text":"<p>Edit <code>packaging/rpm/flightctl.spec</code> to include your new service files. Add entries for both the configuration directory and any specific files:</p> <pre><code>%files services\n    # ... existing content ...\n\n    # Add directory for dynamic config\n    %dir %{_sysconfdir}/flightctl/flightctl-myservice\n\n    # Add directory for read-only config\n    %dir %attr(0444,root,root) %{_datadir}/flightctl/flightctl-myservice\n\n    # Add specific config files (if any)\n    %{_datadir}/flightctl/flightctl-myservice/config.yaml.template\n    %{_datadir}/flightctl/flightctl-myservice/env.template\n    %attr(0755,root,root) %{_datadir}/flightctl/flightctl-myservice/init.sh\n\n    # Quadlet files are included via wildcard: %{_datadir}/containers/systemd/flightctl*\n</code></pre>"},{"location":"developer/service-quadlets/#2-test-rpm-build","title":"2. Test RPM Build","text":"<p>Build the RPM locally:</p> <pre><code>rm -rf bin/rpm\nmake build rpm\n</code></pre> <p>The above will place the built services rpm in <code>bin/rpm/flightctl-services-*</code></p> <p>The rpm can be installed on the host system, or preferably a Fedora / CentOS Stream / RHEL VM.</p> <p>Install locally:</p> <pre><code>sudo dnf install -y bin/rpm/flightctl-services-*.rpm\n</code></pre> <p>Install in a VM:</p> <pre><code># Sample command to move rpm file to VM\nscp -r bin/rpm/flightctl-services-* user@192.168.122.172:/home/user\n\n# ssh into VM\n\n# Install RPM\ncd /home/user\nsudo dnf install flightctl-services-*\n</code></pre> <p>After installation services can be spun up by starting the <code>.target</code>:</p> <pre><code>sudo systemctl start flightctl.target\n</code></pre>"},{"location":"developer/architecture/","title":"Architecture","text":"<p>This section contains detailed documentation about FlightCtl's system architecture and design decisions.</p>"},{"location":"developer/architecture/#core-architecture","title":"Core Architecture","text":"<ul> <li>System Architecture - Overall system design and component relationships</li> </ul>"},{"location":"developer/architecture/#component-architecture","title":"Component Architecture","text":"<ul> <li>Tasks - Task processing and workflow architecture</li> <li>Field Selectors - Field selection and filtering architecture</li> <li>Alerts - Alert system architecture and design</li> </ul>"},{"location":"developer/architecture/#rollout-management","title":"Rollout Management","text":"<ul> <li>Rollout Device Selection - Device selection strategies for rollouts</li> <li>Rollout Disruption Budget - Managing disruption during rollouts</li> </ul>"},{"location":"developer/architecture/#observability","title":"Observability","text":"<ul> <li>Service Observability - Service monitoring and observability architecture</li> </ul> <p>These documents provide deep technical insights into how FlightCtl is designed and implemented. They are essential reading for developers who want to understand the system's internal workings or contribute to its development. </p>"},{"location":"developer/architecture/alerts/","title":"Flight Control Alerts Architecture","text":"<p>This document describes the architecture of Flight Control's alerts system, including the alert exporter, Alertmanager integration, and authentication proxy.</p>"},{"location":"developer/architecture/alerts/#overview","title":"Overview","text":"<p>The Flight Control alerts system provides alerting for resource status changes. It processes events from the Flight Control PostgreSQL database and forwards them to Alertmanager for distribution and management.</p> <pre><code>graph TB\n    subgraph \"Flight Control Core\"\n        API[API Server]\n        DB[(PostgreSQL Database)]\n        EVENTS[Events Table]\n        CHECKPOINTS[Checkpoints Table]\n    end\n\n    subgraph \"Alert Processing\"\n        AE[Alert Exporter]\n    end\n\n    subgraph \"Alert Management\"\n        PROXY[Alertmanager Proxy]\n        AM[Alertmanager]\n        NOTIF[Notification Channels]\n    end\n\n    subgraph \"Users/UI\"\n        USERS[Users/UI]\n    end\n\n    API --&gt; EVENTS\n    API --&gt; CHECKPOINTS\n    EVENTS --&gt; DB\n    CHECKPOINTS --&gt; DB\n    AE --&gt; EVENTS\n    AE --&gt; CHECKPOINTS\n    AE --&gt; AM\n    USERS --&gt; PROXY\n    PROXY --&gt; AM\n    AM --&gt; NOTIF\n\n    style AE fill:#e1f5fe\n    style PROXY fill:#f3e5f5\n    style AM fill:#fff3e0</code></pre>"},{"location":"developer/architecture/alerts/#components","title":"Components","text":""},{"location":"developer/architecture/alerts/#1-alert-exporter","title":"1. Alert Exporter","text":"<ul> <li>Location: <code>internal/alert_exporter/</code></li> <li>Binary: <code>flightctl-alert-exporter</code></li> <li>Purpose: Processes Flight Control events and converts them to Prometheus-compatible alerts</li> </ul>"},{"location":"developer/architecture/alerts/#architecture","title":"Architecture","text":"<pre><code>graph LR\n    subgraph \"Alert Exporter Process\"\n        POLLER[Event Poller]\n        PROC[Event Processor]\n        CKPT[Checkpoint Manager]\n        CLIENT[Alertmanager Client]\n        METRICS[Metrics Server]\n    end\n\n    subgraph \"PostgreSQL Database\"\n        EVENTS_TBL[Events Table]\n        CKPT_TBL[Checkpoints Table]\n    end\n\n    subgraph \"External\"\n        AM[Alertmanager]\n    end\n\n    POLLER --&gt; EVENTS_TBL\n    POLLER --&gt; PROC\n    PROC --&gt; CKPT\n    CKPT --&gt; CKPT_TBL\n    PROC --&gt; CLIENT\n    CLIENT --&gt; AM</code></pre>"},{"location":"developer/architecture/alerts/#key-features","title":"Key Features","text":"<ul> <li>Event Processing: Monitors Flight Control events (device disconnections, resource issues, etc.)</li> <li>State Management: Maintains checkpoint of processed events and active alerts in PostgreSQL</li> <li>Retry Logic: Exponential backoff retry mechanism for Alertmanager communication</li> <li>Metrics: Exposes Prometheus metrics on port 8081</li> <li>Graceful Shutdown: Handles SIGTERM/SIGINT signals properly</li> </ul>"},{"location":"developer/architecture/alerts/#event-types-processed","title":"Event Types Processed","text":"Event Type Alert Generated Group <code>DeviceDisconnected</code> Device connectivity alert - <code>DeviceConnected</code> Resolves connectivity alert - <code>DeviceApplicationError</code> Application error alert App Status <code>DeviceApplicationDegraded</code> Application degraded alert App Status <code>DeviceApplicationHealthy</code> Resolves app status alerts App Status <code>DeviceCPUCritical</code> CPU critical alert CPU <code>DeviceCPUWarning</code> CPU warning alert CPU <code>DeviceCPUNormal</code> Resolves CPU alerts CPU <code>DeviceMemoryCritical</code> Memory critical alert Memory <code>DeviceMemoryWarning</code> Memory warning alert Memory <code>DeviceMemoryNormal</code> Resolves memory alerts Memory <code>DeviceDiskCritical</code> Disk critical alert Disk <code>DeviceDiskWarning</code> Disk warning alert Disk <code>DeviceDiskNormal</code> Resolves disk alerts Disk <code>ResourceDeleted</code> Resolves all alerts for resource - <code>DeviceDecommissioned</code> Resolves all alerts for device -"},{"location":"developer/architecture/alerts/#2-alertmanager-proxy","title":"2. Alertmanager Proxy","text":"<ul> <li>Location: <code>internal/alertmanager_proxy/</code></li> <li>Binary: <code>flightctl-alertmanager-proxy</code></li> <li>Purpose: Provides authentication and authorization for Alertmanager access</li> </ul>"},{"location":"developer/architecture/alerts/#features","title":"Features","text":"<ul> <li>Authentication: Validates Flight Control credentials</li> <li>Authorization: Enforces access controls</li> <li>Proxy: Forwards authenticated requests to Alertmanager</li> <li>SSL/TLS: Secure communication support</li> </ul>"},{"location":"developer/architecture/alerts/#3-alertmanager","title":"3. Alertmanager","text":"<ul> <li>Technology: Prometheus Alertmanager</li> <li>Purpose: Alert routing, grouping, silencing, and notification delivery</li> </ul>"},{"location":"developer/architecture/alerts/#configuration","title":"Configuration","text":"<ul> <li>Routing: Routes alerts based on labels (device, org, severity)</li> <li>Grouping: Groups related alerts to reduce noise</li> <li>Inhibition: Suppresses alerts based on rules</li> <li>Silencing: Temporary muting of alerts</li> <li>Notifications: Email, Slack, webhook integrations</li> </ul>"},{"location":"developer/architecture/alerts/#data-flow","title":"Data Flow","text":""},{"location":"developer/architecture/alerts/#alert-creation-flow","title":"Alert Creation Flow","text":"<pre><code>sequenceDiagram\n    participant D as Device\n    participant A as API Server\n    participant DB as PostgreSQL\n    participant AE as Alert Exporter\n    participant AM as Alertmanager\n    participant N as Notifications\n\n    D-&gt;&gt;A: Status Update/Disconnect\n    A-&gt;&gt;DB: Store Event in events table\n\n    loop Every polling interval\n        AE-&gt;&gt;DB: Query new events from events table\n        AE-&gt;&gt;AE: Process events\n        AE-&gt;&gt;AM: Send alerts\n        AE-&gt;&gt;DB: Update checkpoint in checkpoints table\n        AM-&gt;&gt;N: Dispatch notifications\n    end</code></pre>"},{"location":"developer/architecture/alerts/#checkpoint-management","title":"Checkpoint Management","text":"<p>The alert exporter maintains a checkpoint in the PostgreSQL checkpoints table to track: - Last processed event timestamp - Currently active alerts per resource - Alert metadata (start time, resource info)</p> <p>Note: The checkpoint only contains active alerts. Resolved alerts are removed from the checkpoint when they are resolved.</p> <pre><code>{\n  \"version\": 1,\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"alerts\": {\n    \"org_id:device:device-name\": {\n      \"DeviceDisconnected\": {\n        \"resourceName\": \"device-name\",\n        \"resourceKind\": \"Device\",\n        \"orgID\": \"org_id\",\n        \"reason\": \"DeviceDisconnected\",\n        \"startsAt\": \"2024-01-15T10:25:00Z\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"developer/architecture/alerts/#configuration_1","title":"Configuration","text":""},{"location":"developer/architecture/alerts/#alert-exporter-configuration","title":"Alert Exporter Configuration","text":"<pre><code>alertmanager:\n  hostname: \"localhost\"\n  port: 9093\n  maxRetries: 3\n  baseDelay: \"500ms\"\n  maxDelay: \"10s\"\n\nservice:\n  alertPollingInterval: \"1m\"  # How often to check for new events\n</code></pre>"},{"location":"developer/architecture/alerts/#alertmanager-configuration-example","title":"Alertmanager Configuration Example","text":"<pre><code>global:\n  smtp_smarthost: 'localhost:587'\n\nroute:\n  group_by: ['org_id', 'resource']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 1h\n  receiver: 'web.hook'\n\nreceivers:\n- name: 'web.hook'\n  webhook_configs:\n  - url: 'http://webhook-server:5001/'\n    send_resolved: true\n\ninhibit_rules:\n- source_match:\n    severity: 'critical'\n  target_match:\n    severity: 'warning'\n  equal: ['org_id', 'resource']\n</code></pre>"},{"location":"developer/architecture/alerts/#deployment","title":"Deployment","text":""},{"location":"developer/architecture/alerts/#container-images","title":"Container Images","text":"<ul> <li><code>flightctl-alert-exporter</code>: Alert processing service</li> <li><code>flightctl-alertmanager-proxy</code>: Authentication proxy</li> <li><code>prom/alertmanager</code>: Standard Alertmanager</li> </ul>"},{"location":"developer/architecture/alerts/#kuberneteshelm-deployment","title":"Kubernetes/Helm Deployment","text":"<pre><code># Alert Exporter\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flightctl-alert-exporter\nspec:\n  replicas: 1  # Single instance due to checkpoint state\n  template:\n    spec:\n      containers:\n      - name: alert-exporter\n        image: flightctl-alert-exporter:latest\n        ports:\n        - containerPort: 8081  # Metrics and health\n        env:\n        - name: CONFIG_PATH\n          value: /etc/flightctl/config.yaml\n</code></pre>"},{"location":"developer/architecture/alerts/#podmanquadlet-deployment","title":"Podman/Quadlet Deployment","text":"<p>See <code>deploy/podman/flightctl-alert-exporter/</code> for Quadlet configurations.</p>"},{"location":"developer/architecture/alerts/#data-storage","title":"Data Storage","text":""},{"location":"developer/architecture/alerts/#postgresql-database","title":"PostgreSQL Database","text":"<p>Events Table: Stores all Flight Control system events - Used by alert exporter to query new events since last checkpoint - Filtered by event types relevant to alerting</p> <p>Checkpoints Table: Stores alert exporter state - Key: <code>alert-exporter:active-alerts</code> - Contains JSON blob with active alerts and last processed timestamp - Ensures processing continues from correct point after restarts</p>"},{"location":"developer/architecture/alerts/#observability","title":"Observability","text":""},{"location":"developer/architecture/alerts/#metrics","title":"Metrics","text":"<p>The alert exporter exposes comprehensive metrics on port 8081:</p> <ul> <li>Processing performance and throughput</li> <li>Alert creation/resolution rates</li> <li>Alertmanager interaction success/failure</li> <li>Checkpoint operation metrics</li> <li>System health and uptime</li> </ul> <p>See metrics.md for complete metrics documentation.</p>"},{"location":"developer/architecture/alerts/#logging","title":"Logging","text":"<p>Structured logging with OpenTelemetry trace correlation for: - Event processing pipeline - Alert state changes - Retry operations - Error conditions</p>"},{"location":"developer/architecture/alerts/#health-checks","title":"Health Checks","text":"<ul> <li>HTTP health endpoint at <code>/health</code> (port 8081 - container-internal)</li> <li>Metrics endpoint availability at <code>/metrics</code> (port 8081 - container-internal)</li> <li>Last successful processing timestamp tracking</li> </ul> <p>Note: These endpoints are available on container port 8081 but are not exposed externally via Kubernetes Services. For external access, use <code>kubectl port-forward</code> or configure monitoring tools within the cluster.</p>"},{"location":"developer/architecture/alerts/#security-considerations","title":"Security Considerations","text":""},{"location":"developer/architecture/alerts/#authentication","title":"Authentication","text":"<ul> <li>Alert exporter uses service account credentials</li> <li>Alertmanager proxy validates Flight Control tokens</li> <li>mTLS for inter-service communication</li> </ul>"},{"location":"developer/architecture/alerts/#authorization","title":"Authorization","text":"<ul> <li>Resource-level access controls</li> <li>Organization isolation</li> <li>Role-based alert management</li> </ul>"},{"location":"developer/architecture/alerts/#network-security","title":"Network Security","text":"<ul> <li>Internal network communication</li> <li>TLS encryption for external access</li> <li>Firewall rules for metric endpoints</li> </ul>"},{"location":"developer/architecture/alerts/#scaling-performance","title":"Scaling &amp; Performance","text":""},{"location":"developer/architecture/alerts/#alert-exporter","title":"Alert Exporter","text":"<ul> <li>Single Instance: Due to checkpoint state management in PostgreSQL</li> <li>Polling Frequency: Configurable (default: 1 minute)</li> <li>Batch Processing: Events processed in batches of 1000</li> <li>Memory Usage: Proportional to active alert count</li> </ul>"},{"location":"developer/architecture/alerts/#alertmanager","title":"Alertmanager","text":"<ul> <li>High Availability: Can run multiple replicas</li> <li>Clustering: Gossip protocol for state sharing</li> <li>Storage: Persistent volume for silence/notification state</li> </ul>"},{"location":"developer/architecture/alerts/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer/architecture/alerts/#common-issues","title":"Common Issues","text":"<ol> <li>Missing Alerts</li> <li>Check event generation in PostgreSQL events table</li> <li>Verify alert exporter processing logs</li> <li> <p>Confirm Alertmanager connectivity</p> </li> <li> <p>Duplicate Alerts</p> </li> <li>Check checkpoint state consistency in PostgreSQL</li> <li>Verify single alert exporter instance</li> <li> <p>Review event deduplication logic</p> </li> <li> <p>Performance Issues</p> </li> <li>Monitor processing duration metrics</li> <li>Check PostgreSQL query performance on events table</li> <li>Review polling interval configuration</li> </ol>"},{"location":"developer/architecture/alerts/#debugging","title":"Debugging","text":"<ol> <li>Metrics: Check processing and error rates using:    <pre><code># Port forward to access metrics locally\nkubectl port-forward deployment/flightctl-alert-exporter 8081:8081\ncurl http://localhost:8081/metrics\n</code></pre></li> <li>Logs: Structured logging with OpenTelemetry trace correlation</li> <li>Database: Query events and checkpoints tables directly</li> <li>Alertmanager: Check alert reception and routing</li> </ol>"},{"location":"developer/architecture/alerts/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Multi-tenancy: Enhanced organization isolation</li> <li>Custom Alert Rules: User-defined alerting conditions</li> <li>Alert Correlation: Cross-device alert relationships</li> <li>Webhook Integration: Custom notification channels</li> </ul>"},{"location":"developer/architecture/architecture/","title":"Architecture","text":""},{"location":"developer/architecture/architecture/#system-context","title":"System Context","text":"<pre><code>C4Context\n    title System Context diagram for Device Management Service\n\n    Person(installer, \"Trusted Installer\", \"A person installing a device&lt;br/&gt;and approving its enrollment.\")\n    System(dma, \"Device Management Agent\", \"An agent of the Device&lt;br/&gt;Management Service, installed&lt;br/&gt;on each managed device.\")\n    Person(viewer, \"Fleet Viewer\", \"A person or system viewing&lt;br/&gt;the fleet's live state via a UI or API.\")\n    Person(operator, \"Fleet Operator\", \"A person or system requesting&lt;br/&gt;changes to a fleet via a UI or API.\")\n\n    Boundary(system, \"Device Management System\") {\n        System_Ext(auth, \"AuthZ/N\", \"Authenticates and authorizes&lt;br/&gt;users (not devices).\")\n        System(dms, \"Device Management&lt;br/&gt;Service\", \"A service for managing the&lt;br/&gt;lifecycle and state of device&lt;br/&gt;fleets (enrolling deivices, rolling&lt;br/&gt;out changes, monitoring status).\")\n        System_Ext(ams, \"Application Management&lt;br/&gt;Service\", \"(Optional) service for managing&lt;br/&gt;the lifecycle and state of OTT&lt;br/&gt;workloads on devices.\")\n        System_Ext(obs, \"Observability Service\", \"(Optional) service for collecting&lt;br/&gt;logs and metrics.\")\n    }\n\n    Boundary(external, \"External Systems\") {\n        System_Ext(rdvz, \"FDO Rendezvous Service\", \"(Optional) directory service&lt;br/&gt;when using FDO-based enrollment.\")\n        SystemQueue_Ext(other, \"Other Services\", \"(Optional) services that subscribe&lt;br/&gt;to fleet event notifications.\")\n    }\n\n    Rel(dma, dms, \"request enrollment,&lt;br/&gt;request desired state,&lt;br/&gt;notify current state and events\", \"HTTPS/mTLS\")\n\n    Rel(installer, dms, \"pre-register devices,&lt;br/&gt;approve device enrollment\", \"HTTPS\")\n\n    Rel(operator, dms, \"request updates to fleet\", \"HTTPS\")\n\n    Rel(viewer, dms, \"monitor fleet status and health\", \"HTTPS\")\n\n    Rel(dms, rdvz, \"register device ownership\", \"HTTPS\")\n\n    Rel(dms, other, \"notify events\", \"\")\n\n    UpdateLayoutConfig($c4ShapeInRow=\"4\", $c4BoundaryInRow=\"1\")</code></pre>"},{"location":"developer/architecture/architecture/#component","title":"Component","text":"<pre><code>C4Component\n    title Component diagram for Device Management Service's API server\n\n    Person(installer, \"Trusted Installer\", \"\")\n    System(dma, \"Device Management&lt;br/&gt;Agent\", \"\")\n    Person(viewer, \"Fleet Viewer\", \"\")\n    Person(operator, \"Fleet Operator\", \"\")\n\n    System(blankA, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n    System(blankB, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n    System(blankC, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n    System_Ext(git, \"git Repository\", \"\")\n\n    Boundary(system, \"Device Management Service\") {\n        System(blankD, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n        System(blankE, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n        Component(ui, \"UI Frontend\", \"\")\n        System(blankF, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n\n        Container_Boundary(api, \"API Application\") {\n            Component(esrv, \"Enrollment Request&lt;br/&gt;API Server\", \"A service.\")\n            Component(dsrv, \"Device&lt;br/&gt;API Endpoint\", \"A service.\")\n            Component(fsrv, \"Fleet&lt;br/&gt;API Endpoint\", \"A service.\")\n            Component(gitcache, \"git Repo Cache\", \"A cache for git repos&lt;br/&gt;containing fleet definitions.\")\n\n            Component(approver, \"Auto Approver\", \"A service.\")\n            Component(signer, \"Cert Signer\", \"A service.\")\n            Component(deployer, \"Deployment Controller\", \"A service.\")\n            System(blankI, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n        }\n\n        Container_Boundary(db, \"Database\") {\n            ComponentDb(edb, \"Enr. Req. Database\", \"Stores enrollment requests.\")\n            ComponentDb(ddb, \"Device Database\", \"Stores devices.\")\n            ComponentDb(fdb, \"Fleet Database\", \"Stores fleets.\")\n            System(blankH, \"\", \"\", $bgColor=\"white\" $borderColor=\"white\")\n        }\n    }\n\n    Rel(installer, esrv, \"approve\", \"HTTPS/mTLS\")\n    Rel(dma, esrv, \"enroll\", \"HTTPS/mTLS\")\n    Rel(dma, dsrv, \"fetch spec, notify status\", \"HTTPS/mTLS\")\n\n    Rel(viewer, ui, \"monitor status\", \"HTTPS\")\n    Rel_D(ui, dsrv, \"subscribe updates\", \"HTTPS/mTLS\")\n    Rel_D(ui, fsrv, \"subscribe updates\", \"HTTPS/mTLS\")\n\n    Rel(operator, git, \"merge PR\", \"HTTPS\")\n    Rel(git, gitcache, \"webhook event\", \"HTTPS\")\n    Rel(gitcache, fsrv, \"update&lt;br/&gt;fleet spec\", \"\")\n\n    Rel(esrv, edb, \"read/write\", \"SQL/TCP\")\n    Rel(dsrv, ddb, \"read/write\", \"SQL/TCP\")\n    Rel(fsrv, fdb, \"read/write\", \"SQL/TCP\")\n\n    Rel(esrv, approver, \"notify\", \"\")\n    Rel(approver, esrv, \"&lt;br/&gt;approve\", \"\")\n\n    Rel(esrv, signer, \"notify\", \"\")\n    Rel(signer, esrv, \"&lt;br/&gt;sign\", \"\")\n    Rel(dsrv, signer, \"notify\", \"\")\n    Rel(signer, dsrv, \"&lt;br/&gt;sign\", \"\")\n\n    Rel(dsrv, deployer, \"notify\", \"\")\n    Rel(deployer, dsrv, \"&lt;br/&gt;update device spec\", \"\")\n    Rel(fsrv, deployer, \"notify\", \"\")\n    Rel(deployer, fsrv, \"&lt;br/&gt;update fleet status\", \"\")\n\n    UpdateLayoutConfig($c4ShapeInRow=\"4\", $c4BoundaryInRow=\"1\")</code></pre>"},{"location":"developer/architecture/architecture/#on-boarding-sequence","title":"On-boarding Sequence","text":"<pre><code>\nsequenceDiagram\n    actor inst as Trusted&lt;br/&gt;Installer\n    participant dma as Device Management&lt;br/&gt;Agent\n    participant eapi as Enr.Req.&lt;br/&gt;API\n    participant edb as Enr.Req.&lt;br/&gt; DB\n    participant signer as CSR&lt;br/&gt;Signer\n    participant dapi as Device&lt;br/&gt;API\n    participant ddb as Device&lt;br/&gt; DB\n\n    activate dma\n    dma-&gt;&gt;dma: generate key pair\n    deactivate dma\n    dma-&gt;&gt;+eapi: createEnrollmentRequest(&lt;br/&gt;fingerprint, csr, deviceStatus)\n    eapi-&gt;&gt;edb: write\n    edb--&gt;&gt;eapi: \n    eapi--&gt;&gt;-dma: 201 Created\n    inst-&gt;&gt;+eapi: updateEnrollmentRequestApproval(fingerprint, fleet, labels)\n    eapi-&gt;&gt;edb: write\n    edb--&gt;&gt;eapi: \n    eapi--&gt;&gt;dapi: createDevice(fingerprint, fleet, labels)\n    dapi-&gt;&gt;ddb: write\n    ddb--&gt;&gt;dapi: \n    dapi--&gt;&gt;eapi: 201 Created\n    eapi-&gt;&gt;signer: notify\n    activate signer\n    eapi--&gt;&gt;-inst: 200 OK\n    signer-&gt;&gt;signer: sign cert\n    signer-&gt;&gt;eapi: updateEnrollmentRequestStatus(fingerprint, cert)\n    eapi-&gt;&gt;edb: write\n    edb--&gt;&gt;eapi: \n    eapi--&gt;&gt;signer: 200 OK\n    deactivate signer\n    dma-&gt;&gt;+eapi: getEnrollmentRequestStatus(fingerprint)\n    eapi-&gt;&gt;edb: read\n    edb--&gt;&gt;eapi: \n    eapi--&gt;&gt;-dma: 200 OK (deviceApiUrl, cert)\n    dma-&gt;&gt;dapi: getDeviceSpec(fingerprint)</code></pre>"},{"location":"developer/architecture/field-selectors/","title":"Field Selectors","text":"<p>Field selectors filter a list of Flight Control resources based on specific resource field values. They follow the same syntax, principles, and operators as Kubernetes Field and Label selectors, with additional operators available for more advanced search use cases.</p>"},{"location":"developer/architecture/field-selectors/#adding-selectors","title":"Adding Selectors","text":"<p>Selectors are always tied to a resource model (e.g., device, fleet, etc.).</p> <p>Inside <code>internal/store/model</code>, each resource model can define selectors. Once passed to <code>NewFieldSelector(dest any)</code>, the selectors will be detected and resolved automatically.</p> <p>There are three ways to define a resolvable selector:</p>"},{"location":"developer/architecture/field-selectors/#1-tagging-a-resource-model-field","title":"1. Tagging a Resource Model Field","text":"<p>You can tag a resource model field with a selector name: <pre><code>Name string `gorm:\"primary_key;\" selector:\"metadata.name\"`\n</code></pre> Once the field is tagged with a selector name, it can be resolved using the field-selector corresponding to that name. The field name (or DBName) and type will be automatically detected by the field-selector.</p>"},{"location":"developer/architecture/field-selectors/#using-hidden-and-private-selectors","title":"Using Hidden and Private Selectors","text":"<p>Selectors can be further annotated as hidden or private to control their behavior: <pre><code>Labels JSONMap[string, string] `gorm:\"type:jsonb\" selector:\"metadata.labels,hidden,private\"`\n</code></pre> * <code>hidden</code>: The selector will not be exposed to end-users during discovery. It will not appear in the list of available selectors.</p> <ul> <li><code>private</code>: The selector cannot be directly used by the field-selector. However, it may still be utilized internally by other selectors, such as the label selector.</li> </ul>"},{"location":"developer/architecture/field-selectors/#2-adding-selector-mapping","title":"2. Adding Selector Mapping","text":"<p>A resource model can define a resolvable selector name mapped to an existing selector defined by the resource model.</p> <p>To enable this, the resource model must implement the following functions, which will be used by the field-selector during resolution:</p> <pre><code>MapSelectorName(name selector.SelectorName) []selector.SelectorName\n\nListSelectors() selector.SelectorNameSet\n</code></pre> <p>This is useful in cases where: - You rename a selector and want to support the deprecated name for backward compatibility. - You want to map one selector name to multiple existing selectors (e.g., nameOrAlias).</p>"},{"location":"developer/architecture/field-selectors/#example-add-mapping-to-metadatanameoralias-selector","title":"Example: Add mapping to metadata.nameOrAlias selector","text":"<pre><code>func (m *Device) MapSelectorName(name selector.SelectorName) []selector.SelectorName {\n    if strings.EqualFold(\"metadata.nameOrAlias\", name.String()) {\n        return []selector.SelectorName{\n            selector.NewSelectorName(\"metadata.name\"),\n            selector.NewSelectorName(\"metadata.alias\"),\n        }\n    }\n    return nil\n}\n\nfunc (m *Device) ListSelectors() selector.SelectorNameSet {\n    return selector.NewSelectorFieldNameSet().Add(selector.NewSelectorName(\"metadata.nameOrAlias\"))\n}\n</code></pre> <p>[!NOTE] - Mapping to multiple selectors will result in an OR condition between them. - A mapped selector will be resolved first. It can override or hide an existing resolver defined by the resource model. - <code>NewSelectorName</code> can be replaced with <code>NewHiddenSelectorName</code> to mark the selector as hidden. This ensures it won't be exposed during discovery but can still be used internally (see the explanation above).</p>"},{"location":"developer/architecture/field-selectors/#3-custom-selector-resolution","title":"3. Custom Selector Resolution","text":"<p>For more advanced cases, selectors can be manually resolved.</p> <p>To enable this, the resource model must implement the following functions, which will be used by the field-selector during resolution:</p> <pre><code>ResolveSelector(name selector.SelectorName) (*selector.SelectorField, error) \n\nListSelectors() selector.SelectorNameSet\n</code></pre>"},{"location":"developer/architecture/field-selectors/#example-use-case-whitelisting","title":"Example Use Case: Whitelisting","text":"<p>We use custom selectors to create a whitelist for the <code>Status</code> and <code>Spec</code> fields. For all Flight Control resources, <code>Status</code> and <code>Spec</code> fields are of type JSONB. Using explicit tagging on the resource model field results in allowing all JSONB keys to be queried.</p> <p>For example, tagging the <code>Status</code> field to allow it to be resolved: <pre><code>// The last reported state, stored as opaque JSON object.\nStatus *JSONField[api.DeviceStatus] `gorm:\"type:jsonb\" selector:\"metadata.status\"`\n</code></pre></p> <p>The field-selector, in turn, resolves this field as type JSONB, automatically allowing keys like <code>status.updated.status</code> to be queried.</p> <p>While this approach is powerful, it introduces two challenges:</p> <ul> <li> <p>Type Constraints: Resolved keys only accept JSON values. For example: <code>status.updated.status=\"UpToDate\"</code></p> </li> <li> <p>Loss of Control: Allowing all <code>Status</code> keys to be queried restricts our ability to whitelist and only support specific keys.</p> </li> </ul>"},{"location":"developer/architecture/field-selectors/#custom-selector-for-jsonb-fields","title":"Custom Selector for JSONB Fields","text":"<p>Adding Custom Selector for <code>status.updated.status</code> <pre><code>func (m *Device) ResolveSelector(name selector.SelectorName) (*selector.SelectorField, error) {\n  if strings.EqualFold(\"status.updated.status\", name.String()) {\n        return &amp;selector.SelectorField{\n            Type:      selector.String,\n            FieldName: \"status-&gt;'updated'-&gt;&gt;'status'\",\n            FieldType: \"jsonb\",\n        }, nil\n    }\n    return nil, nil\n}\n\nfunc (m *Device) ListSelectors() selector.SelectorNameSet {\n    return selector.NewSelectorFieldNameSet().Add(\"status.updated.status\")\n}\n</code></pre></p> <p>[!NOTE] - Mapping a selector name using <code>MapSelectorName</code> to a custom selector is also supported. This can be useful for deprecating a key. - When <code>FieldType</code> is defined as JSONB, the field-selector Adapts the <code>FieldName</code> to a valid JSONB key (e.g., <code>status -&gt; 'updated' -&gt;&gt; 'status'</code>). - If the <code>Type</code> is different from JSONB, the field-selector will cast the key to the corresponding type, and the selector will be processed as that type. - A custom selector is resolved after mapped selectors. It can override or hide an existing resolver defined by the resource model.</p>"},{"location":"developer/architecture/field-selectors/#kubernetes-selector-package","title":"Kubernetes Selector Package","text":"<p>The field-selector uses the Kubernetes selector to initially parse the query.</p> <p>The package was added in <code>/pkg/k8s/selector</code>, and the following modifications were made:</p> <ul> <li>Kubernetes label selectors are now used for both fields and labels.</li> <li>The functions <code>validateLabelKey</code> and <code>validateLabelValue</code> are applied only to labels.</li> <li>Fields have a modified lexer to support escaping and RHS symbols (e.g., <code>key in (x=y)</code>).</li> <li>Two new operators, <code>contains</code> and <code>notcontains</code>, were added.</li> </ul> <p>A \"vanilla\" commit of Kubernetes selector: <code>86edb2182817bb492751786aa8471732abadf8ab</code></p>"},{"location":"developer/architecture/rollout-device-selection/","title":"Rollout device selection","text":"<p>The rollout device selection is implemented as periodic reconciler that is invoked by the periodic server.</p> <p>The rollout device selection enables controlled, batch-based updates across device fleets. It works in conjunction with the disruption budget to ensure safe and manageable rollouts.</p> <p>Prerequisites: - Fleet must have a defined rollout policy with device selection criteria - Devices must be identified as out-of-date compared to the fleet's device specification</p> <p>The reconciler processes fleets that meet these criteria and manages the progression of updates through defined batches.</p> <p>The following chart describes a fleet reconcile flow:</p> <pre><code>flowchart TD\n    start((Start))\n    isRolloutNew{{Is Rollout New?}}\n    resetRollout[Reset Rollout]\n    isRolledOut{{Is Rolled Out?}}\n    approved{{Is Batch Approved?}}\n    approveAutomatically{{Approve Automatically?}}\n    approveBatch[Approve Batch]\n    notify[Initiate Batch Rollout]\n    isBatchComplete{{Is Batch Complete?}}\n    setSuccess[Set Success Percentage]\n    hasMore{{Has More Batches?}}\n    advanceBatch[Advance Batch]\n    finish((Finish))\n\n    start --&gt; isRolloutNew\n    isRolloutNew --&gt;|Yes| resetRollout\n    resetRollout --&gt; isRolledOut\n    isRolloutNew --&gt;|No| isRolledOut\n    isRolledOut --&gt;|Yes| isBatchComplete\n    isRolledOut --&gt;|No| approved\n    approved --&gt;|Yes| notify\n    approved --&gt;|No| approveAutomatically\n    approveAutomatically --&gt;|Yes| approveBatch\n    approveAutomatically --&gt;|No| finish\n    approveBatch --&gt; notify\n    notify --&gt; isBatchComplete\n    isBatchComplete --&gt;|No| finish\n    isBatchComplete --&gt;|Yes| setSuccess\n    setSuccess --&gt; hasMore\n    hasMore --&gt;|Yes| advanceBatch\n    advanceBatch --&gt; isRolledOut\n    hasMore --&gt;|No| finish\n</code></pre>"},{"location":"developer/architecture/rollout-disruption-budget/","title":"Disruption Budget","text":"<p>The disruption budget is implemented as a periodic reconciler that is invoked by the periodic server.</p> <p>All relevant fleets are reconciled using the following process: 1. A special query (count by labels) determines how many devices need to be rendered for each label key 2. Based on the disruption budget policy, a subset of devices is selected for rendering 3. Selected devices are sent for rendering while staying within budget constraints</p> <p>The following chart describes the high-level flow of fleet reconciliation by the disruption budget reconciler: <pre><code>flowchart TD\n   start((Start))\n   fleetCounts[Get Fleet Counts]\n   hasMoreCounts{{Has More Counts Per Labels?}}\n   computeNumToRender[Compute Num To Render]\n   sendForRendering[Send Device to Rendering]\n   devicesToRender{{Has Devices To Render?}}\n   finish((Finish))\n\n   start --&gt; fleetCounts\n   fleetCounts --&gt; hasMoreCounts\n   hasMoreCounts --&gt;|Yes| computeNumToRender\n   hasMoreCounts --&gt; |No| finish\n   computeNumToRender --&gt; devicesToRender\n   devicesToRender --&gt; |Yes| sendForRendering\n   devicesToRender --&gt; |No| hasMoreCounts\n   sendForRendering --&gt; devicesToRender</code></pre></p>"},{"location":"developer/architecture/service-observability/","title":"Service Observability","text":"<p>This guide explains how to instrument Flightctl services with OpenTelemetry tracing. It covers span creation, context propagation, and best practices for integrating tracing into service logic.</p>"},{"location":"developer/architecture/service-observability/#what-is-tracing","title":"What Is Tracing?","text":"<p>Tracing provides visibility into how requests flow through a distributed system. In OpenTelemetry, a trace represents a single request's path and is made up of multiple spans.</p>"},{"location":"developer/architecture/service-observability/#what-is-a-span","title":"What is a Span?","text":"<p>A span is a single unit of work or operation within a trace. It includes:</p> <ul> <li>A name (e.g., <code>create-device</code>)</li> <li>Duration</li> <li>Status (OK/Error)</li> <li>Attributes (metadata like <code>request.id</code>, SQL table, etc.)</li> <li>Parent/child relationships to form the full request flow</li> </ul>"},{"location":"developer/architecture/service-observability/#what-is-a-tracer","title":"What is a Tracer?","text":"<p>A tracer is the component responsible for creating spans. Each service or component can use a tracer (usually named) to start spans consistently. All spans are created using the global tracer provider.</p>"},{"location":"developer/architecture/service-observability/#tracer-initialization","title":"Tracer Initialization","text":"<p>All services should call <code>InitTracer()</code> during startup to configure the global OpenTelemetry tracer:</p> <pre><code>shutdown := InitTracer(log, cfg, \"flightctl-api\")\ndefer shutdown(ctx)\n</code></pre> <p>This function:</p> <ul> <li>Initializes an OTLP HTTP exporter using values from <code>config.yaml</code>.</li> <li>Configures the global tracer provider (<code>otel.SetTracerProvider</code>).</li> <li>Sets <code>TraceContext</code> propagation.</li> <li>Falls back to a no-op provider if tracing is disabled.</li> </ul> <p>[!NOTE] The <code>serviceName</code> argument can distinguish spans across components (e.g., <code>flightctl-api</code>, <code>flightctl-worker</code>).</p> <p>Be sure to call the shutdown function on app exit:</p> <pre><code>shutdown(ctx)\n</code></pre> <p>This flushes any remaining spans before exit.</p>"},{"location":"developer/architecture/service-observability/#creating-spans","title":"Creating Spans","text":"<p>Use the <code>StartSpan</code> helper to begin a new span:</p> <pre><code>ctx, span := StartSpan(ctx, \"flightctl/service\", \"CreateDevice\")\ndefer span.End()\n</code></pre> <p>This:</p> <ul> <li>Uses the global tracer</li> <li>Normalizes the span name to kebab-case (e.g., <code>create-device</code>)</li> <li>Maintains parent-child relationships via the context</li> </ul> <p>You can pass optional <code>trace.SpanStartOption</code> values such as <code>WithAttributes</code> or <code>WithLinks</code> to enrich the span with metadata or associate it with another context (e.g., for async task correlation):</p> <pre><code>receivedCtx, handlerSpan := instrumentation.StartSpan(\n  receivedCtx, \"flightctl/queues\", r.name, trace.WithLinks(\n    trace.LinkFromContext(ctx, attribute.String(\"request.id\", requestID))))\n</code></pre>"},{"location":"developer/architecture/service-observability/#instrumenting-services-example","title":"Instrumenting Services (Example)","text":"<p>The following is an example of how Flightctl uses a <code>TracedService</code> wrapper to consistently trace service logic. Each method is wrapped with standardized span handling:</p> <pre><code>func startSpan(ctx context.Context, method string) (context.Context, trace.Span) {\n    ctx, span := instrumentation.StartSpan(ctx, \"flightctl/service\", method)\n    return ctx, span\n}\n\nfunc endSpan(span trace.Span, st api.Status) {\n    span.SetAttributes(attribute.Int(\"status.code\", int(st.Code)))\n\n    if st != api.StatusOK() {\n        span.RecordError(errors.New(st.Message))\n        span.SetStatus(codes.Error, st.Message)\n    }\n\n    span.End()\n}\n\n// --- Example usage ---\nfunc (t *TracedService) ListCertificateSigningRequests(ctx context.Context, p api.ListCertificateSigningRequestsParams) (*api.CertificateSigningRequestList, api.Status) {\n    ctx, span := startSpan(ctx, \"ListCertificateSigningRequests\")\n    resp, st := t.inner.ListCertificateSigningRequests(ctx, p)\n    endSpan(span, st)\n    return resp, st\n}\n</code></pre>"},{"location":"developer/architecture/service-observability/#why-this-pattern-is-helpful","title":"Why this pattern is helpful","text":"<ul> <li>Reduces boilerplate in service logic</li> <li>Standardizes status and error reporting</li> <li>Keeps all span logic consistent and easy to audit</li> </ul>"},{"location":"developer/architecture/tasks/","title":"Asynchronous tasks in the service","text":"<p>The service aims to perform the minimum amount of work in the synchronous part of API calls, and offload work to asynchronous tasks.</p> <p>There are two types of tasks: event-based and periodic.</p>"},{"location":"developer/architecture/tasks/#event-based-tasks","title":"Event-based tasks","text":"<p>Tasks must be idempotent and not rely on ordering so that they can be delivered and retried without any race conditions. Tasks must be independent to avoid deadlocks.</p> <p>This flow chart depicts the tasks that each update to the store can trigger, and what store updates each task can trigger.</p> <pre><code>flowchart TD\n    FltTemplateUpdated[(Fleet template updated)] --&gt; FleetValidateTask[[FleetValidateTask]]\n    FltSelectorUpdated[(Fleet selector updated)] --&gt; FleetSelectorMatchTask[[FleetSelectorMatchTask]]\n    FltConfigSourceUpdated[(Fleet config source updated)] --&gt; FleetValidateTask[[FleetValidateTask]]\n    RepoUpdated[(Repository updated)] --&gt; RepositoryUpdatesTask[[RepositoryUpdatesTask]]\n    ReposDeleted[(All repositories deleted)] --&gt; RepositoryUpdatesTask[[RepositoryUpdatesTask]]\n    FleetsDeleted[(All fleets deleted)] --&gt; FleetSelectorMatchTask[[FleetSelectorMatchTask]]\n    DevsDeleted[(All devices deleted)] --&gt; FleetSelectorMatchTask[[FleetSelectorMatchTask]]\n    DevLabelsUpdated[(Device labels updated)] --&gt; FleetSelectorMatchTask[[FleetSelectorMatchTask]]\n    DevSpecUpdated[(Device spec updated)] --&gt; DeviceRenderTask[[DeviceRenderTask]]\n    DisruptionBudgetReconciler[(Disruption budget reconciler)] --&gt; DeviceRenderTask\n    DevConfigSourceUpdated[(Device config source updated)] --&gt; DeviceRenderTask[[DeviceRenderTask]]\n    TemplateVersionCreated[(TemplateVersion created)] --&gt; FleetRolloutTask[[FleetRolloutTask]]\n    DeviceSelectionReconciler[(Device selection reconciler)] --&gt; FleetRolloutTask\n    DevLabelsUpdated --&gt; FleetRolloutTask\n    DevOwnerUpdated[(Device owner updated)] --&gt; FleetRolloutTask\n\n    FleetRolloutTask --&gt; DevSpecUpdated\n    FleetSelectorMatchTask --&gt; DevOwnerUpdated\n    FleetValidateTask --&gt; TemplateVersionCreated\n    RepositoryUpdatesTask --&gt; FltConfigSourceUpdated\n    RepositoryUpdatesTask --&gt; DevConfigSourceUpdated</code></pre>"},{"location":"developer/architecture/tasks/#periodic-tasks","title":"Periodic tasks","text":"<ol> <li>Try to access each repository and update its Status.</li> <li>Check if each ResourceSync is up-to-date, and update resources if necessary.</li> <li>Perform device selection for fleet rollout according to the batches defined in the rollout policy</li> <li>Send devices to rendering according to the disruption budget defined in the rollout policy</li> </ol>"},{"location":"developer/enhancements/","title":"Enhancement Proposals","text":"<p>This section contains FlightCtl Enhancement Proposals (FEPs) - design documents that describe significant changes and new features for FlightCtl.</p>"},{"location":"developer/enhancements/#current-proposals","title":"Current Proposals","text":"<ul> <li>FEP-000: API Device Fleet - Device and fleet API design</li> <li>FEP-002: Remote Console - Remote console access for devices</li> </ul>"},{"location":"developer/enhancements/#about-enhancement-proposals","title":"About Enhancement Proposals","text":"<p>FlightCtl Enhancement Proposals (FEPs) are design documents that:</p> <ul> <li>Describe new features or significant changes to FlightCtl</li> <li>Provide technical specifications and implementation details</li> <li>Document the decision-making process for major changes</li> <li>Serve as a reference for future development</li> </ul>"},{"location":"developer/enhancements/#contributing-enhancement-proposals","title":"Contributing Enhancement Proposals","text":"<p>If you have ideas for significant improvements to FlightCtl:</p> <ol> <li>Review existing FEPs to avoid duplication</li> <li>Follow the FEP template (to be created)</li> <li>Submit your proposal as a pull request</li> <li>Engage with the community for feedback</li> </ol> <p>Enhancement proposals help ensure that major changes to FlightCtl are well-designed, thoroughly reviewed, and aligned with the project's goals. </p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/","title":"EP: Definition of the Fleet and Device API spec","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#summary","title":"Summary","text":"<p>The Device API, and Fleet API, and the dynamics of managing individual devices as well as fleets of devices is a fundamental piece of flightctl.</p> <p>The Fleet API must serve as a way to manage groups of devices while still allowing for the management of individual devices in a way that we can integrate with other management systems.</p> <p>During this RFE two logical controllers are mentioned: <code>device-controller</code> and <code>fleet-controller</code>, those are the logical pieces of our code-base in charge of maintaining the device rendered spec, and the device spec in relation to a fleet. Those controllers are not separate microservices, and this RFE does not mandate or request that.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#motivation","title":"Motivation","text":"<p>We need agreement on the API design direction and the semantics of the API to be able to implement and grow the flightctl service.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#goals","title":"Goals","text":"<ul> <li> <p>Define the format and behavior of the Device and Fleet APIs</p> </li> <li> <p>Allow the management of individual fleetless devices on a smaller scale   as an integration mechanism for services like AAP and ACM.</p> </li> <li> <p>Allow the management of fleets of devices on a larger scale, via gitops or API.</p> </li> <li> <p>Change API fields to provide a more consistent experience.</p> </li> <li> <p>Enable temporary/manual drift of fleet-managed devices for debug purposes.</p> </li> </ul>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#non-goals","title":"Non-Goals","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#proposal","title":"Proposal","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#general","title":"General","text":"<p>All resources containing ObjectMeta will include a <code>resourceVersion</code> field, this field is an opaque string that is updated on every change to the resource, it can be used for opportunistic concurrency control.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#device-api","title":"Device API","text":"<p>The device API is divided into multiple methods, some user-facing, and other device-facing, this design facilitates cleaner RBAC control of the endpoint access. The diagram is only intended to illustrate the flow of information between the user/system and the device.</p> <pre><code>block-beta\ncolumns 1\n  user([\"User\"])\n\n  space\n\n\n  block\n    frontEndpoint[\"/devices/{name}\"]\n  end\n\n  user --&gt; frontEndpoint\n  frontEndpoint --&gt; user\n\n  space\n  block\n    metadata\n    devSpec[\"spec\"]\n    devStatus[\"status\"]\n  end\n\n  space\n\n  frontEndpoint --&gt; metadata\n  frontEndpoint --&gt; devSpec\n  frontEndpoint --&gt; devStatus\n\n  block\n     renderedEndpoint[\"/devices/{name}/rendered\"]\n     statusEndpoint[\"/devices/{name}/status\"]\n  end\n\n  space\n\n  statusEndpoint --&gt; devStatus\n  statusEndpoint --&gt; devStatus\n  devSpec --&gt; renderedEndpoint\n  renderedEndpoint --&gt; Device\n  Device --&gt; statusEndpoint\n\n\n  Device([\"Device\"])\n\n  style frontEndpoint fill:#969,stroke:#333,stroke-width:4px\n  style renderedEndpoint fill:#969,stroke:#333,stroke-width:4px\n  style statusEndpoint fill:#969,stroke:#333,stroke-width:4px\n  ```\n\n#### `/devices/{name}` User facing method\n\nThis endpoint can be accessed by the user or external systems to\nmanage individual devices, also internally from the fleet specifications\nfor devices.\n\nThe proposed changes include:\n\n* Reincorporating device.spec as a visible part through this frontend API.\n\n* The `device.spec.os.image` contains a reference to the image to be used for the device.\n\n* The `device.spec.templateVersion` is removed. An annotation will be used to track the latest template applied to the\n  device. (See the fleet API section for more details)\n\n* The `device.spec.{containers, systemd}` fields are moved under `device.spec.monitoring.{containers, systemd}`\n\n* The `device.spec.monitoring.containers` contains a list of container patterns to be watched on the device (as in the fleet spec)\n\n* The `device.spec.monitoring.systemd` contains a list of systemd service patterns to be watched on the device (as in the fleet spec)\n\n* The `device.spec.config` contains a list of zero or more config items.\n\n* The config items could be inline definition of config files (`InlineConfigProviderSpec`)\n\n* Some config items reference external configurations (`KubernetesSecretProviderSpec`, `GitConfigProviderSpec`)\n\n* External references (image or config items) must support floating tags (`latest`, `main`, `v1.0`), although\n  **when managed from a fleet, the floating tags will be frozen as hashes** on the device spec by the\n  fleet controller.\n\n* Some external items are actually non-versioned like the K8s secrets, so are inherently floating.\n\n* The `device.status.conditions` field can be extended by the `device-controller` to provide\n  additional conditions related to management of the device related to the spec rendering (i.e.\n  A source referenced on the spec cannot be found, a reference is not accessible, pre-flight checks\n  related to an os-image aren't passing, etc..)\n  No other fields on the status or agent-related conditions could be written by the `device-controller`.\n\n\nComplete representation of the proposed device:\n\n```yaml\napiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: fab9839018890a88b898b980f8f809f8e8ac333761977d987a777a777a987ccce\n  labels:\n    site: factory-a\n    deviceType: optical-inspector\n    stage: production\n  annotations:\n    fleet-controller/templateVersion: \"optical-inspector-production-fleet-0000001\" # the fleet controller uses this annotation to track the latest template applied\n  owner: Fleet/optical-inspector-production-fleet\n  resourceVersion: \"somehash\" # provides opportunistic concurrency control\nspec:\n  os:\n    image: quay.io/redhat/rhde:9.2\n  config:\n    - name: rendered-config\n      configType: InlineConfigProviderSpec\n      inline:\n        ignition:\n          version: 3.4.0\n        storage:\n          files:\n            - contents:\n                source: &gt;-\n                  data:,This%20system%20is%20managed%20by%20flightctl.%0A\n              mode: 422\n              overwrite: true\n              path: \"/etc/motd\"\n\n    - name: config-from-git\n      configType: GitConfigProviderSpec\n      repository: my-repo\n      ref: v1.0.0\n      path: /path/to/config/in/git\n\n    - name: config-from-k8s-secret\n      configType: KubernetesSecretProviderSpec\n      name: my-secret\n      namespace: my-namespace\n      mountPath: /path/to/config/in/device\n\n  monitoring:\n    containers:\n      matchPatterns:\n        - *my-container*\n        - *another-container*\n\n    systemd:\n      matchPatterns:\n        - chronyd.service\n        - firewalld.service\n        - sshd*.service\n\nstatus:\n  conditions: # NOTE: The conditions will probably need a full definition/documentation/possible adjustments\n  - lastTransitionTime: \"2024-04-30T15:06:20Z\"\n    message: All is good\n    reason: AsExpected\n    status: \"False\"\n    type: Progressing\n  - lastTransitionTime: \"2024-04-30T15:06:19Z\"\n    message: All is good\n    reason: AsExpected\n    status: \"True\"\n    type: Available\n  containers:\n    - id: fa31890ae222449abb00ff90ed801674\n      name: my-container\n      status: running\n      image: quay.io/myorg/myimage:v1.0.0\n      engine: podman\n  systemdUnits:\n    - name: chronyd.service\n      loadState: running     #Q: those fields need clatification, not obvious what they mean\n      activeState: active\n    - name: sshd.service\n      loadState: running\n      activeState: active\n  systemInfo: # The systemInfo field will likely change in future RFEs, i.e. measurements will probably\n              # go away or change format (to provide specific quotes for specific PCRs)\n    architecture: arm64\n    bootID: 87f7e27e-bdc0-42b1-b909-6dc81fe43ea2\n    machineID: fa31890ae222449abb00ff90ed801674\n    measurements:\n      pcr01: \"0000000000000000000000000000000000000000000000000000000000000000\"\n      ...\n      pcr16: \"0000000000000000000000000000000000000000000000000000000000000000\"\n    operatingSystem: linux\n  updatedAt: \"2024-04-30T15:06:19Z\"</code></pre>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#device-state-regarding-fleet-managment","title":"Device state regarding fleet managment","text":"<p>This diagram illustrates what the following sections describe in text. <pre><code>stateDiagram-v2\n    state \"&lt;b&gt;Individual Device&lt;/b&gt;&lt;br/&gt;&lt;b&gt;owner&lt;/b&gt;: nil (API writable)&lt;br/&gt;&lt;b&gt;spec:&lt;/b&gt; user writable // unmanaged\" as Individual_Device\n    state \"&lt;b&gt;Fleet Device&lt;/b&gt;&lt;br/&gt;&lt;b&gt;owner&lt;/b&gt;: Fleet/the-matching-fleet&lt;br/&gt;&lt;b&gt;spec&lt;/b&gt;: fleet-controller writable // managed\" as Fleet_Device\n    state \"&lt;b&gt;Fleet Device (paused/owner released)&lt;/b&gt;&lt;br/&gt;&lt;b&gt;owner&lt;/b&gt;: nil&lt;br/&gt;&lt;b&gt;spec&lt;/b&gt;: user writable // management paused\" as Fleet_Paused\n    [*] --&gt; Individual_Device\n    Individual_Device --&gt; Fleet_Device : matching fleet labels &amp;&amp; owner == nil\n    Fleet_Device --&gt; Individual_Device : no matching fleet labels\n    Fleet_Device --&gt; Fleet_Paused : flightctl.io/fleet-controller=paused\n    Fleet_Paused--&gt; Fleet_Device: ! flightctl.io/fleet-controller=paused\n    Fleet_Paused--&gt; Individual_Device: no matching fleet labels</code></pre></p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#devicesname-with-no-owner-fleet-individual-device","title":"<code>/devices/{name}</code> with no owner fleet (Individual Device)","text":"<p>Devices with no matching labels to a fleet are manually managed and start with no <code>metadata.owner</code> reference; the fleet controller will not attempt to reconcile or configure the device in any way.</p> <p>Ownership of a device can be claimed through the API by setting the <code>metadata.owner</code> field to <code>{owner}/{additional data}</code>, i.e. the fleet-controller can claim a device by setting <code>Fleet/fleet-name</code>. </p> <p><code>metadata.owner</code> is a protected field, specific owners can only be set through the API with specific authentication, i.e. we could use a specific attribute of the X.509 TLS certificate to contain the owner identity, or be passed as a header from the API gateway. This means that the fleet-controller is the only one being able to claim a device to Fleet/ or to release a device claimed by a fleet.</p> <p>External controllers dealing with devices can only set the <code>metadata.owner</code> field to the authentication-allowed {owner} namespace.</p> <p>If a fleet matches this device, and the device has empty <code>metadata.owner</code> the fleet controller will claim the device, by setting <code>metadata.owner</code> to <code>Fleet/{fleet-name}</code>.</p> <p>If a fleet stops matching a device or if the fleet controller is paused on a device, <code>metadata.owner</code> is cleared by the fleet controller, and the device becomes manually managed.</p> <p>The <code>os.image</code> and configuration fields in this API support floating tags, and while the fleet manager does freeze the tags to hashes, the user is free to setup the device spec with floating references.</p> <p>Every time the device is updated in any way, the <code>metadata.resourceVersion</code> field is updated.</p> <p>Every time the device spec changes, the device controller will generate a new device rendered configuration, and update the <code>metadata.annotation['renderedVersion']</code> field.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#expected-behavior-regarding-external-references-with-floating-tags","title":"Expected behavior regarding external references with floating tags","text":"<p>Changes on external references are monitored and acted on (git branches, device images, secrets), the device controller should re-evaluate the device spec and apply the changes to the rendered version which will be exposed on the <code>/devices/{name}/rendered</code> endpoint.</p> <p>Every time the rendered output changes due to changes on external references, the <code>metadata.annotation['renderedVersion']</code> is updated this detail is exposed via the <code>/devices/{name}/rendered</code> endpoint. <code>renderedVersion</code> is monotonically increasing and can be used to track changes to the device spec, as well as easily understood by a human observer.</p> <p>Several mechanisms can be used to track external references: * Polling * Webhooks</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#devicesname-while-managed-by-a-fleet-fleet-device","title":"<code>/devices/{name}</code> while managed by a fleet (Fleet Device)","text":"<p>When managing a device through a fleet, flightctl is responsible for maintaining the device spec in sync with the fleet spec; in this case write access is only possible for the modification of labels and other metadata through this API except for the owner fleet.</p> <p>[!NOTE] Devices managed by a fleet have their floating tags resolved to stable hashes at this API level. This is done to ensure that the device is always in sync with the fleet spec.</p> <p>The device will have an owner reference to the managing fleet, i.e.:</p> <pre><code>  owner: Fleet/optical-inspector-production-fleet\n</code></pre>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#devicesnamerendered-device-and-user-read-only","title":"<code>/devices/{name}/rendered</code> (device and user read-only)","text":"<p>This endpoint is used by the device agent to retrieve the rendered device spec, this endpoint is read-only, each device can only access it's own device rendered spec based on the device certificate identification, a user with admin privileges can access any device rendered spec for debug purposes.</p> <p>The agent can pass: <code>knownRenderedVersion</code>, this is compared to the <code>renderedVersion</code> device annotation, if this opaque field has not changed the API will return 204 No Content, if the field has changed, the API will return the rendered spec.</p> <p>Change proposed: * The parameter name <code>knownOwner</code> is removed. * The parameter name <code>knownTemplateVersion</code>is renamed to <code>knownRenderedVersion</code>.</p> <p>Behavior changes: * If a device configuration is not yet available for rendering (e.g. because it is still  being fetched from the configuration source), FC will queue the device for rendering and instruct   the device to try again later by returning 202 Accepted.</p> <p>The user can find the fully rendered device spec by using the following CLI command: <pre><code>flightctl get device/xxxxxxx --rendered\n</code></pre></p> <p>or</p> <pre><code>flightctl get device/xxxxxxx --rendered -o json\n</code></pre>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#devicesnamestatus-device-side","title":"<code>/devices/{name}/status</code> (device side)","text":"<p>This endpoint is used by the device agent to report the status of the device, this endpoint is write-only, each device can only access it's own device status based on the device certificate identification.</p> <p>The result of this write will be exposed on the <code>/devices/{name}</code> endpoint as part of the status field, the status conditions reported from the agent are merged on the <code>/devices/{name}</code> endpoint at read in a way that the user can see the status of the device and the controller status conditions in a single view (See the design details section for more information).</p> <p>Reporting to this endpoint also serves as a heartbeat mechanism, the device agent should report the status, if a device agent stops reporting to this endpoint in the expected timelines, the device will be considered offline.</p> <p>Via this endpoint, the device agent reports <code>renderedVersion</code> instead of <code>templateVersion</code> to indicate the currently applied configuration.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#fleet-api","title":"Fleet API","text":"<p>Fleet is an automation layer on top of Device API, the DeviceTemplate is a mechanism to control drift and enforce policy across devices in a fleet.</p> <p>A DeviceTemplate is a template for a device spec, it's a way to define group specific configuration.</p> <p>We are proposing extension mechanisms to this API to allow for more complex configurations where device labels or name would influence the configuration generated to the device.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#fleetsname-user-facing","title":"<code>/fleets/{name}</code> (user facing)","text":"<p>This endpoint provides read/write access to fleets.</p> <p>Full example of fleet:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Fleet\nmetadata:\n  creationTimestamp: \"2024-04-30T14:06:17Z\"\n  generation: 1\n  labels: {}\n  name: optical-inspector-production-fleet\n  owner: ResourceSync/basic-nginx-r3sourcesync\nspec:\n  selector:\n    matchLabels:\n      device: optical-inspector\n  template:\n    metadata:\n      generation: 1\n    spec:\n      config:\n      - configType: InlineConfigProviderSpec\n        inline:\n          ignition:\n            version: 3.4.0\n          storage:\n            files:\n            - contents:\n                source: data:,This%20system%20is%20managed%20by%20flightctl.%0A\n              mode: 422\n              overwrite: true\n              path: /etc/motd\n        name: motd-update\n      - configType: GitConfigProviderSpec\n        gitRef:\n          path: /basic-nginx-demo/configuration\n          repository: basic-nginx-d3mo\n          targetRevision: demo\n        name: microshift-manifests\n      - configType: GitConfigProviderSpec\n        gitRef:\n          path: /configuration\n          repository: ricky-super-secrets\n          targetRevision: main\n        name: ricky-super-secrets\n      os:\n        image: quay.io/flightctl/flightctl-agent-basic-nginx:latest\n      monitoring:\n        systemd:\n          matchPatterns:\n          - microshift.service\n          - crio.service\n          - flightctl-agent.service\nstatus:\n  conditions:\n  - lastTransitionTime: \"2024-05-09T14:20:21Z\"\n    status: \"False\"\n    type: OverlappingSelectors\n</code></pre>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#expected-behavior","title":"Expected behavior","text":"<p>[!NOTE] This section dives into the implementation details of the fleet controller, the <code>TemplateVersion</code> is an internal object that is used to track changes to fleet spec device templates and source references. It is useful to provide an audit trail of the changes to the fleet templates and sources. It's also useful to enable implementations where offline devices can traverse a history of configurations to reach the current state.</p> <p>When <code>fleet.spec.template</code> is updated the Fleet deployment changes, a copy of the device template is stored as a <code>TemplateVersion</code> object. This object freezes a copy of the template and also creates a list of external references (like git refs, image tags, etc..) that are floating tags by scanning all fleet devices, these floating tags are resolved to stable hashes and stored in (or along) the <code>TemplateVersion</code> object.</p> <p>When a previously frozen source changes, a new copy of <code>TemplateVersion</code> object is created with the updated source reference.</p> <p>If an error happens during the creation of the <code>TemplateVersion</code> object, the fleet controller will mark a status condition on the fleet object (e.g. missing sources, missing floating tags, etc..), and the fleet controller will not proceed with the rollout.</p> <p>Once a <code>TemplateVersion</code> is created the fleet controller starts rolling out that update to devices. This update can take a long time (depending on the upgrade strategy). The fleet controller marks the latest template version that is being rolled out, as a <code>fleet-controller/templateVersion</code> annotation in the fleet for observability through the API.</p> <p>When a template is applied to a specific device via the Device API: * Floating tags for external references (os image, git refs, etc..) get converted to stable tags (hashes),   this gives flightctl the ability to check images being deployed on devices before the device could auto pick-up   a floating tag. (i.e. checks verifying the installation of the flightctl agent, and configuration) * When later in time a device has labels updated, the device controller will queue the device to be re-evaulated,   for example if a change of fleet owner happens because of the label changes. * An <code>annotation</code> is added to the device in the form of <code>fleet-controller/templateVersion</code> to track   the latest <code>TemplateVersion</code> applied to the device.</p> <p>TemplateVersions are exposed via the API as read-only objects, they can be used to track changes to the fleet spec and the external references that were frozen on the devices:</p> <ul> <li><code>/fleets/{name}/templateversions</code> - This endpoint enables listing and cleanup of                                      <code>TemplateVersion</code> objects. Allows filtering by labels.</li> <li><code>/fleets/{name}/templateversions/{version}</code> - This endpoint returns a specific <code>TemplateVersion</code> object for the fleet.</li> </ul>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#device-management-within-a-fleet","title":"Device management within a fleet","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#removing-a-device-from-a-fleet","title":"Removing a device from a fleet","text":"<p>A device could be stripped from the labels associating it to a specific fleet, in such case the <code>metadata.owner</code> field will be cleared by the fleet controller, and the device spec will need to be manually managed or eventually associated to a different fleet/owner.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#changing-a-device-to-a-different-fleet","title":"Changing a device to a different fleet","text":"<p>A device could be moved to a different fleet, in such case the <code>metadata.owner</code> field will be updated by the fleet controller, and the device will be managed by the new fleet.</p> <p>This can be performed by modifying device labels to match a new fleet or modifying the fleet's device selector.</p> <p>The fleet controller will apply the latest <code>TemplateVersion</code> for the new fleet to the device.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#temporarily-disabling-fleet-management-fleet-device-paused","title":"Temporarily disabling fleet management (Fleet Device paused)","text":"<p>A user can temporarily stop fleet management of a device by setting the <code>fleet-controller=paused</code> in the device labels, the fleet manager will ignore devices with this label for any subsequent update or rollout.</p> <p>This feature is intended to allow temporarily debugging a device. To allow non-fleet writes the fleet controller will clear the <code>metadata.owner</code> field, and the device will be manually managed.</p> <p>We would know that a device belongs to a fleet because of the labels, but the <code>metadata.owner</code> field would be empty.</p> <p>At this point the device will not receive updates from new <code>TemplateVersions</code> generated from a fleet, and the API will allow editing the device spec.</p> <p>When a fleet selected device has the <code>fleet-controller=paused</code> label removed the fleet controller will reclaim ownership of the device by setting the <code>metadata.owner</code> field and then it will roll-out the latest <code>TemplateVersion</code> to the device, or a series of template versions if the policies and fleet controller implement that.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#resource-versioning-and-propagation","title":"Resource versioning and propagation","text":"<p>Fleets provide an annotation in the form of <code>fleet-controller/templateVersion</code>, this field is used to track the TemplateVersion that is being rolled out to devices.</p> <p>When the fleet controller applies a template to a device, this is tracked transparently through the <code>fleet-controller/templateVersion</code> on the device metadata, in this case this annotation will reference the latest applied <code>TemplateVersion</code> from the owning fleet.</p> <p>In addition devices have a <code>renderedVersion</code> annotation in metadata, this field is used to track changes to the resulting rendered spec seen by the device, this field can change under the following circumstances:</p> <ul> <li>The device spec has been modified by the fleet controller or the user:</li> <li>Due to changes in the fleet template.</li> <li>Due to changes in floating changes referenced by the fleet template, but frozen on the device spec</li> <li>Due to changes of fleet</li> <li> <p>Due to changes in labels (see PR#248)</p> </li> <li> <p>The device render has been re-rendered due to changes in floating tags or external references   directly applied on the device spec (e.g. when a device is individually managed).</p> </li> </ul>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#examples-of-resource-propagation","title":"Examples of resource propagation","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#fleet-template-changes","title":"Fleet template changes","text":"<p>1) A fleet.spec.template changes. 2) A new <code>TemplateVersion</code> object is created. 3) The <code>fleet-controller/templateVersion</code> annotation is updated on the fleet. 4) The fleet controller starts rolling out the new template to devices. 5) When a device is applied the new template, the <code>fleet-controller/templateVersion</code> annotation is added to the device. 6) The device controller re-renders the device spec and updates the <code>renderedVersion</code> annotation. 7) The device finds a new rendered spec via the <code>/devices/{name}/rendered</code> endpoint. 8) The device controller reports the new <code>renderedVersion</code> on the <code>/devices/{name}/status</code> endpoint.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#external-fleet-references-changes","title":"External fleet references changes","text":"<p>1) A fleet external reference changes (e.g. a git ref, or an image tag). 2) A new <code>TemplateVersion</code> object is created, with the updated reference. 3) The <code>fleet-controller/templateVersion</code> annotation is updated on the fleet. 4) The fleet controller starts rolling out the new template to devices. 5) When a device is applied the new template, the <code>fleet-controller/templateVersion</code> annotation is added to the device. 6) The device controller re-renders the device spec and updates the <code>renderedVersion</code> annotation. 7) The device finds a new rendered spec via the <code>/devices/{name}/rendered</code> endpoint. 8) The device controller reports the new <code>renderedVersion</code> on the <code>/devices/{name}/status</code> endpoint.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#external-device-reference-changes","title":"External device reference changes","text":"<p>1) A device external reference changes (e.g. a git ref, or an image tag). 2) The device controller re-renders the device spec and updates the <code>renderedVersion</code> annotation. 3) The device finds a new rendered spec via the <code>/devices/{name}/rendered</code> endpoint. 4) The device controller reports the new <code>renderedVersion</code> on the <code>/devices/{name}/status</code> endpoint.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#device-spec-changes","title":"Device spec changes","text":"<p>1) A device spec changes. 2) The device controller re-renders the device spec and updates the <code>renderedVersion</code> annotation. 3) The device finds a new rendered spec via the <code>/devices/{name}/rendered</code> endpoint. 4) The device controller reports the new <code>renderedVersion</code> on the <code>/devices/{name}/status</code> endpoint.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#user-stories","title":"User Stories","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#story-1","title":"Story 1","text":"<p>As an IT user, I want to manage several devices used for different purposes, those devices don't share the similar configuration and image with other devices.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#story-2","title":"Story 2","text":"<p>As an IT user, I want to manage a small number of MicroShift devices individually via RHACM, similar to how I manage OpenShift clusters and SNOs.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#story-3","title":"Story 3","text":"<p>As an IT user, I want to manage several RHEL devices declaratively via AAP, so I can orchestrate very complex update workflows.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#story-4","title":"Story 4","text":"<p>As an IT user, I want to be able to easily get a device\u2019s spec via the CLI, so I can compare it with the device template and verify how external references have been frozen.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#story-5","title":"Story 5","text":"<p>As an IT user, I want to pause fleet management on specific devices, so I can perform manual changes on the spec for debugging purposes without the fleet controller rolling back the changes.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#notesconstraintscaveats","title":"Notes/Constraints/Caveats","text":"<p>Devices don't keep track of the rendered specs and sources over time. This could be captured so far by emitting event logs. This could be extended in the feature to provide better traceability but it's left out of scope because when devices are managed by a Fleet this is already being captured as TemplateVersions, and capturing it again on devices would be redundant and impact scalability.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#risks-and-mitigations","title":"Risks and Mitigations","text":"<p>TemplateVersions could accumulate and grow in size, we need to have a mechanism to clean up old versions, or to archive them into an audit trail when those template versions aren't necessary anymore for a device.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#design-details","title":"Design Details","text":"<p>We have some design details in the proposal, all references to <code>TemplateVersion</code> is a design detail outside of the core Fleet/API spec, but necessary to define expected behavior.</p> <p>The device reporting to the <code>/devices/{name}/status</code> includes conditions that are stored in a separate field in the device database, then those conditions are merged with the status field on the device spec read from the <code>/devices/{name}</code> endpoint. This is useful to provide the agent the ability to clear/remove conditions by just not posting them to the status endpoint during an update.</p>"},{"location":"developer/enhancements/fep-000-api-device-fleet/#scalability","title":"Scalability","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#implementation-history","title":"Implementation History","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#drawbacks","title":"Drawbacks","text":""},{"location":"developer/enhancements/fep-000-api-device-fleet/#alternatives","title":"Alternatives","text":""},{"location":"developer/enhancements/fep-002-remote-console/","title":"EP: Remote console access to devices","text":""},{"location":"developer/enhancements/fep-002-remote-console/#summary","title":"Summary","text":"<p>This enhancement proposal defines a new API endpoint to provide remote console access to devices.</p>"},{"location":"developer/enhancements/fep-002-remote-console/#motivation","title":"Motivation","text":"<p>Under some circumstances administrators may need access to the devices for debugging purposes. Some complex issues may require direct access to the device console to troubleshoot the problem, then once the issue is identified and resolved, the remediation can be applied at the fleet level.</p>"},{"location":"developer/enhancements/fep-002-remote-console/#goals","title":"Goals","text":"<ul> <li>Define the API for remote console access to devices.</li> <li>Provide a way to access the device console from the API.</li> <li>Provide a way to access the device console from the CLI.</li> <li>Provide a way to access the device console from the UI.</li> <li>Make this feature opt-in and configurable in the agent.</li> <li>Ensure that audit logs are generated for all console access.</li> </ul>"},{"location":"developer/enhancements/fep-002-remote-console/#non-goals","title":"Non-Goals","text":""},{"location":"developer/enhancements/fep-002-remote-console/#proposal","title":"Proposal","text":"<p>The commit where this RFE is posted provides an interim implementation of the feature, which while functional, is not complete.</p>"},{"location":"developer/enhancements/fep-002-remote-console/#to-dos","title":"TO-DOs:","text":"<ul> <li>Check if protoc compilation can be performed with //go:generate like the rest of the APIs.</li> <li> <p>Use buf for protobuf compilation as it has more powerful lintig capabilities and can   detect changes breaking older clients.</p> </li> <li> <p>Make sure that a new console session, while one is happening is either: blocked, shared, or   kills the previous one (--force flag/query parameter?)</p> </li> <li> <p>In the interim solution we offer an endpoint to request a console, that provides a grpc endpoint   and a session ID. The GRPC endpoint is on the agent api-side under a different authentication   realm (mTLS). In the final solution we should have a ws method <code>/ws/devices/{name}/console</code> which   directly drop us into a console, or denies access based on permissions.</p> </li> <li> <p>An administrator can forcedfully close existing console connections.</p> </li> <li> <p>The proof-of-concept relies on the fact that both, client and server connect to the same gRPC endpoint   and process, making the data stream possible. In the final implementation the agent service must   be a separate pod, and the frontend API and the agent service must communicate through rabbitmq   (i.e. using ephemeral queues/exchanges for session communication, based on session ID)</p> </li> <li> <p>Sessions should be tracked with timeouts. I.e. if a session is requested but one end does not   connect, it should timeout and be cleaned up from server.</p> </li> </ul>"},{"location":"developer/enhancements/fep-002-remote-console/#general","title":"General","text":""},{"location":"developer/enhancements/fep-002-remote-console/#user-stories","title":"User Stories","text":""},{"location":"developer/enhancements/fep-002-remote-console/#story-1","title":"Story 1","text":""},{"location":"developer/enhancements/fep-002-remote-console/#notesconstraintscaveats","title":"Notes/Constraints/Caveats","text":""},{"location":"developer/enhancements/fep-002-remote-console/#risks-and-mitigations","title":"Risks and Mitigations","text":""},{"location":"developer/enhancements/fep-002-remote-console/#design-details","title":"Design Details","text":""},{"location":"developer/enhancements/fep-002-remote-console/#scalability","title":"Scalability","text":""},{"location":"developer/enhancements/fep-002-remote-console/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer/enhancements/fep-002-remote-console/#implementation-history","title":"Implementation History","text":""},{"location":"developer/enhancements/fep-002-remote-console/#drawbacks","title":"Drawbacks","text":""},{"location":"developer/enhancements/fep-002-remote-console/#alternatives","title":"Alternatives","text":""},{"location":"user/","title":"Flight Control User Documentation","text":"<p>Welcome to the Flight Control user documentation.</p> <p>Introduction - An introduction to the project, basic concepts, and Flight Control's high-level architecture.</p> <p>Getting Started - How to get started with Flight Control by deploying the service and enrolling your first device.</p> <p>Using Flight Control - How to manage individual and fleets of devices with Flight Control.</p> <ul> <li>Building Images - How to build your own OS images and publish them to a container registry.</li> <li>Understanding OS Images and the Image Build Process</li> <li>Building and Publishing OS Images and Disk Images</li> <li>Considerations for Specific Target Platforms<ul> <li>Red Hat OpenShift Virtualization</li> <li>VMware vSphere</li> </ul> </li> <li>Best Practices</li> <li>Provisioning Devices - How to provision a device with an OS image.</li> <li>Testing an OS image on a developer machine</li> <li>Provisioning Physical Devices</li> <li>Provisioning on Red Hat OpenShift Virtualization</li> <li>Provisioning on VMware vSphere</li> <li>Managing Devices - How to manage individual devices.</li> <li>Enrolling Devices</li> <li>Viewing the Device Inventory and Device Details</li> <li>Organizing Devices</li> <li>Updating the OS</li> <li>Managing OS Configuration</li> <li>Managing Applications</li> <li>Using Device Lifecycle Hooks</li> <li>Monitoring Device Resources</li> <li>Accessing Devices Remotely</li> <li>Scheduling Updates and Downloads</li> <li>Alerts and Monitoring - How to monitor device health and manage alerts.</li> <li>Managing Device Fleets - How to manage fleets of devices.</li> <li>Understanding Fleets</li> <li>Selecting Devices into a Fleet</li> <li>Defining Device Templates</li> <li>Defining Rollout Policies</li> <li>Managing Fleets Using GitOps</li> <li>Solving Specific Use Cases - How to solve specific use cases in Flight Control.</li> <li>Auto-Registering Devices with MicroShift into ACM</li> <li>Adding Device Observability</li> </ul> <p>Administrating Flight Control - How to deploy and administrate a Flight Control service.</p> <ul> <li>Installing and Configuring the Flight Control Service and UI</li> <li>Configuring Flight Control to use k8s auth</li> <li>Installing the Flight Control CLI</li> <li>Using the Flight Control CLI</li> <li>Configuring the Flight Control Agent</li> <li>Troubleshooting</li> </ul> <p>References - Useful references.</p> <ul> <li>API Resources</li> <li>Device Status Definitions</li> </ul>"},{"location":"user/alerts/","title":"Flight Control Alerts","text":"<p>Flight Control provides built-in alerting capabilities that automatically monitor your edge devices and notify you when issues occur. This system processes events from your devices and forwards them to Alertmanager for distribution.</p>"},{"location":"user/alerts/#overview","title":"Overview","text":"<p>The Flight Control alerting system consists of three main components:</p> <ol> <li>Alert Exporter: Processes Flight Control events and converts them to Prometheus-compatible alerts</li> <li>Alertmanager Proxy: Provides authenticated access to Alertmanager using Flight Control credentials</li> <li>Alertmanager: Handles alert routing, grouping, silencing, and notification delivery</li> </ol>"},{"location":"user/alerts/#supported-alert-types","title":"Supported Alert Types","text":"<p>Flight Control automatically generates alerts for the following conditions:</p>"},{"location":"user/alerts/#device-status-alerts","title":"Device Status Alerts","text":"<ul> <li>Device Disconnected: Triggered when a device loses connection to Flight Control</li> <li>Device Connected: Automatically resolves disconnection alerts when devices reconnect</li> </ul>"},{"location":"user/alerts/#resource-usage-alerts","title":"Resource Usage Alerts","text":"<ul> <li>CPU Alerts:</li> <li><code>DeviceCPUCritical</code>: CPU usage exceeds critical threshold</li> <li><code>DeviceCPUWarning</code>: CPU usage exceeds warning threshold</li> <li> <p><code>DeviceCPUNormal</code>: Resolves CPU alerts when usage returns to normal</p> </li> <li> <p>Memory Alerts:</p> </li> <li><code>DeviceMemoryCritical</code>: Memory usage exceeds critical threshold</li> <li><code>DeviceMemoryWarning</code>: Memory usage exceeds warning threshold</li> <li> <p><code>DeviceMemoryNormal</code>: Resolves memory alerts when usage returns to normal</p> </li> <li> <p>Disk Alerts:</p> </li> <li><code>DeviceDiskCritical</code>: Disk usage exceeds critical threshold</li> <li><code>DeviceDiskWarning</code>: Disk usage exceeds warning threshold</li> <li><code>DeviceDiskNormal</code>: Resolves disk alerts when usage returns to normal</li> </ul>"},{"location":"user/alerts/#application-alerts","title":"Application Alerts","text":"<ul> <li>Application Status:</li> <li><code>DeviceApplicationError</code>: Application is in error state</li> <li><code>DeviceApplicationDegraded</code>: Application is running but degraded</li> <li><code>DeviceApplicationHealthy</code>: Resolves application alerts when healthy</li> </ul>"},{"location":"user/alerts/#lifecycle-alerts","title":"Lifecycle Alerts","text":"<ul> <li>Resource Deletion: Automatically resolves all alerts when a device or resource is deleted</li> <li>Device Decommissioning: Resolves all alerts when a device is decommissioned</li> </ul>"},{"location":"user/alerts/#alert-states","title":"Alert States","text":""},{"location":"user/alerts/#active-alerts","title":"Active Alerts","text":"<p>Alerts are considered active when:</p> <ul> <li>The triggering condition is present (e.g., device disconnected, high CPU usage)</li> <li>No resolving event has been received</li> <li>The device/resource still exists</li> </ul>"},{"location":"user/alerts/#resolved-alerts","title":"Resolved Alerts","text":"<p>Alerts are automatically resolved when:</p> <ul> <li>A resolving event is received (e.g., <code>DeviceConnected</code>, <code>DeviceCPUNormal</code>)</li> <li>The device or resource is deleted</li> <li>The device is decommissioned</li> </ul>"},{"location":"user/alerts/#accessing-alerts","title":"Accessing Alerts","text":""},{"location":"user/alerts/#prerequisites","title":"Prerequisites","text":"<p>Flight Control alerts are accessible through the Alertmanager proxy, which requires authentication. You'll need:</p> <ol> <li>Valid Flight Control credentials (token-based authentication)</li> <li>Network access to the Flight Control deployment</li> <li>Proper permissions to view alerts for your organization/devices</li> </ol>"},{"location":"user/alerts/#authentication-setup","title":"Authentication Setup","text":"<ol> <li>Get your authentication token (varies by auth method):</li> <li> <p>OIDC: Obtain token from your identity provider or FlightCtl client config:</p> <pre><code># Extract token from FlightCtl client config\nTOKEN=$(grep '^  token:' ~/.config/flightctl/client.yaml | awk '{print $2}')\n</code></pre> </li> <li> <p>OpenShift: Use <code>oc whoami -t</code> command</p> </li> <li> <p>AAP: Use your AAP Gateway token</p> </li> <li> <p>Access the Web UI:</p> </li> <li>In your browser, navigate to the alertmanager proxy URL:<ul> <li>External: <code>https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443</code></li> <li>Example: <code>https://flightctl-alertmanager-proxy.example.com:8443</code></li> </ul> </li> <li>Note: Browser-based authentication with bearer tokens requires additional setup (like browser extensions or proxy tools)</li> <li> <p>Alternative: Use API access (see examples below) or tools like curl for programmatic access</p> </li> <li> <p>Test connectivity (optional):</p> </li> </ol> <pre><code># Test that the proxy is accessible and your token works\ncurl -H \"Authorization: Bearer &lt;your-token&gt;\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/status\n</code></pre>"},{"location":"user/alerts/#practical-examples","title":"Practical Examples","text":"<p>For Web UI Access:</p> <pre><code># Your alertmanager proxy URL (replace with your domain):\n# https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443\n</code></pre> <p>For API/Programmatic Access:</p> <pre><code># Extract your FlightCtl token\nTOKEN=$(grep '^  token:' ~/.config/flightctl/client.yaml | awk '{print $2}')\n\n# Test connection\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/status\n\n# Get all alerts\ncurl -H \"Authorization: Bearer $TOKEN\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/alerts\n</code></pre>"},{"location":"user/alerts/#using-the-api","title":"Using the API","text":"<p>Query active alerts programmatically:</p> <pre><code># List all active alerts (external access)\ncurl -H \"Authorization: Bearer &lt;your-token&gt;\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/alerts\n\n# Filter alerts by device\ncurl -H \"Authorization: Bearer &lt;your-token&gt;\" \\\n     \"https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/alerts?filter=resource=my-device\"\n\n# Filter alerts by type\ncurl -H \"Authorization: Bearer &lt;your-token&gt;\" \\\n     \"https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/alerts?filter=alertname=DeviceDisconnected\"\n</code></pre>"},{"location":"user/alerts/#configuration","title":"Configuration","text":""},{"location":"user/alerts/#alert-polling-interval","title":"Alert Polling Interval","text":"<p>Configure how frequently Flight Control checks for new events to generate alerts:</p> <pre><code># In your Flight Control configuration\nservice:\n  alertPollingInterval: \"30s\"  # Check for new events every 30 seconds\n</code></pre>"},{"location":"user/alerts/#alertmanager-integration","title":"Alertmanager Integration","text":"<p>Flight Control automatically connects to Alertmanager when deployed. The connection is configured via:</p> <pre><code># In your Flight Control configuration\nalertmanager:\n  hostname: \"flightctl-alertmanager\"\n  port: 9093\n</code></pre>"},{"location":"user/alerts/#enablingdisabling-components","title":"Enabling/Disabling Components","text":"<p>Control which alert components are deployed:</p> <pre><code># In Helm values.yaml\nalertExporter:\n  enabled: true  # Set to false to disable alert generation\n\nalertmanagerProxy:\n  enabled: true  # Set to false to disable authenticated access\n\nalertmanager:\n  enabled: true  # Set to false to disable Alertmanager entirely\n</code></pre>"},{"location":"user/alerts/#notification-setup","title":"Notification Setup","text":"<p>Flight Control uses Prometheus Alertmanager for notifications. Configure notification channels in your Alertmanager configuration:</p>"},{"location":"user/alerts/#email-notifications","title":"Email Notifications","text":"<pre><code># alertmanager.yml\nglobal:\n  smtp_smarthost: 'smtp.example.com:587'\n  smtp_from: 'flightctl@example.com'\n\nroute:\n  group_by: ['alertname']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 1h\n  receiver: 'email-notifications'\n\nreceivers:\n- name: 'email-notifications'\n  email_configs:\n  - to: 'admin@example.com'\n    subject: 'Flight Control Alert: {{ .GroupLabels.alertname }}'\n    body: |\n      {{ range .Alerts }}\n      Alert: {{ .Annotations.summary }}\n      Device: {{ .Labels.resource }}\n      {{ end }}\n</code></pre>"},{"location":"user/alerts/#slack-notifications","title":"Slack Notifications","text":"<pre><code># alertmanager.yml\nreceivers:\n- name: 'slack-notifications'\n  slack_configs:\n  - api_url: 'YOUR_SLACK_WEBHOOK_URL'\n    channel: '#flightctl-alerts'\n    title: 'Flight Control Alert'\n    text: |\n      {{ range .Alerts }}\n      *{{ .Labels.alertname }}* on device {{ .Labels.resource }}\n      {{ end }}\n</code></pre>"},{"location":"user/alerts/#webhook-notifications","title":"Webhook Notifications","text":"<pre><code># alertmanager.yml\nreceivers:\n- name: 'webhook-notifications'\n  webhook_configs:\n  - url: 'http://your-webhook-endpoint.com/alerts'\n    send_resolved: true\n</code></pre>"},{"location":"user/alerts/#alert-labels-and-filtering","title":"Alert Labels and Filtering","text":"<p>Every Flight Control alert includes these labels:</p> <ul> <li><code>alertname</code>: The type of alert (e.g., \"DeviceDisconnected\")</li> <li><code>resource</code>: The name of the affected resource</li> <li><code>org_id</code>: The organization ID</li> </ul> <p>Use these labels to create targeted notification rules and filters:</p> <pre><code># Route critical CPU alerts to on-call team\nroutes:\n- match:\n    alertname: DeviceCPUCritical\n  receiver: 'oncall-team'\n\n# Route disconnection alerts to monitoring team\n- match:\n    alertname: DeviceDisconnected\n  receiver: 'monitoring-team'\n</code></pre>"},{"location":"user/alerts/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user/alerts/#no-alerts-appearing","title":"No Alerts Appearing","text":"<ol> <li>Check alert exporter status:</li> </ol> <pre><code># For Kubernetes\nkubectl logs deployment/flightctl-alert-exporter\n\n# For Quadlets\nsudo journalctl -u flightctl-alert-exporter.service\n</code></pre> <ol> <li>Check Alertmanager status:</li> </ol> <pre><code># For Kubernetes\nkubectl logs deployment/flightctl-alertmanager\n\n# For Quadlets\nsudo journalctl -u flightctl-alertmanager.service\n</code></pre> <ol> <li>Check authentication and proxy:</li> </ol> <pre><code># Verify your token works and proxy is accessible\ncurl -H \"Authorization: Bearer &lt;your-token&gt;\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/status\n</code></pre>"},{"location":"user/alerts/#alerts-not-resolving","title":"Alerts Not Resolving","text":"<ol> <li>Check if resolution events are being generated:</li> <li>Verify devices are reconnecting</li> <li>Confirm resource usage has returned to normal</li> <li> <p>Check application health status</p> </li> <li> <p>Review event logs:</p> </li> </ol> <pre><code># Check recent events\nflightctl get events --limit 50\n</code></pre>"},{"location":"user/alerts/#missing-alert-notifications","title":"Missing Alert Notifications","text":"<ol> <li>Verify Alertmanager configuration:</li> </ol> <pre><code># Check Alertmanager status through the proxy\ncurl -H \"Authorization: Bearer &lt;your-token&gt;\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/status\n</code></pre> <ol> <li>Test notification channels:</li> <li>Send test alerts to verify email/Slack/webhook configuration</li> <li> <p>Check Alertmanager logs for delivery errors</p> </li> <li> <p>Review routing rules:</p> </li> <li>Ensure alert labels match your routing configuration</li> <li>Verify receiver configurations are correct</li> </ol>"},{"location":"user/alerts/#performance-issues","title":"Performance Issues","text":"<ol> <li>Adjust polling interval if system is under heavy load:</li> </ol> <pre><code>service:\n  alertPollingInterval: \"60s\"  # Reduce frequency\n</code></pre> <ol> <li>Monitor alert exporter resource usage:</li> </ol> <pre><code># Check memory and CPU usage\nkubectl top pod -l flightctl.service=flightctl-alert-exporter\n</code></pre>"},{"location":"user/alerts/#best-practices","title":"Best Practices","text":""},{"location":"user/alerts/#alert-routing-strategy","title":"Alert Routing Strategy","text":"<ol> <li>Prioritize by severity:</li> <li>Route critical alerts (CPU/Memory critical, disconnections) to immediate notification channels</li> <li> <p>Route warning alerts to monitoring dashboards or delayed notifications</p> </li> <li> <p>Group by device or fleet:</p> </li> <li>Avoid alert storms by grouping related alerts</li> <li>Use appropriate group intervals to batch notifications</li> </ol>"},{"location":"user/alerts/#retention-and-cleanup","title":"Retention and Cleanup","text":"<ol> <li>Configure alert retention:</li> </ol> <pre><code># In Alertmanager configuration\nglobal:\n  resolve_timeout: 5m  # Auto-resolve alerts after 5 minutes of no updates\n</code></pre> <ol> <li>Regular maintenance:</li> <li>Monitor alert volume and adjust thresholds if needed</li> <li>Review and update notification channels regularly</li> </ol>"},{"location":"user/alerts/#integration-with-monitoring","title":"Integration with Monitoring","text":"<ol> <li>Combine with metrics: Use alerts alongside Flight Control metrics for comprehensive monitoring</li> <li>Dashboard integration: Display alert status in monitoring dashboards</li> <li>Incident management: Integrate alerts with your incident response tools</li> </ol>"},{"location":"user/alerts/#examples","title":"Examples","text":""},{"location":"user/alerts/#view-all-active-alerts","title":"View All Active Alerts","text":"<pre><code>curl -H \"Authorization: Bearer &lt;token&gt;\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/alerts | jq '.'\n</code></pre>"},{"location":"user/alerts/#check-specific-device-alerts","title":"Check Specific Device Alerts","text":"<pre><code>curl -H \"Authorization: Bearer &lt;token&gt;\" \\\n     \"https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/alerts?filter=resource=my-edge-device\" | jq '.'\n</code></pre>"},{"location":"user/alerts/#monitor-alert-count","title":"Monitor Alert Count","text":"<pre><code># Count active alerts\ncurl -s -H \"Authorization: Bearer &lt;token&gt;\" \\\n     https://flightctl-alertmanager-proxy.&lt;your-domain&gt;:8443/api/v2/alerts | jq 'length'\n</code></pre>"},{"location":"user/api-resources/","title":"API resources","text":"<p>This document serves as a high-level overview of the various resources defined by the flightctl API.  You may view and interact with these resources via the API, CLI, or UI.</p> <p>You may configure your edge devices by specifying their configurations directly to flightctl or maintain the configurations in one or more git repositories and use GitOps to synchronize the configurations.</p>"},{"location":"user/api-resources/#general-structure","title":"General structure","text":"<p>Resources in flightctl are modeled after Kubernetes resources.  Each resource has the following fields:</p> <ul> <li>apiVersion: Defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value and may reject unrecognized values.  More information can be found here.</li> <li>kind: A string value representing the REST resource this object represents. Servers may infer this from the endpoint to which the client submits requests.  It cannot be updated. More information can be found here.</li> <li>metadata:</li> <li>name: The name of the object used as an immutable identifier.</li> <li>labels: Map of string keys and values that can be used to organize and categorize (scope and select) objects.</li> <li>creationTimestamp: The time at which the object was created.</li> <li>deletionTimestamp: The time at which the object was deleted.</li> <li>generation: A sequence number representing a specific generation of the desired state. Populated by the system. Read-only.</li> <li>owner: An object that owns this object, in \"kind/name\" format.</li> <li>annotations: Properties set by the service.</li> <li>resourceVersion: An opaque string that identifies the server's internal version of an object.</li> <li>spec: The desired state of the object.</li> <li>status: The current state of the object.</li> </ul>"},{"location":"user/api-resources/#repositories","title":"Repositories","text":"<p>A repository resource defines how flightctl can access an external configuration source.  While flightctl currently supports git as the sole repository type, others may be added in the future.</p>"},{"location":"user/api-resources/#enrollmentrequests","title":"EnrollmentRequests","text":"<p>Once you boot a device that runs the flightctl agent, the agent will contact the service to create an EnrollmentRequest resource.</p> <p>If you recognize this device, approve the enrollment request.  Doing so will cause flightctl to create a Device object corresponding to this enrollment request.  The Device resource is described in the next section.  When approving the enrollment request, you may optionally pass the following information:</p> <ul> <li>labels: A set of labels to apply to the device object that will be created</li> <li>approvedBy: The name of the approver</li> </ul> <p>Approved enrollment requests remain in the system and serve as a record of who approved each device and when.</p>"},{"location":"user/api-resources/#devices","title":"Devices","text":"<p>The device resource represents an edge device that flightctl will manage.  A device can be managed individually or as part of a group.  A group of devices is called a Fleet.  The Fleet resource is described in the next section.</p> <p>When managing a single device, you must describe what flightctl should deploy to the device using the <code>spec</code> property.  This includes the OS image to deploy, any additional configuration, and what the flightctl agent should monitor.  The configuration, specified in <code>spec.config</code> is a list of configuration items, where each can be any one of three types:</p> <ul> <li>Inline: File content is specified in ignition format directly in the device\u2019s <code>spec.config</code>.</li> <li>Git: File content is stored in a git repository.  The device\u2019s <code>spec.config</code> references a repository object, target revision (e.g., branch, tag, or hash), and a path in the git repository.</li> <li>Kubernetes Secret: File content is stored in a Kubernetes Secret.  Flightctl currently assumes that to use this feature, flightctl is running on Kubernetes and has sufficient permissions to access the referenced Secret on the cluster.</li> </ul> <p>When managing a device as part of a Fleet, ensure the device object has appropriate labels set, as flightctl will use these labels to assign devices to fleets.  The device\u2019s <code>spec</code> should be left empty, as flightctl will update it according to the fleet\u2019s definition.  You can see what fleet a device belongs to by checking the <code>owner</code> property.</p>"},{"location":"user/api-resources/#fleets","title":"Fleets","text":"<p>As mentioned, a fleet is a group of devices. A fleet\u2019s definition has two main parts. The first is the <code>spec.selector</code> property, which defines how to select devices for this fleet according to their labels. The second is the <code>spec.template</code> property, which contains the configuration to be rolled out to each device.  This configuration is identical to the device configuration described above.</p>"},{"location":"user/api-resources/#templateversions","title":"TemplateVersions","text":"<p>Whenever flightctl detects changes to a fleet\u2019s template, it creates a snapshot of the configuration called a TemplateVersion.  It freezes the configuration, so, for example, git branches and tags are translated to hashes.  Whenever a new valid template version object is created, flightctl will apply it to all devices belonging to the fleet.</p>"},{"location":"user/api-resources/#resourcesyncs","title":"ResourceSyncs","text":"<p>To get a end-to-end GitOps experience, you can:</p> <ol> <li>Define your fleet objects in a git repository in YAML format</li> <li>Create a repository object that references the git repository</li> <li>Create a resource sync object that specifies a file or directory in the repository containing the fleet definitions</li> </ol> <p>Flightctl will periodically check for updates to the fleet definitions and apply them to the system.  This will, of course, trigger the creation of template version objects, that will trigger updating the devices in the fleets.</p>"},{"location":"user/api-resources/#resource-relationships","title":"Resource Relationships","text":"<ul> <li>A device's configuration may reference zero or more repositories.  A repository may be referenced by zero or more devices.</li> <li>A fleet's configuration may reference zero or more repositories.  A repository may be referenced by zero or more fleets.</li> <li>A device may belong to zero or one fleet.  A fleet may have zero or more devices.</li> <li>Approving an enrollment request creates a single device.</li> <li>A fleet may have zero or more template versions.</li> <li>A resource sync may create one or more fleets.  A fleet may be created by zero or one resource sync.</li> </ul> <pre><code>erDiagram\n    Device}o..o{ Repository : references\n    Fleet|o..o| Repository : references\n    Device}o..o| Fleet : belongs-to\n    EnrollmentRequest ||--|| Device : creates\n    TemplateVersion}o..|| Fleet : belongs-to\n    ResourceSync|o..|{ Fleet : creates</code></pre>"},{"location":"user/auth-resources/","title":"Authentication resources","text":"<p>The table below contains the routes, names, resource names, and verbs for Flight Control API endpoints:</p> Route Name Resource Verb <code>GET /api/v1/certificatesigningrequests</code> <code>ListCertificateSigningRequests</code> <code>certificatesigningrequests</code> <code>list</code> <code>POST /api/v1/certificatesigningrequests</code> <code>CreateCertificateSigningRequest</code> <code>certificatesigningrequests</code> <code>create</code> <code>DELETE /api/v1/certificatesigningrequests/{name}</code> <code>DeleteCertificateSigningRequest</code> <code>certificatesigningrequests</code> <code>delete</code> <code>GET /api/v1/certificatesigningrequests/{name}</code> <code>ReadCertificateSigningRequest</code> <code>certificatesigningrequests</code> <code>get</code> <code>PATCH /api/v1/certificatesigningrequests/{name}</code> <code>PatchCertificateSigningRequest</code> <code>certificatesigningrequests</code> <code>patch</code> <code>PUT /api/v1/certificatesigningrequests/{name}</code> <code>ReplaceCertificateSigningRequest</code> <code>certificatesigningrequests</code> <code>update</code> <code>DELETE /api/v1/certificatesigningrequests/{name}/approval</code> <code>DenyCertificateSigningRequest</code> <code>certificatesigningrequests/approval</code> <code>delete</code> <code>POST /api/v1/devices</code> <code>CreateDevice</code> <code>devices</code> <code>create</code> <code>GET /api/v1/devices</code> <code>ListDevices</code> <code>devices</code> <code>list</code> <code>GET /api/v1/devices/{name}</code> <code>ReadDevice</code> <code>devices</code> <code>get</code> <code>PUT /api/v1/devices/{name}</code> <code>ReplaceDevice</code> <code>devices</code> <code>update</code> <code>DELETE /api/v1/devices/{name}</code> <code>DeleteDevice</code> <code>devices</code> <code>delete</code> <code>GET /api/v1/devices/{name}/status</code> <code>ReadDeviceStatus</code> <code>devices/status</code> <code>get</code> <code>PUT /api/v1/devices/{name}/status</code> <code>ReplaceDeviceStatus</code> <code>devices/status</code> <code>update</code> <code>GET /api/v1/devices/{name}/rendered</code> <code>GetRenderedDevice</code> <code>devices/rendered</code> <code>get</code> <code>PUT /api/v1/devices/{name}/decommission</code> <code>DecommissionDevice</code> <code>devices/decommission</code> <code>update</code> <code>GET /ws/v1/devices/{name}/console</code> <code>DeviceConsole</code> <code>devices/console</code> <code>get</code> <code>POST /api/v1/enrollmentrequests</code> <code>CreateEnrollmentRequest</code> <code>enrollmentrequests</code> <code>create</code> <code>GET /api/v1/enrollmentrequests</code> <code>ListEnrollmentRequests</code> <code>enrollmentrequests</code> <code>list</code> <code>GET /api/v1/enrollmentrequests/{name}</code> <code>ReadEnrollmentRequest</code> <code>enrollmentrequests</code> <code>get</code> <code>PUT /api/v1/enrollmentrequests/{name}</code> <code>ReplaceEnrollmentRequest</code> <code>enrollmentrequests</code> <code>update</code> <code>PATCH /api/v1/enrollmentrequests/{name}</code> <code>PatchEnrollmentRequest</code> <code>enrollmentrequests</code> <code>patch</code> <code>DELETE /api/v1/enrollmentrequests/{name}</code> <code>DeleteEnrollmentRequest</code> <code>enrollmentrequests</code> <code>delete</code> <code>GET /api/v1/enrollmentrequests/{name}/status</code> <code>ReadEnrollmentRequestStatus</code> <code>enrollmentrequests/status</code> <code>get</code> <code>POST /api/v1/enrollmentrequests/{name}/approval</code> <code>ApproveEnrollmentRequest</code> <code>enrollmentrequests/approval</code> <code>post</code> <code>PUT /api/v1/enrollmentrequests/{name}/status</code> <code>ReplaceEnrollmentRequestStatus</code> <code>enrollmentrequests/status</code> <code>update</code> <code>POST /api/v1/fleets</code> <code>CreateFleet</code> <code>fleets</code> <code>create</code> <code>GET /api/v1/fleets</code> <code>ListFleets</code> <code>fleets</code> <code>list</code> <code>GET /api/v1/fleets/{name}</code> <code>ReadFleet</code> <code>fleets</code> <code>get</code> <code>PUT /api/v1/fleets/{name}</code> <code>ReplaceFleet</code> <code>fleets</code> <code>update</code> <code>DELETE /api/v1/fleets/{name}</code> <code>DeleteFleet</code> <code>fleets</code> <code>delete</code> <code>GET /api/v1/fleets/{name}/status</code> <code>ReadFleetStatus</code> <code>fleets/status</code> <code>get</code> <code>PUT /api/v1/fleets/{name}/status</code> <code>ReplaceFleetStatus</code> <code>fleets/status</code> <code>update</code> <code>POST /api/v1/repositories</code> <code>CreateRepository</code> <code>repositories</code> <code>create</code> <code>GET /api/v1/repositories</code> <code>ListRepositories</code> <code>repositories</code> <code>list</code> <code>PUT /api/v1/repositories/{name}</code> <code>ReplaceRepository</code> <code>repositories</code> <code>update</code> <code>DELETE /api/v1/repositories/{name}</code> <code>DeleteRepository</code> <code>repositories</code> <code>delete</code> <code>POST /api/v1/resourcesyncs</code> <code>CreateResourceSync</code> <code>resourcesyncs</code> <code>create</code> <code>GET /api/v1/resourcesyncs</code> <code>ListResourceSync</code> <code>resourcesyncs</code> <code>list</code> <code>GET /api/v1/resourcesyncs/{name}</code> <code>ReadResourceSync</code> <code>resourcesyncs</code> <code>get</code> <code>PUT /api/v1/resourcesyncs/{name}</code> <code>ReplaceResourceSync</code> <code>resourcesyncs</code> <code>update</code> <code>DELETE /api/v1/resourcesyncs/{name}</code> <code>DeleteResourceSync</code> <code>resourcesyncs</code> <code>delete</code> <code>GET /api/v1/fleets/{fleet}/templateVersions</code> <code>ListTemplateVersions</code> <code>fleets/templateversions</code> <code>list</code> <code>GET /api/v1/fleets/{fleet}/templateVersions/{name}</code> <code>ReadTemplateVersion</code> <code>fleets/templateversions</code> <code>get</code> <code>DELETE /api/v1/fleets/{fleet}/templateVersions/{name}</code> <code>DeleteTemplateVersion</code> <code>fleets/templateversions</code> <code>delete</code>"},{"location":"user/building-images/","title":"Building OS Images","text":""},{"location":"user/building-images/#understanding-os-images-and-the-image-build-process","title":"Understanding OS Images and the Image Build Process","text":"<p>Image-based OSes allow the whole OS (and optionally also OS configuration and applications) to be versioned, deployed, and updated as a single unit. This reduces operational risk:</p> <ul> <li>It minimizes potential drift between what has been thoroughly tested and what is deployed to a large number of devices.</li> <li>It minimizes the risk of failed updates that require expensive maintenance or replacement through transactional updates and rollbacks.</li> </ul> <p>Flight Control initially focuses on image-based Linux OSes running bootable container images (bootc), with support for ostree and rpm-ostree images planned for later. It does not update package-based OSes.</p> <p>At a high level, the image building process for bootc works as follows:</p> <ol> <li>Choose a base bootc image (for example Fedora, CentOS, or RHEL).</li> <li>Create a Containerfile that layers onto that base image<ul> <li>the Flight Control agent and configuration,</li> <li>(optionally) any drivers specific to your target deployment environment, and</li> <li>(optionally) host configuration (e.g. CA bundles) and application workloads common to all deployments from this image.</li> </ul> </li> <li>Build, publish, and sign an OS image (bootc) using <code>podman</code> and <code>skopeo</code>.</li> <li>Build, publish, and sign an OS disk image using <code>bootc-image-builder</code> (bib) and <code>skopeo</code>.</li> </ol> <p> </p> <p>The OS disk image is used to image (or \"flash\") a device when it is provisioned. For subsequent device updates, only the OS image (bootc) is required. This is because bootc is a file system image, that is it contains just the files in the file system including their attributes, but the disk layout (partitions, volumes) and file systems need to have been created first. The OS disk image includes everything, the disk layout, bootloader, file systems, and the files in the OS image (bootc). It can therefore be written verbatim to the device's drive.</p>"},{"location":"user/building-images/#building-and-publishing-os-images-and-disk-images","title":"Building and Publishing OS Images and Disk Images","text":"<p>This section describes the generic process for building an OS image (bootc) that contains the Flight Control agent and building an OS disk image for flashing to physical devices. Later sections then describe considerations when building for specific virtualization and bare metal provisioning environments.</p> <p>Before you start, ensure you have installed the following prerequisites:</p> <ul> <li><code>flightctl</code> CLI latest version (installation guide)</li> <li><code>podman</code> version 5.0 or higher (installation guide)</li> <li><code>skopeo</code> version 1.14 or higher (installation guide)</li> </ul>"},{"location":"user/building-images/#choosing-an-enrollment-method","title":"Choosing an Enrollment Method","text":"<p>When the Flight Control agent starts, it expects to find its configuration in <code>/etc/flightctl/config.yaml</code>. This configuration needs to contain:</p> <ul> <li>the Flight Control enrollment service to connect to (enrollment endpoint),</li> <li>the X.509 client certificate and key to connect with (enrollment certificate),</li> <li>optionally, any further agent configuration (see Configuring the Flight Control Agent).</li> </ul> <p>You can provision the enrollment endpoint and certificate to the device in the following ways:</p> <ul> <li>Early binding: You can build an OS image that includes both the enrollment endpoint and certificate.</li> </ul> <p>Devices using this image can automatically connect to \"their\" Flight Control service to request enrollment, without depending on any provisioning infrastructure. On the other hand, devices are bound to a specific service and owner. They also share the same, typically long-lived X.509 client certificate for connecting to the enrollment service.</p> <ul> <li>Late binding: You can build an OS image without enrollment endpoint and certificate and instead inject both at provisioning-time.</li> </ul> <p>Devices using this image are not bound to a single owner or service and can have device-specific, short-lived X.509 client certificates for connecting to the enrollment service. However, late binding requires virtualization or bare metal provisioning infrastructure that can request device-specific enrollment endpoints and certificates from Flight Control and inject them into the provisioned device using mechanisms such as cloud-init, Ignition, or kickstart.</p> <p>[!NOTE] The enrollment certificate is only used to secure the network connection for submitting an enrollment request. It is not involved in the actual verification or approval of the enrollment request. It is also no longer used with enrolled devices, as these rely on device-specific management certificates instead.</p> <p>The following procedure describes the early binding method of building the agent configuration including the enrollment endpoint and certificate into the image.</p>"},{"location":"user/building-images/#requesting-an-enrollment-certificate","title":"Requesting an Enrollment Certificate","text":"<p>Use the <code>flightctl</code> CLI to authenticate with the Flight Control service, then run the following command to obtain enrollment credentials with a validity of one year, in the format of an agent configuration file:</p> <pre><code>flightctl certificate request --signer=enrollment --expiration=365d --output=embedded &gt; config.yaml\n</code></pre> <p>The returned <code>config.yaml</code> contains the URLs of the Flight Control service, its CA bundle, and the enrollment client certificate and key for the agent. It should look similar to this:</p> <pre><code>enrollment-service:\n  authentication:\n    client-certificate-data: LS0tLS1CRUdJTiBD...\n    client-key-data: LS0tLS1CRUdJTiBF...\n  service:\n    certificate-authority-data: LS0tLS1CRUdJTiBD...\n    server: https://agent-api.flightctl.127.0.0.1.nip.io:7443\n  enrollment-ui-endpoint: https://ui.flightctl.127.0.0.1.nip.io:8081\n</code></pre>"},{"location":"user/building-images/#building-the-os-image-bootc","title":"Building the OS Image (bootc)","text":"<p>Create a file named <code>Containerfile</code> with the following content to build an OS image based on CentOS Stream 9 that includes the Flight Control agent and configuration:</p> <pre><code>FROM quay.io/centos-bootc/centos-bootc:stream9\n\nRUN dnf -y copr enable @redhat-et/flightctl &amp;&amp; \\\n    dnf -y install flightctl-agent &amp;&amp; \\\n    dnf -y clean all &amp;&amp; \\\n    systemctl enable flightctl-agent.service\n\n# Optional: To enable podman-compose application support, uncomment below\n# RUN dnf -y install epel-release &amp;&amp; \\\n#     dnf -y install podman-compose &amp;&amp; \\\n#     dnf -y clean all &amp;&amp; \\\n#     systemctl enable podman.service\n\nADD config.yaml /etc/flightctl/\n</code></pre> <p>[!NOTE] If you have used Podman or Docker before to build application containers, you will notice this is a regular <code>Containerfile</code>, with the only difference that the base image referenced in <code>FROM</code> is bootable container (bootc) image. That means it already contains a Linux kernel. This allows you to reuse existing standard container build tools and workflows.</p> <p>[!NOTE] If your device relies on an OS image from a private repository, authentication credentials (pull secrets) must be placed in the appropriate system path <code>/etc/ostree/auth.json</code>. Authentication must exist on the device before it can be consumed.</p> <p>Define the OCI registry, image repository, and image tag you want to use (ensure you have write-permissions to that repository):</p> <pre><code>OCI_REGISTRY=quay.io\nOCI_IMAGE_REPO=${OCI_REGISTRY}/your_org/centos-bootc\nOCI_IMAGE_TAG=v1\n</code></pre> <p>Build the OS image for your target platform:</p> <pre><code>sudo podman build -t ${OCI_IMAGE_REPO}:${OCI_IMAGE_TAG} .\n</code></pre>"},{"location":"user/building-images/#using-rhel-base-images","title":"Using RHEL base images","text":"<p>When using Flight Control with a RHEL 9 base image, you need to make a few changes to the <code>Containerfile</code>, specifically you need to disable RHEL's default automatic updates and use a different command to enable the EPEL repository in case you need <code>podman-compose</code>:</p> <pre><code>FROM registry.redhat.io/rhel9/rhel-bootc:9.5\n\nRUN dnf -y copr enable @redhat-et/flightctl &amp;&amp; \\\n    dnf -y install flightctl-agent &amp;&amp; \\\n    dnf -y clean all &amp;&amp; \\\n    systemctl enable flightctl-agent.service &amp;&amp; \\\n    systemctl mask bootc-fetch-apply-updates.timer\n\n# Optional: To enable podman-compose application support, uncomment below\n# RUN dnf -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-9.noarch.rpm &amp;&amp; \\\n#     dnf -y install podman-compose &amp;&amp; \\\n#     dnf -y clean all &amp;&amp; \\\n#     rm -rf /var/{cache,log} /var/lib/{dnf,rhsm} &amp;&amp; \\\n#     systemctl enable podman.service\n\nADD config.yaml /etc/flightctl/\n</code></pre> <p>You also need to log in to the Red Hat registry before building your image:</p> <pre><code>sudo podman login registry.redhat.io\n</code></pre>"},{"location":"user/building-images/#signing-and-publishing-the-os-image-bootc","title":"Signing and Publishing the OS Image (bootc)","text":"<p>There are several methods for signing container images. We will focus on signing with Sigstore signatures using a private key. For other options, refer to the RHEL or cosign documentations.</p> <p>Generate a Sigstore key pair <code>signingkey.pub</code> and <code>signingkey.private</code>:</p> <pre><code>skopeo generate-sigstore-key --output-prefix signingkey\n</code></pre> <p>Configure container tools like Podman and Skopeo to upload Sigstore signatures together with your signed image to your OCI registry:</p> <pre><code>sudo tee \"/etc/containers/registries.d/${OCI_REGISTRY}.yaml\" &gt; /dev/null &lt;&lt;EOF\ndocker:\n    ${OCI_REGISTRY}:\n        use-sigstore-attachments: true\nEOF\n</code></pre> <p>Log in to your OCI registry, then sign and publish the OS image:</p> <pre><code>sudo podman login ${OCI_REGISTRY}\nsudo podman push --sign-by-sigstore-private-key ./signingkey.private ${OCI_IMAGE_REPO}:${OCI_IMAGE_TAG}\n</code></pre>"},{"location":"user/building-images/#building-the-os-disk-image","title":"Building the OS Disk Image","text":"<p>Next, create a directory called \"output\" and use <code>bootc-image-builder</code> to generate an OS disk image of type <code>iso</code> from your OS image:</p> <pre><code>mkdir -p output\n\nsudo podman run --rm -it --privileged --pull=newer \\\n    --security-opt label=type:unconfined_t \\\n    -v \"${PWD}/output\":/output \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    quay.io/centos-bootc/bootc-image-builder:latest \\\n    --type iso \\\n    ${OCI_IMAGE_REPO}:${OCI_IMAGE_TAG}\n</code></pre> <p>Once <code>bootc-image-builder</code> completes, you can find the ISO disk image under <code>${PWD}/output/bootiso/install.iso</code>.</p> <p>Refer to <code>bootc-image-builder</code>'s list of image types for other supported types.</p>"},{"location":"user/building-images/#optional-signing-and-publishing-the-os-disk-image-to-an-oci-registry","title":"Optional: Signing and Publishing the OS Disk Image to an OCI Registry","text":"<p>Optionally, you can compress, sign, and publish your disk image as so-called \"OCI artifacts\" to your OCI registry, too. This helps unify hosting and distribution. For example, to publish your ISO disk image to a repository named after your bootc image with <code>/diskimage-iso</code> appended, run the following commands:</p> <pre><code>sudo chown -R $(whoami):$(whoami) \"${PWD}/output\"\n\nOCI_DISK_IMAGE_REPO=${OCI_IMAGE_REPO}/diskimage-iso\n\nsudo podman manifest create \\\n    ${OCI_DISK_IMAGE_REPO}:${OCI_IMAGE_TAG}\n\nsudo podman manifest add \\\n    --artifact --artifact-type application/vnd.diskimage.iso \\\n    --arch=amd64 --os=linux \\\n    ${OCI_DISK_IMAGE_REPO}:${OCI_IMAGE_TAG} \\\n    \"${PWD}/output/bootiso/install.iso\"\n\nsudo podman manifest push --all \\\n     --sign-by-sigstore-private-key ./signingkey.private \\\n    ${OCI_DISK_IMAGE_REPO}:${OCI_IMAGE_TAG} \\\n    docker://${OCI_DISK_IMAGE_REPO}:${OCI_IMAGE_TAG}\n</code></pre>"},{"location":"user/building-images/#further-references","title":"Further References","text":"<p>For further information and practical examples, refer to:</p> <ul> <li>Example images in the Flight Control demos repository.</li> <li>Flight Control demos repository's automated build pipeline.</li> <li>The Fedora/CentOS bootc project's community-provided examples.</li> </ul>"},{"location":"user/building-images/#considerations-for-specific-target-platforms","title":"Considerations for Specific Target Platforms","text":""},{"location":"user/building-images/#red-hat-openshift-virtualization","title":"Red Hat OpenShift Virtualization","text":"<p>When building an OS image and disk image for OpenShift Virtualization, follow the generic process with the following changes:</p> <ol> <li>Use late binding of the enrollment endpoint and enrollment certificates, injecting the enrollment certificate or even the whole agent configuration through <code>cloud-init</code> when provisioning the virtual device.</li> <li>Add the <code>open-vm-tools</code> guest tools to the image.</li> <li>Build a disk image of type \"qcow2\" instead of type \"iso\".</li> <li>Optional: Upload the disk image to an OCI registry as a container disk.</li> </ol> <p>Create a file named <code>Containerfile</code> with the following content to build an OS image based on CentOS Stream 9 that includes the Flight Control agent and VM guest tools, but no agent configuration:</p> <pre><code>FROM quay.io/centos-bootc/centos-bootc:stream9\n\nRUN dnf -y copr enable @redhat-et/flightctl &amp;&amp; \\\n    dnf -y install flightctl-agent &amp;&amp; \\\n    dnf -y clean all &amp;&amp; \\\n    systemctl enable flightctl-agent.service\n\nRUN dnf -y install cloud-init open-vm-tools &amp;&amp; \\\n    dnf -y clean all &amp;&amp; \\\n    ln -s ../cloud-init.target /usr/lib/systemd/system/default.target.wants &amp;&amp; \\\n    systemctl enable vmtoolsd.service\n\n# Optional: To enable podman-compose application support, uncomment below\n# RUN dnf -y install epel-release epel-next-release &amp;&amp; \\\n#    dnf -y install podman-compose &amp;&amp; \\\n#    dnf -y clean all &amp;&amp; \\\n#    systemctl enable podman.service\n</code></pre> <p>Build, sign, and publish the OS image (bootc) following the generic process.</p> <p>For the disk image, build an image of type \"qcow2\" instead of \"iso\":</p> <pre><code>mkdir -p output\n\nsudo podman run --rm -it --privileged --pull=newer \\\n    --security-opt label=type:unconfined_t \\\n    -v \"${PWD}/output\":/output \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    quay.io/centos-bootc/bootc-image-builder:latest \\\n    --type qcow2 \\\n    ${OCI_IMAGE_REPO}:${OCI_IMAGE_TAG}\n</code></pre> <p>Once <code>bootc-image-builder</code> completes, you can find the disk image under <code>${PWD}/output/qcow2/disk.qcow2</code>.</p> <p>As OpenShift Virtualization can download disk images from an OCI registry, but expects a \"container disk\" image instead of an OCI artifact, use the following procedure to build, sign, and upload the QCoW2 disk image:</p> <p>Create a file called <code>Containerfile.qcow2</code> with the following content:</p> <pre><code>FROM registry.access.redhat.com/ubi9/ubi:latest AS builder\nADD --chown=107:107 output/qcow2/disk.qcow2 /disk/\nRUN chmod 0440 /disk/*\n\nFROM scratch\nCOPY --from=builder /disk/* /disk/\n</code></pre> <p>This adds the QCoW2 disk image to a builder container in order to set the required file ownership (107 is the QEMU user) and file permissions (0440), then copies the file to a scratch image.</p> <p>Next, build, sign, and publish your disk image:</p> <pre><code>sudo chown -R $(whoami):$(whoami) \"${PWD}/output\"\n\nOCI_DISK_IMAGE_REPO=${OCI_IMAGE_REPO}/diskimage-qcow2\n\nsudo podman build -t ${OCI_DISK_IMAGE_REPO}:${OCI_IMAGE_TAG} -f Containerfile.qcow2 .\n\nsudo podman push --sign-by-sigstore-private-key ./signingkey.private ${OCI_DISK_IMAGE_REPO}:${OCI_IMAGE_TAG}\n</code></pre>"},{"location":"user/building-images/#vmware-vsphere","title":"VMware vSphere","text":"<p>When building OS images and disk images for VMware vSphere, follow the generic process with the following changes:</p> <ol> <li>Use late binding of the enrollment endpoint and enrollment certificates, injecting the enrollment certificate or even the whole agent configuration through <code>cloud-init</code> when provisioning the virtual device.</li> <li>Add the <code>open-vm-tools</code> guest tools to the image.</li> <li>Build a disk image of type \"vmdk\" instead of type \"iso\".</li> </ol> <p>Create a file named <code>Containerfile</code> with the following content to build an OS image based on CentOS Stream 9 that includes the Flight Control agent and VM guest tools, but no agent configuration:</p> <pre><code>FROM quay.io/centos-bootc/centos-bootc:stream9\n\nRUN dnf -y copr enable @redhat-et/flightctl &amp;&amp; \\\n    dnf -y install flightctl-agent &amp;&amp; \\\n    dnf -y clean all &amp;&amp; \\\n    systemctl enable flightctl-agent.service\n\nRUN dnf -y install cloud-init open-vm-tools &amp;&amp; \\\n    dnf -y clean all &amp;&amp; \\\n    ln -s ../cloud-init.target /usr/lib/systemd/system/default.target.wants &amp;&amp; \\\n    systemctl enable vmtoolsd.service\n</code></pre> <p>Build the OS image (bootc) in the generic process, but build an image of type \"vmdk\" instead of \"iso\":</p> <pre><code>mkdir -p output\n\nsudo podman run --rm -it --privileged --pull=newer \\\n    --security-opt label=type:unconfined_t \\\n    -v \"${PWD}/output\":/output \\\n    -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    quay.io/centos-bootc/bootc-image-builder:latest \\\n    --type vmdk \\\n    ${OCI_IMAGE_REPO}:${OCI_IMAGE_TAG}\n</code></pre> <p>Once <code>bootc-image-builder</code> completes, you can find the disk image under <code>${PWD}/output/vmdk/disk.vmdk</code>.</p>"},{"location":"user/building-images/#references","title":"References","text":"<p>For details and other target platforms, refer to</p> <ul> <li>The \"Deploying the RHEL bootc images\" section of the RHEL documentation</li> </ul>"},{"location":"user/building-images/#best-practices-when-building-images","title":"Best Practices When Building Images","text":""},{"location":"user/building-images/#prefer-build-time-configuration-over-dynamic-runtime-configuration","title":"Prefer Build-time Configuration over Dynamic Runtime Configuration","text":"<p>Prefer adding configuration to the OS image itself at build-time, so they get tested, distributed, and updated together (\"lifecycle-bound\"). There are cases when this is not feasible or desirable, in which case use Flight Control's approach to dynamically configure devices at runtime instead:</p> <ul> <li>configuration that is deployment- or site-specific (e.g. a hostname or a site-specific network credential)</li> <li>secrets that are not secure to distribute via the image</li> <li>application workloads that need to be added, updated, or deleted without reboot or on a faster cadence than the OS</li> </ul>"},{"location":"user/building-images/#prefer-configuration-in-usr-over-etc","title":"Prefer Configuration in /usr over /etc","text":"<p>Prefer placing  configuration files under <code>/usr</code> if the configuration is static and the application or service supports it. This way, configuration remains read-only and fully defined by the image (avoiding ostree's 3-way merge of <code>/etc</code> as a potential source of drift). There are cases when this is not feasible or desirable:</p> <ul> <li>the configuration is deployment- or site-specific</li> <li>the application or service only supports reading configuration from <code>/etc</code></li> <li>the configuration may need to be changed at runtime (although most applications allow configuration in <code>/etc</code> to override that in <code>/usr</code>)</li> </ul>"},{"location":"user/building-images/#use-drop-in-directories","title":"Use Drop-in Directories","text":"<p>Avoid editing configuration files, as this is a source of drift and hard to use with declarative configuration management. Instead, most system services support \"drop-in directories\" (recognized by the <code>.d/</code> at the end of the name) where you can \"drop-in\" (or replace or remove) configuration files that the service aggregates together. Examples: <code>/etc/containers/certs.d</code>, <code>/etc/cron.d</code>, <code>/etc/NetworkManager/conf.d</code>.</p>"},{"location":"user/building-images/#avoid-mutating-the-file-system-out-of-band","title":"Avoid Mutating the File System Out-of-Band","text":"<p>Avoid executing scripts or commands that change the file system as a side-effect, as these may be overwritten by bootc or Flight Control or may lead to drift or failed integrity checks. Instead, run such scripts or commands during image-building, so changes become part of the image or use Flight Control's configuration management mechanisms instead.</p>"},{"location":"user/building-images/#further-references_1","title":"Further References","text":"<p>See also the guidance in the bootc documentation.</p>"},{"location":"user/configuring-agent/","title":"Configuring the Flight Control Agent","text":"<p>When the <code>flightctl-agent</code> starts, it reads its configuration from <code>/etc/flightctl/config.yaml</code> as well as a number of drop-in directories:</p> <ul> <li><code>/etc/flightctl/conf.d/</code>: Drop-in directory for the agent configuration.</li> <li><code>/etc/flightctl/hooks.d/</code>: Drop-in directory for device lifecycle hooks. Overrides hooks of the same name under <code>/usr/lib/flightctl/hooks.d</code>.</li> <li><code>/usr/lib/flightctl/hooks.d/</code>: Drop-in directory for device lifecycle hooks.</li> <li><code>/usr/lib/flightctl/custom-info.d/</code>: Drop-in directory for custom system info collectors.</li> </ul>"},{"location":"user/configuring-agent/#agent-configyaml-configuration-file","title":"Agent <code>config.yaml</code> configuration file","text":"<p>The agent's configuration file <code>/etc/flightctl/config.yaml</code> takes the following parameters:</p> Parameter Type Required Description <code>enrollment-service</code> <code>EnrollmentService</code> Y Connection details for the device owner's Flight Control service used by the agent to enroll the device. <code>spec-fetch-interval</code> <code>Duration</code> Interval in which the agent polls the service for updates to its device specification. Default: <code>60s</code> <code>status-update-interval</code> <code>Duration</code> Interval in which the agent reports its device status under normal conditions. The agent immediately sends status reports on major events related to the health of the system and application workloads as well as on the progress during a system update. Default: <code>60s</code> <code>default-labels</code> <code>object</code> (<code>string</code>) Labels (<code>key: value</code>-pairs) that the agent requests for the device during enrollment. Default: <code>{}</code> <code>system-info</code> <code>array</code> (<code>string</code>) System info that the agent shall include in status updates from built-in collectors. See Built-in system info collectors. Default: <code>[\"hostname\", \"kernel\", \"distroName\", \"distroVersion\", \"productName\", \"productUuid\", \"productSerial\", \"netInterfaceDefault\", \"netIpDefault\", \"netMacDefault\"]</code> <code>system-info-custom</code> <code>array</code> (<code>string</code>) System info that the agent shall include in status updates from user-defined collectors. See Custom system info collectors. Default: <code>[]</code> <code>system-info-timeout</code> <code>Duration</code> The timeout for collecting system info. Default: <code>2m</code> <code>log-level</code> <code>string</code> The level of logging: \"panic\", \"fatal\", \"error\", \"warn\"/\"warning\", \"info\", \"debug\", or \"trace\". Default: <code>info</code> <p><code>Duration</code> values are strings of an integer value with appended unit of time ('s' for seconds, 'm' for minutes, or 'h' for hours). Examples: <code>30s</code>, <code>10m</code>, <code>24h</code></p> <p>[!NOTE] The <code>/etc/flightctl/conf.d/</code> drop-in directory supports only a subset of the agent configuration. Currently supported keys include: <code>log-level</code>, <code>system-info</code>, <code>system-info-custom</code>, and <code>system-info-timeout</code>.</p>"},{"location":"user/configuring-agent/#built-in-system-info-collectors","title":"Built-in system info collectors","text":"<p>The agent has a set of built-in collectors for system information. You can see the information collected by these collectors using the following command:</p> <pre><code>sudo flightctl-agent system-info | jq '.'\n</code></pre> <p>Out of these, the agent includes a standard set of system infos in its device status:</p> <pre><code>status:\n  [...]\n  systemInfo:\n    architecture: amd64\n    operatingSystem: linux\n    agentVersion: v0.7.0\n    bootID: 87f7e27e-bdc0-42b1-b909-6dc81fe43ea2\n</code></pre> <p>You can specify extra system infos to be included in the device status by listing them under the <code>system-info</code> configuration parameter:</p> System Info Description <code>hostname</code> The system hostname reported by the device <code>kernel</code> The running Linux kernel version <code>distroName</code> The name of the operating system distribution. <code>distroVersion</code> The version of the operating system distribution <code>productName</code> The system\u2019s product or model name (from DMI data) <code>productSerial</code> The hardware serial number (if available) <code>productUuid</code> The UUID of the system board or chassis <code>biosVendor</code> The vendor of the BIOS or firmware <code>biosVersion</code> The version of the BIOS or firmware <code>netInterfaceDefault</code> The name of the default network interface <code>netIpDefault</code> The first usable IP address of the default network interface <code>netMacDefault</code> The MAC address of the default network interface <code>gpu</code> Lists detected GPU devices <code>memoryTotalKb</code> Total memory (RAM) in kilobytes <code>cpuCores</code> Number of physical CPU cores detected <code>cpuProcessors</code> Number of logical processors detected <code>cpuModel</code> CPU vendor and model name <p>For example, if you add the following parameter to your agent's <code>config.yaml</code></p> <pre><code>system-info: [hostname, kernel, distroName, distroVersion]\n</code></pre> <p>then the reported device status might look like</p> <pre><code>status:\n  [...]\n  systemInfo:\n    architecture: amd64\n    operatingSystem: linux\n    agentVersion: v0.7.0\n    bootID: 87f7e27e-bdc0-42b1-b909-6dc81fe43ea2\n    hostname: device.example.com\n    kernel: 5.14.0-503.38.1.el9_5.x86_64\n    distroName: Red Hat Enterprise Linux\n    distroVersion: 9.5 (Plow)\n</code></pre>"},{"location":"user/configuring-agent/#custom-system-info-collectors","title":"Custom system info collectors","text":"<p>You can specify custom system info collectors that the agent calls and whose output it includes under <code>status.systemInfo.customInfo</code> in the device status.</p> <p>To add a key <code>myInfo</code>,</p> <ol> <li>add an executable with that name to <code>/usr/lib/flightctl/custom-info.d/</code> that when it is executed returns the desired value, and</li> <li>enable the collection and reporting of this info by adding the key <code>myInfo</code> to the agent's <code>config.yaml</code> under the <code>system-info-custom</code> configuration parameter.</li> </ol> <p>For example, to have the agent report the system's FIPS mode status, create a file <code>/usr/lib/flightctl/custom-info.d/fips</code> with the following content and \"executable\" file permissions:</p> <pre><code>#!/bin/sh\n\nfips-mode-setup --is-enabled\ncase $? in\n    0) echo \"enabled\";;\n    1) echo \"inconsistent\";;\n    2) echo \"disabled\";;\n    *) echo \"unknown\";;\nesac\n</code></pre> <p>Then, add the following to the agent's <code>config.yaml</code>:</p> <pre><code>system-info-custom: [fips]\n</code></pre> <p>The reported device status might look like</p> <pre><code>status:\n  [...]\n  systemInfo:\n    architecture: amd64\n    operatingSystem: linux\n    agentVersion: v0.7.0\n    bootID: 87f7e27e-bdc0-42b1-b909-6dc81fe43ea2\n    customInfo:\n      fips: disabled\n</code></pre>"},{"location":"user/configuring-agent/#flightctl-agent-system-info","title":"flightctl-agent system-info","text":"<p>You can run this command on a device to inspect the full system information collected by the agent:</p> <pre><code>flightctl-agent system-info\n</code></pre> <p>It prints a JSON summary of the device\u2019s hardware and OS, including:</p> <ul> <li>Architecture, OS, kernel, hostname</li> <li>CPU, memory, disks, network interfaces</li> <li>GPU (if available)</li> <li>BIOS/system identifiers</li> <li>Custom info (from user-defined collectors)</li> <li>Boot ID and time</li> </ul> <p>[!NOTE] This command is local-only and does not affect device state or communicate with the Flight Control service.</p>"},{"location":"user/database-migration/","title":"Flight Control Database Access Restriction","text":"<p>This document describes the database access restriction system implemented in Flight Control to enhance security by separating database privileges between migration operations and runtime services.</p>"},{"location":"user/database-migration/#overview","title":"Overview","text":"<p>Flight Control uses a three-user database access model for production deployments:</p> <ol> <li><code>admin</code> - Full superuser privileges for database administration and user creation</li> <li><code>flightctl_migrator</code> - Limited privileges for schema creation and migrations (following principle of least privilege)</li> <li><code>flightctl_app</code> - Limited privileges for runtime data operations (SELECT, INSERT, UPDATE, DELETE)</li> </ol> <p>This separation follows the principle of least privilege, ensuring that production services cannot accidentally modify database schema or structure, while maintaining clear separation between administrative, migration, and runtime operations.</p> <p>Security Note: The migration user has been designed with minimal privileges required for database schema operations. It does not have SUPERUSER, CREATEROLE, or CREATEDB privileges, which would grant excessive permissions like bypassing row-level security, creating/dropping roles, creating databases, or altering any database object. It also does not have data-plane permissions (SELECT, INSERT, UPDATE, DELETE) on tables, ensuring it cannot access or modify production data. Instead, it has only the specific privileges needed for schema migrations: CREATE privileges on schemas and databases, sequence usage for auto-increment fields, and function execution for migration operations.</p>"},{"location":"user/database-migration/#database-users","title":"Database Users","text":"<p>Flight Control uses exactly 3 database users for secure operation:</p>"},{"location":"user/database-migration/#1-admin-user-admin","title":"1. Admin User (<code>admin</code>)","text":"<ul> <li>Purpose: Database administration, user creation, and initial setup</li> <li>Privileges:</li> <li>SUPERUSER (full administrative privileges)</li> <li>Used to create other database users</li> <li>Database initialization and administrative tasks</li> <li>When used: Database container initialization and migration job user setup</li> <li>Password: <code>masterPassword</code> secret key</li> </ul>"},{"location":"user/database-migration/#2-migration-user-flightctl_migrator","title":"2. Migration User (<code>flightctl_migrator</code>)","text":"<ul> <li>Purpose: Schema creation, table modifications, and database migrations</li> <li>Privileges (following principle of least privilege):</li> <li>CONNECT to database</li> <li>CREATE on schema and database (for creating tables, indexes, sequences, functions, triggers)</li> <li>USAGE, SELECT on sequences in the public schema (needed for sequence operations during schema creation)</li> <li>EXECUTE on all functions in the public schema (needed for migration functions)</li> <li>Note: Migration user does NOT have data-plane permissions (SELECT, INSERT, UPDATE, DELETE) for security reasons - migrations only modify schema structure, not data</li> <li>When used: Only during database migrations and initial setup</li> <li>Password: <code>migrationPassword</code> secret key</li> </ul>"},{"location":"user/database-migration/#3-application-user-flightctl_app","title":"3. Application User (<code>flightctl_app</code>)","text":"<ul> <li>Purpose: Runtime data operations for all Flight Control services</li> <li>Privileges:</li> <li>CONNECT to database</li> <li>SELECT, INSERT, UPDATE, DELETE on all tables</li> <li>USAGE, SELECT on all sequences</li> <li>Automatic permission inheritance for new tables (via event triggers)</li> <li>When used: All runtime service operations (API, Worker, Periodic, Alert-Exporter)</li> <li>Password: <code>userPassword</code> secret key</li> </ul>"},{"location":"user/database-migration/#environment-variables","title":"Environment Variables","text":""},{"location":"user/database-migration/#for-runtime-services-api-worker-periodic-alert-exporter","title":"For Runtime Services (API, Worker, Periodic, Alert-Exporter)","text":"<pre><code># Application database user (used by all services during runtime)\nDB_USER=flightctl_app\nDB_PASSWORD=&lt;userPassword from secret&gt;\n</code></pre>"},{"location":"user/database-migration/#for-migration-operations-only","title":"For Migration Operations Only","text":"<pre><code># Migration database user (used only for migrations)\nDB_MIGRATION_USER=flightctl_migrator\nDB_MIGRATION_PASSWORD=&lt;migrationPassword from secret&gt;\n</code></pre>"},{"location":"user/database-migration/#for-database-administration-migration-job-setup-phase","title":"For Database Administration (Migration Job Setup Phase)","text":"<pre><code># Admin database user (used only for user creation and setup)\nDB_ADMIN_USER=admin\nDB_ADMIN_PASSWORD=&lt;masterPassword from secret&gt;\n</code></pre> <p>Security Note:</p> <ul> <li>Runtime services should never have access to migration or admin user credentials</li> <li>Only dedicated migration jobs/commands should have migration credentials</li> <li>Only database setup operations should have admin credentials</li> <li>This maintains proper privilege separation across all operations</li> </ul>"},{"location":"user/database-migration/#deployment-methods","title":"Deployment Methods","text":""},{"location":"user/database-migration/#helm-deployment","title":"Helm Deployment","text":"<p>The Helm deployment automatically handles user creation and migration:</p> <ol> <li>Database Secrets: Contains all 3 user credentials:</li> <li><code>masterUser</code> / <code>masterPassword</code>: Admin user for database setup</li> <li><code>user</code> / <code>userPassword</code>: Application user for runtime services</li> <li><code>migrationUser</code> / <code>migrationPassword</code>: Migration user for schema changes</li> <li>Migration Job: Post-install/post-upgrade hook that:</li> <li>Uses admin user to create migration and application users with appropriate privileges</li> <li>Runs database migrations using the migration user</li> <li>Sets up automatic permission granting for future tables</li> <li>Service Configuration: All runtime services use the application user only</li> </ol>"},{"location":"user/database-migration/#migration-job-process","title":"Migration Job Process","text":"<pre><code># 1. Wait for database to be ready\n# 2. Execute consolidated setup script from container image (/app/deploy/scripts/setup_database_users.sh) which:\n#    - Verifies database connectivity\n#    - Creates flightctl_migrator and flightctl_app users\n#    - Grants appropriate privileges\n#    - Sets up automatic permission inheritance\n# 3. Run database migrations using migration user\n</code></pre>"},{"location":"user/database-migration/#quadlet-deployment","title":"Quadlet Deployment","text":"<p>The quadlet deployment includes integrated user setup and migration:</p> <ol> <li>Database Container: Uses <code>flightctl_app</code> as the default user, with <code>admin</code> as the master user</li> <li>User Creation: Automatic setup of all 3 users during deployment</li> <li>Migration Execution: Runs migrations using a temporary container with migration user</li> <li>Service Configuration: All services connect using the application user</li> </ol>"},{"location":"user/database-migration/#deployment-process","title":"Deployment Process","text":"<pre><code># 1. Start database container\n# 2. Execute consolidated setup script (setup_database_users.sh)\n# 3. Run migrations using flightctl-db-migrate command\n# 4. Start all services with application user\n</code></pre>"},{"location":"user/database-migration/#migration-process","title":"Migration Process","text":""},{"location":"user/database-migration/#automatic-migration","title":"Automatic Migration","text":"<p>Database migrations are handled by dedicated tools and jobs:</p> <ul> <li>Helm deployments: Migration job runs automatically during install/upgrade</li> <li>Quadlet deployments: Migration runs during the deployment script</li> <li>Manual deployments: Use the <code>flightctl-db-migrate</code> command</li> </ul>"},{"location":"user/database-migration/#manual-migration","title":"Manual Migration","text":"<p>You can run migrations manually using the dedicated migration command:</p> <pre><code># Set migration environment variables\nexport DB_USER=flightctl_migrator\nexport DB_PASSWORD=&lt;migration_password&gt;\nexport DB_MIGRATION_USER=flightctl_migrator\nexport DB_MIGRATION_PASSWORD=&lt;migration_password&gt;\n\n# Run migration\nflightctl-db-migrate\n</code></pre> <p>Note: The migration command automatically uses the migration user credentials and runs all necessary database schema updates.</p>"},{"location":"user/database-migration/#security-features","title":"Security Features","text":""},{"location":"user/database-migration/#privilege-separation","title":"Privilege Separation","text":"<ul> <li>Runtime services cannot create or modify database schema</li> <li>Migration operations are isolated to specific deployment phases</li> <li>Credential separation: Runtime services only have application user credentials, never migration credentials</li> <li>Automatic permission granting ensures new tables are accessible to application user</li> </ul>"},{"location":"user/database-migration/#permission-inheritance","title":"Permission Inheritance","text":"<p>An event trigger automatically grants appropriate permissions to the application user when new tables or sequences are created:</p> <pre><code>CREATE EVENT TRIGGER grant_app_permissions_trigger\n    ON ddl_command_end\n    WHEN TAG IN ('CREATE TABLE', 'CREATE SEQUENCE')\n    EXECUTE FUNCTION grant_app_permissions();\n</code></pre>"},{"location":"user/database-migration/#database-user-validation","title":"Database User Validation","text":"<p>Services validate database connectivity and user privileges during startup, providing clear error messages if misconfigured.</p>"},{"location":"user/database-migration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user/database-migration/#common-issues","title":"Common Issues","text":""},{"location":"user/database-migration/#1-permission-denied-errors","title":"1. Permission Denied Errors","text":"<p>Symptom: Services fail with \"permission denied\" database errors Solution:</p> <ul> <li>Verify the application user has been created and granted proper privileges</li> <li>Check that migrations have been run with the migration user</li> <li>Ensure the application is connecting with the correct user credentials</li> </ul>"},{"location":"user/database-migration/#2-migration-failures","title":"2. Migration Failures","text":"<p>Symptom: Migration job fails during deployment Solution:</p> <ul> <li>Check database connectivity and admin user privileges</li> <li>Verify migration user credentials</li> <li>Review migration logs for specific error details</li> </ul>"},{"location":"user/database-migration/#3-user-creation-errors","title":"3. User Creation Errors","text":"<p>Symptom: Database user creation fails during setup Solution:</p> <ul> <li>Ensure admin user has CREATEDB and superuser privileges</li> <li>Check database connection parameters</li> <li>Verify password complexity requirements</li> </ul>"},{"location":"user/database-migration/#4-services-attempting-to-run-migrations","title":"4. Services Attempting to Run Migrations","text":"<p>Symptom: Services fail on startup with messages about migrations or schema creation Solution:</p> <ul> <li>Verify that migrations have been completed during deployment phase</li> <li>Check that services are using application user credentials (not migration credentials)</li> <li>Ensure the database schema is properly set up before starting services</li> </ul>"},{"location":"user/database-migration/#manual-user-setup","title":"Manual User Setup","text":"<p>If automatic user setup fails, you can manually create users using the consolidated database setup script:</p> <pre><code># Run the setup script (recommended approach used by all deployment methods)\n./deploy/scripts/setup_database_users.sh\n\n# Or with custom environment variables\nexport DB_HOST=your_db_host\nexport DB_PORT=5432\nexport DB_NAME=flightctl\nexport DB_ADMIN_USER=admin\nexport DB_ADMIN_PASSWORD=your_admin_password\nexport DB_MIGRATION_USER=flightctl_migrator\nexport DB_MIGRATION_PASSWORD=your_migration_password\nexport DB_APP_USER=flightctl_app\nexport DB_APP_PASSWORD=your_app_password\n\n./deploy/scripts/setup_database_users.sh\n</code></pre> <p>Note: All deployment methods (Helm, Quadlet, Manual) use the same consolidated setup script. For Helm deployments, the script is already included in the container image at <code>/app/deploy/scripts/setup_database_users.sh</code>. For other deployments, it's located at <code>deploy/scripts/setup_database_users.sh</code>. This script provides database connectivity checks, proper error handling, and uses the canonical SQL file, ensuring consistency and reliability across all deployment approaches.</p>"},{"location":"user/database-migration/#verification-commands","title":"Verification Commands","text":"<p>Check database secret structure:</p> <pre><code># Verify all 3 users are present in the secret\nkubectl get secret flightctl-db-secret -o jsonpath='{.data}' | jq 'keys'\n# Should show: [\"masterPassword\", \"masterUser\", \"migrationPassword\", \"migrationUser\", \"user\", \"userPassword\"]\n\n# Check individual user credentials (base64 encoded)\nkubectl get secret flightctl-db-secret -o jsonpath='{.data.masterUser}' | base64 -d\nkubectl get secret flightctl-db-secret -o jsonpath='{.data.user}' | base64 -d\nkubectl get secret flightctl-db-secret -o jsonpath='{.data.migrationUser}' | base64 -d\n</code></pre> <p>Check database user privileges:</p> <pre><code>-- List all 3 database users and their roles\nSELECT rolname, rolsuper, rolcreaterole, rolcreatedb, rolcanlogin\nFROM pg_roles\nWHERE rolname IN ('admin', 'flightctl_migrator', 'flightctl_app')\nORDER BY rolname;\n\n-- Check table permissions for application user\nSELECT tablename, privileges\nFROM (\n    SELECT schemaname, tablename,\n           array_to_string(array_agg(privilege_type), ', ') as privileges\n    FROM information_schema.table_privileges\n    WHERE grantee = 'flightctl_app' AND schemaname = 'public'\n    GROUP BY schemaname, tablename\n) t;\n</code></pre>"},{"location":"user/database-migration/#best-practices","title":"Best Practices","text":"<ol> <li>Use different passwords for all 3 database users (admin, migration, application)</li> <li>Rotate passwords regularly using your secret management system</li> <li>Monitor database permissions to ensure proper access restrictions</li> <li>Test migrations in non-production environments first</li> <li>Review migration logs for any permission or connectivity issues</li> <li>Audit user access - ensure services only have the minimum required credentials:</li> <li>Runtime services: Only application user credentials</li> <li>Migration operations: Only migration user credentials</li> <li>Database setup: Only admin user credentials</li> </ol>"},{"location":"user/device-api-statuses/","title":"Device API Statuses","text":"<p>The following sections document the various statuses reported by Flight Control's Device API. These statuses represent the service's view of the managed device, which is the last reported status from the device agent augmented by service's local context and user policies. The last reported status in turn may be outdated relative to the agent's current status due to reporting delays.</p>"},{"location":"user/device-api-statuses/#device-status","title":"Device Status","text":"<p>The Device Status represents the availability and health of the device's hardware resources and operating system.</p> <p>The <code>device.status.summary</code> field can have the following values:</p> Status Description Formal Definition<sup>1 <code>Online</code> All hardware resources and operating system services are reported to be healthy. <code>!deviceIsDisconnected &amp;&amp; !deviceIsRebooting &amp;&amp; \u2200 r\u2208{CPU, Memory, Disk}, status.resources[r]\u2208{Healthy}</code> <code>Degraded</code> One or more hardware resources or operating system services are reported to be degraded but in a still functional or recovering state. <code>!deviceIsDisconnected &amp;&amp; !deviceIsRebooting &amp;&amp; \u2200 r\u2208{CPU, Memory, Disk}, status.resources[r]\u2209{Error, Critical} &amp;&amp; \u2203 r\u2208{CPU, Memory, Disk}, status.resources[r]\u2208{Degraded}</code> <code>Error</code> One or more hardware resources or operating system services are reported to be in error or critical state. <code>!deviceIsDisconnected &amp;&amp; !deviceIsRebooting &amp;&amp; \u2203 r\u2208{CPU, Memory, Disk}, status.resources[r]\u2208{Error, Critical}</code> <code>Rebooting</code> The device is rebooting. <code>!deviceIsDisconnected &amp;&amp; deviceIsRebooting</code> <code>Offline</code> The device is disconnected from the service but may still be running. <code>deviceIsDisconnected</code> <p><sup>1</sup> For the detailed definitions derived from the device specs and statuses, see Helper Definitions.</p> <p>The following state diagram shows the possible transitions between device statuses, including when the corresponding device lifecycle hooks would be called.</p> <pre><code>stateDiagram\n    classDef transientNotReported stroke-dasharray:5 5\n    class ActivatingConfig transientNotReported\n\n    classDef notYetSupported fill:white\n    class PoweringOff notYetSupported\n    class PoweredOff notYetSupported\n    class PoweringOn notYetSupported\n\n    direction LR\n\n    state Unknown {\n        Offline\n    }\n    state Known {\n        state PoweredOn {\n            direction LR\n\n            [*] --&gt; Online\n            Online --&gt; Degraded\n            Online --&gt; Error\n\n            Degraded --&gt; Online\n            Degraded --&gt; Error\n\n            Error --&gt; Online\n            Error --&gt; Degraded\n\n            state beforeRebootingHook &lt;&lt;choice&gt;&gt;\n            state afterRebootingHook &lt;&lt;choice&gt;&gt;\n            Online --&gt; beforeRebootingHook\n            Degraded --&gt; beforeRebootingHook\n            Error --&gt; beforeRebootingHook\n            beforeRebootingHook --&gt; Rebooting: beforeRebooting hook\n            Rebooting --&gt; afterRebootingHook\n            afterRebootingHook --&gt; Online: afterRebooting hook\n        }\n\n        [*] --&gt; PoweredOn\n        PoweredOn --&gt; PoweringOff\n        PoweringOff --&gt; PoweredOff\n        PoweredOff --&gt; PoweringOn\n        PoweringOn --&gt; PoweredOn\n    }\n\n    [*] --&gt; Unknown\n    Unknown --&gt; Known\n    Known --&gt; Unknown</code></pre>"},{"location":"user/device-api-statuses/#device-update-status","title":"Device Update Status","text":"<p>The Device Update Status represents whether the device's currently running specification (OS, configuration, applications, etc.) matches the user's intent as expressed via the device spec or the fleet's device template.</p> <p>The <code>device.status.updated.status</code> field can have the following values:</p> Status Description Formal Definition<sup>1 <code>UpToDate</code> The device is updated to its device spec. If the device is member of a fleet, its device spec is at the same template version as its fleet's device template. <code>!deviceIsUpdating &amp;&amp; deviceIsUpdatedToDeviceSpec &amp;&amp; (deviceIsNotManaged \\|\\| deviceIsUpdatedToFleetSpec)</code> <code>Updating</code> The device is in the process of updating to its device spec. <code>deviceIsUpdating</code> <code>OutOfDate</code> The device is not updating and either not updated to its device spec or - if it is member of a fleet - its spec is not yet of the same template version as its fleet's device template. <code>!deviceIsUpdating &amp;&amp; (!deviceIsUpdatedToDeviceSpec \\|\\| (deviceIsManaged &amp;&amp; !deviceIsUpdatedToFleetSpec))</code> <code>Unknown</code> The device's agent either never reported status or its last reported status was <code>Updating</code> and the device has been disconnected since. <code>deviceIsDisconnected &amp;&amp; lastStatus == Updating</code> <p><sup>1</sup> For the detailed definitions derived from the device specs and statuses, see Helper Definitions.</p> <p>The <code>device.status.conditions.Updating.Reason</code> field contains the current state of the update in progress and can take the following values:</p> Update State Description <code>Preparing</code> The agent is validating the desired device spec and downloading dependencies. No changes have been made to the device's configuration yet. <code>ReadyToUpdate</code> The agent has validated the desired spec, downloaded all dependencies, and is ready to update. No changes have been made to the device's configuration yet. <code>ApplyingUpdate</code> The agent has started the update transaction and is writing the update to disk. <code>Rebooting</code> The agent initiated a reboot required to activate the new OS image and configuration. <code>ActivatingConfig</code> (transient, not reported) The agent is activating the new configuration without requiring a reboot. <code>RollingBack</code> The agent has detected an error and is rolling back to the pre-update OS image and configuration. <code>Updated</code> The agent has successfully completed the update and the device is conforming to its device spec. Note that the device's update status may still be reported as <code>OutOfDate</code> if the device spec is not yet at the same version as the fleet's device template. <code>Error</code> The agent failed to apply the desired spec and will not retry. The device's OS image and configuration have been rolled back to the pre-update version and have been activated. <p>The <code>device.status.updated.info</code> field contains a human readable more detailed information about the last state transition.</p> <p>The following state diagram shows the possible transitions between update statuses and states, including when the corresponding device lifecycle hooks would be called.</p> <pre><code>stateDiagram\n    classDef transientNotReported stroke-dasharray:5 5\n    class ActivatingConfig transientNotReported\n\n    classDef notYetSupported fill:white\n    class Canceled notYetSupported\n\n    direction LR\n\n    Unknown\n    state Known {\n        direction LR\n\n        UpToDate\n        state Updating {\n            state beforeUpdatingHook &lt;&lt;choice&gt;&gt;\n            state beforeRebootingHook &lt;&lt;choice&gt;&gt;\n            state afterRebootingHook &lt;&lt;choice&gt;&gt;\n            state afterUpdatingHook &lt;&lt;choice&gt;&gt;\n\n            [*] --&gt; Preparing\n            Preparing --&gt; ReadyToUpdate\n            Preparing --&gt; Canceled\n            Preparing --&gt; Error: on error\n            ReadyToUpdate --&gt; beforeUpdatingHook: beforeUpdatingHook\n            ReadyToUpdate --&gt; Canceled\n            beforeUpdatingHook --&gt; ApplyingUpdate\n            ApplyingUpdate --&gt; beforeRebootingHook: if OS updated\n            ApplyingUpdate --&gt; ActivatingConfig: if OS not updated\n            ApplyingUpdate --&gt; RollingBack: on error\n            beforeRebootingHook --&gt; Rebooting: beforeRebooting hook\n            Rebooting --&gt; afterRebootingHook\n            afterRebootingHook --&gt; ActivatingConfig: afterRebooting hook\n            Rebooting --&gt; RollingBack: on greenboot failed\n            ActivatingConfig --&gt; afterUpdatingHook: afterUpdating hook\n            afterUpdatingHook --&gt; Updated\n            afterUpdatingHook --&gt; RollingBack: on error\n            RollingBack --&gt; Error\n\n            Updated --&gt; [*]\n            Canceled --&gt; [*]\n            Error --&gt; [*]\n        }\n\n        [*] --&gt; UpToDate\n        UpToDate --&gt; OutOfDate\n        OutOfDate --&gt; Updating\n        Updating --&gt; UpToDate\n        Updating --&gt; OutOfDate\n    }\n\n    [*] --&gt; Unknown\n    Unknown --&gt; Known\n    Known --&gt; Unknown</code></pre>"},{"location":"user/device-api-statuses/#application-status","title":"Application Status","text":"<p>The Application Status represents a summary of the availability and health of all applications on the system.</p> <p>The <code>device.status.applicationSummary</code> field can have the following values:</p> Status Description Formal Definition<sup>1 <code>Healthy</code> All applications are reported to be in service or have successfully completed. <code>!deviceIsDisconnected &amp;&amp; \u2200 a\u2208status.applications, status.applications[a]\u2208{Running, Completed}</code> <code>Degraded</code> One or more applications are reported to not be in service but still in a starting or recovering state. <code>!deviceIsDisconnected &amp;&amp; \u2200 a\u2208status.applications, status.applications[a]\u2209{Error} &amp;&amp; \u2203 a\u2208status.applications, status.applications[a]\u2208{Preparing, Starting}</code> <code>Error</code> One or more applications are reported to be in error state. <code>!deviceIsDisconnected &amp;&amp; \u2203 a\u2208status.applications, status.applications[a]\u2208{Error}</code> <code>Unknown</code> The device's agent either never reported status or the device is currently disconnected. <code>deviceIsDisconnected</code> <p><sup>1</sup> For the detailed definitions derived from the device specs and statuses, see Helper Definitions.</p> <p>The following state diagram shows the possible transitions between application summary statuses.</p> <pre><code>stateDiagram\n    classDef transientNotReported stroke-dasharray:5 5\n    class ActivatingConfig transientNotReported\n\n    classDef notYetSupported fill:white\n    class PoweringOff notYetSupported\n    class PoweredOff notYetSupported\n    class PoweringOn notYetSupported\n\n    direction LR\n\n    Unknown\n    state Known {\n        direction LR\n\n        [*] --&gt; Healthy\n        Healthy --&gt; Degraded\n        Healthy --&gt; Error\n\n        Degraded --&gt; Healthy\n        Degraded --&gt; Error\n\n        Error --&gt; Healthy\n        Error --&gt; Degraded\n    }\n\n    [*] --&gt; Unknown\n    Unknown --&gt; Known\n    Known --&gt; Unknown</code></pre>"},{"location":"user/device-api-statuses/#helper-definitions","title":"Helper Definitions","text":"<p>The formal definition uses the following helper definitions:</p> <pre><code>// A device is assumed disconnected if its agent hasn't sent an update for the duration of a disconnectionTimeout.\ndeviceIsDisconnected := device.status.lastSeen + disconnectionTimeout &lt; time.Now()\n\n// A device is not managed by a fleet if its owner field is unset.\ndeviceIsNotManaged := len(device.metadata.owner) == 0\n\n// A device is rebooting when the agent sets the \"Rebooting\" condition to true.\ndeviceIsRebooting := device.status.conditions.rebooting == true\n\n// A device is updating when the agent sets the \"Updating\" condition to true.\ndeviceIsUpdating := device.status.conditions.updating == true\n\n// A device is updated to its device spec when the version of the device spec that the agent reports as running\n// equals the version rendered to the device by the service.\ndeviceIsUpdatedToDeviceSpec := device.status.config.renderedVersion == device.metadata.annotations.renderedVersion\n\n// A device is updated to it's fleet's spec when it is updated to its device spec and that device spec's\n// template version matches the device's fleet's template version.\ndeviceIsUpdatedToFleetSoec := deviceIsUpdatedToDeviceSpec &amp;&amp; device.metadata.annotations.templateVersion == fleet[device.metadata.owner].spec.templateVersion\n</code></pre>"},{"location":"user/disconnected-cluster/","title":"Installing a Flight Control in a Disconnected Cluster Environment","text":""},{"location":"user/disconnected-cluster/#mirroring-images","title":"Mirroring images","text":""},{"location":"user/disconnected-cluster/#mirroring-flightctl-images","title":"Mirroring flightctl images","text":"<pre><code>export FCTL_VERSION=&lt;required_flightctl_version&gt;\nexport LOCAL_REGISTRY=&lt;registry-hostname&gt;:&lt;registry-port&gt;\n</code></pre> <p>\ud83d\udccc Please note, that you may need to provide credentials for your local registry via <code>oc image mirror -a &lt;creds_file&gt;</code>.</p> <pre><code>for component in api periodic ui worker; do oc image mirror quay.io/flightctl/flightctl-$component:${FCTL_VERSION} ${LOCAL_REGISTRY}/flightctl/flightctl-$component:${FCTL_VERSION}; done\n</code></pre> <p>If you cannot connect directly to hub's registry, you will have to mirror images to a disk or USB stick and bring the mirrored content to the disconnected management hub. Then mirror the content to a hub's registry.</p> <p>Example:</p> <pre><code>#on machine connected to internet\noc image mirror quay.io/&lt;img&gt; file://path/&lt;img&gt;\n#on disconnected environment\noc image mirror file://path/&lt;img&gt; ${LOCAL_REGISTRY}/&lt;img&gt;\n</code></pre>"},{"location":"user/disconnected-cluster/#mirroring-other-images","title":"Mirroring other images","text":"<pre><code>oc image mirror quay.io/keycloak/keycloak:25.0.1 ${LOCAL_REGISTRY}/keycloak/keycloak:25.0.1\n\noc image mirror quay.io/openshift/origin-cli:4.20.0 ${LOCAL_REGISTRY}/openshift/origin-cli:4.20.0\n\noc image mirror quay.io/sclorg/postgresql-16-c9s:20250214 ${LOCAL_REGISTRY}/sclorg/postgresql-16-c9s:20250214\n\noc image mirror docker.io/redis:7.4.1 ${LOCAL_REGISTRY}/redis:7.4.1\n</code></pre>"},{"location":"user/disconnected-cluster/#configuring-image-repository-mirroring","title":"Configuring image repository mirroring","text":"<p>Create <code>ImageTagMirrorSet</code> with the following content</p> <pre><code>oc apply -f - &lt;&lt;EOF\napiVersion: config.openshift.io/v1\nkind: ImageTagMirrorSet\nmetadata:\n  name: image-mirror\nspec:\n  imageTagMirrors:\n  - source: quay.io/flightctl\n    mirrors:\n    - ${LOCAL_REGISTRY}/flightctl\n  - source: quay.io/sclorg\n    mirrors:\n    - ${LOCAL_REGISTRY}/sclorg\n  - source: quay.io/keycloak\n    mirrors:\n    - ${LOCAL_REGISTRY}/keycloak\n  - source: quay.io/openshift/origin-cli\n    mirrors:\n    - ${LOCAL_REGISTRY}/openshift/origin-cli\n  - source: docker.io/redis\n    mirrors:\n    - ${LOCAL_REGISTRY}/redis\nEOF\n</code></pre> <p>After creating/editing <code>ImageTagMirrorSet</code>, the OpenShift will drain all nodes. You will need to wait for all nodes to return to <code>Ready</code> state.</p>"},{"location":"user/disconnected-cluster/#installing-flightctl","title":"Installing flightctl","text":"<p>You need to download the helm chart first, as it is stored in quay.io</p> <pre><code>#on machine connected to internet\nhelm pull oci://quay.io/flightctl/charts/flightctl --version ${FCTL_VERSION}\n#copy the downloaded file to disconnected environment\n#on disconnected environment\nhelm upgrade --install --namespace flightctl --create-namespace flightctl ./flightctl-${FCTL_VERSION}.tgz\n</code></pre> <p>If you modify any image location/tag in helm chart, you need to ensure that you run <code>oc image mirror</code> for the modified image location/tag and <code>ImageTagMirrorSet</code> has proper mirrors set.</p>"},{"location":"user/field-selectors/","title":"Field Selectors","text":"<p>Field selectors filter a list of Flight Control resources based on specific resource field values. They follow the same syntax, principles, and operators as Kubernetes Field and Label selectors, with additional operators available for more advanced search use cases.</p>"},{"location":"user/field-selectors/#supported-fields","title":"Supported Fields","text":"<p>Flight Control resources provide a set of metadata fields that can be selected.</p> <p>Each resource supports the following metadata fields:</p> <ul> <li><code>metadata.name</code></li> <li><code>metadata.owner</code></li> <li><code>metadata.creationTimestamp</code></li> </ul> <p>[!NOTE] To query labels, use Label Selectors for advanced and flexible label filtering.</p>"},{"location":"user/field-selectors/#list-of-additional-supported-fields","title":"List of Additional Supported Fields","text":"<p>In addition to the metadata fields, each resource has its own unique set of fields that can be selected, offering further flexibility in filtering and selection based on resource-specific attributes.</p> <p>The following table lists the fields supported for filtering for each resource kind:</p> Kind Fields Certificate Signing Request <code>status.certificate</code> Device <code>status.summary.status</code><code>status.applicationsSummary.status</code><code>status.updated.status</code><code>status.lastSeen</code><code>status.lifecycle.status</code> Enrollment Request <code>status.approval.approved</code><code>status.certificate</code> Fleet <code>spec.template.spec.os.image</code> Repository <code>spec.type</code><code>spec.url</code> Resource Sync <code>spec.repository</code>"},{"location":"user/field-selectors/#examples","title":"Examples","text":""},{"location":"user/field-selectors/#example-1-excluding-a-specific-device-by-name","title":"Example 1: Excluding a Specific Device by Name","text":"<p>The following command filters out a specific device by its name:</p> <pre><code>flightctl get devices --field-selector 'metadata.name!=c3tkb18x9fw32fzx5l556n0p0dracwbl4uiojxu19g2'\n</code></pre>"},{"location":"user/field-selectors/#example-2-filter-by-owner-labels-and-creation-timestamp","title":"Example 2: Filter by Owner, Labels, and Creation Timestamp","text":"<p>This command retrieves devices owned by <code>Fleet/pos-fleet</code>, located in the <code>us</code> region, and created in 2024:</p> <pre><code>flightctl get devices --field-selector 'metadata.owner=Fleet/pos-fleet, metadata.creationTimestamp &gt;= 2024-01-01T00:00:00Z, metadata.creationTimestamp &lt; 2025-01-01T00:00:00Z' -l 'region=us'\n</code></pre>"},{"location":"user/field-selectors/#example-3-filter-by-owner-labels-and-device-status","title":"Example 3: Filter by Owner, Labels, and Device Status","text":"<p>This command retrieves devices owned by <code>Fleet/pos-fleet</code>, located in the <code>us</code> region, and with a <code>status.updated.status</code> of either <code>Unknown</code> or <code>OutOfDate</code>:</p> <pre><code>flightctl get devices --field-selector 'metadata.owner=Fleet/pos-fleet, status.updated.status in (Unknown, OutOfDate)' -l 'region=us'\n</code></pre>"},{"location":"user/field-selectors/#fields-discovery","title":"Fields Discovery","text":"<p>Some Flight Control resources might expose additional supported fields. You can discover the supported fields by using <code>flightctl</code> with the <code>--field-selector</code> option. If you attempt to use an unsupported field, the error message will list the available supported fields.</p> <p>For example:</p> <pre><code>flightctl get device --field-selector='text'\n\nError: listing devices: 400, message: unknown or unsupported selector: unable to resolve selector name \"text\". Supported selectors are: [metadata.alias metadata.creationTimestamp metadata.name metadata.nameOrAlias metadata.owner status.applicationsSummary.status status.lastSeen status.summary.status status.updated.status]\n</code></pre> <p>In this example, the field <code>text</code> is not a valid field for filtering. The error message provides a list of supported fields that can be used with <code>--field-selector</code> for the <code>device</code> resource.</p> <p>You can then use one of the supported fields, as shown below:</p> <pre><code>flightctl get devices --field-selector 'metadata.alias contains cluster'\n</code></pre> <p>In this command, the <code>metadata.alias</code> field is checked with the containment operator <code>contains</code> to see if it contains the value <code>cluster</code>.</p>"},{"location":"user/field-selectors/#supported-operators","title":"Supported operators","text":"Operator Symbol Description Exists <code>&lt;field&gt;</code> Checks if a field exists. For example, the <code>--field-selector 'metadata.owner'</code> field selector returns resources that have the <code>metadata.owner</code> field. DoesNotExist <code>!</code> Checks if a field does not exist Equals <code>=</code> Checks if a field is equal to a value DoubleEquals <code>==</code> Another form of equality check NotEquals <code>!=</code> Checks if a field is not equal to a value GreaterThan <code>&gt;</code> Checks if a field is greater than a value GreaterThanOrEquals <code>&gt;=</code> Checks if a field is greater than or equal to a value LessThan <code>&lt;</code> Checks if a field is less than a value LessThanOrEquals <code>&lt;=</code> Checks if a field is less than or equal to a value In <code>in</code> Checks if a field is within a list of values NotIn <code>notin</code> Checks if a field is not in a list of values Contains <code>contains</code> Checks if a field contains a value NotContains <code>notcontains</code> Checks if a field does not contain a value"},{"location":"user/field-selectors/#operators-usage-by-field-type","title":"Operators Usage by Field Type","text":"<p>Each field type supports a specific subset of operators, listed below:</p> Field Type Supported Operators Value String <code>Equals</code>: Matches if the field value is an exact match to the specified string. <code>DoubleEquals</code>: Matches if the field value is an exact match to the specified string (alternative to <code>Equals</code>). <code>NotEquals</code>: Matches if the field value is not an exact match to the specified string. <code>In</code>: Matches if the field value matches at least one string in the list. <code>NotIn</code>: Matches if the field value does not match any of the strings in the list. <code>Contains</code>: Matches if the field value contains the specified substring. <code>NotContains</code>: Matches if the field value does not contain the specified substring. <code>Exists</code>: Matches if the field is present. <code>DoesNotExist</code>: Matches if the field is not present. Text string Timestamp <code>Equals</code>: Matches if the field value is an exact match to the specified timestamp. <code>DoubleEquals</code>: Matches if the field value is an exact match to the specified timestamp (alternative to <code>Equals</code>). <code>NotEquals</code>: Matches if the field value is not an exact match to the specified timestamp. <code>GreaterThan</code>: Matches if the field value is after the specified timestamp. <code>GreaterThanOrEquals</code>: Matches if the field value is after or equal to the specified timestamp. <code>LessThan</code>: Matches if the field value is before the specified timestamp. <code>LessThanOrEquals</code>: Matches if the field value is before or equal to the specified timestamp. <code>In</code>: Matches if the field value matches at least one timestamp in the list. <code>NotIn</code>: Matches if the field value does not match any of the timestamps in the list. <code>Exists</code>: Matches if the field is present. <code>DoesNotExist</code>: Matches if the field is not present. RFC 3339 format Number <code>Equals</code>: Matches if the field value equals the specified number. <code>DoubleEquals</code>: Matches if the field value equals the specified number (alternative to <code>Equals</code>). <code>NotEquals</code>: Matches if the field value does not equal to the specified number. <code>GreaterThan</code>: Matches if the field value is greater than the specified number. <code>GreaterThanOrEquals</code>: Matches if the field value is greater than or equal to the specified number. <code>LessThan</code>: Matches if the field value is less than the specified number. <code>LessThanOrEquals</code>: Matches if the field value is less than or equal to the specified number. <code>In</code>: Matches if the field value equals at least one number in the list. <code>NotIn</code>: Matches if the field value does not equal any numbers in the list. <code>Exists</code>: Matches if the field is present. <code>DoesNotExist</code>: Matches if the field is not present. Number format Boolean <code>Equals</code>: Matches if the value is <code>true</code> or <code>false</code>. <code>DoubleEquals</code>: Matches if the value is <code>true</code> or <code>false</code> (alternative to <code>Equals</code>). <code>NotEquals</code>: Matches if the value is the opposite of the specified value. <code>In</code>: Matches if the value (<code>true</code> or <code>false</code>) is in the list.Note: The list can only contain <code>true</code> or <code>false</code>, so this operator is limited in use. <code>NotIn</code>: Matches if the value is not in the list. <code>Exists</code>: Matches if the field is present. <code>DoesNotExist</code>: Matches if the field is not present. Boolean format (<code>true</code>, <code>false</code>) Array <code>Contains</code>: Matches if the array contains the specified value. <code>NotContains</code>: Matches if the array does not contain the specified value. <code>In</code>: Matches if the array overlaps with the specified values. <code>NotIn</code>: Matches if the array does not overlap with the specified values. <code>Exists</code>: Matches if the field is present. <code>DoesNotExist</code>: Matches if the field is not present. Array element"},{"location":"user/getting-started/","title":"Getting Started","text":"<p>The following are the recommended ways of getting started with Flight Control. Choose the method that best matches your environment and additional requirements. Please refer to Installing the Flight Control CLI for other installation options.</p>"},{"location":"user/getting-started/#deploying-a-local-kind-cluster","title":"Deploying a Local Kind Cluster","text":"<p>Install the following prerequisites by following the respective documentation:</p> <ul> <li><code>kind</code> latest version (installation guide)</li> <li><code>kubectl</code> CLI of a matching version (installation guide)</li> <li><code>helm</code> CLI version v3.15 or later (installation guide)</li> </ul> <p>Deploy a Kind cluster:</p> <pre><code>$ kind create cluster\n\nenabling experimental podman provider\nCreating cluster \"kind\" ...\n</code></pre> <p>Verify the cluster is up and you can access it:</p> <pre><code>$ kubectl get pods -A\n\nNAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE\nkube-system          coredns-76f75df574-v6plv                     1/1     Running   0          49s\nkube-system          coredns-76f75df574-xfm2w                     1/1     Running   0          49s\nkube-system          etcd-kind-control-plane                      1/1     Running   0          61s\nkube-system          kindnet-kznkx                                1/1     Running   0          49s\nkube-system          kube-apiserver-kind-control-plane            1/1     Running   0          61s\nkube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          61s\nkube-system          kube-proxy-qffqj                             1/1     Running   0          49s\nkube-system          kube-scheduler-kind-control-plane            1/1     Running   0          65s\nlocal-path-storage   local-path-provisioner-7577fdbbfb-wxbck      1/1     Running   0          49s\n</code></pre> <p>Verify Helm is installed and can access the cluster:</p> <pre><code>helm list\n</code></pre>"},{"location":"user/getting-started/#deploying-the-flight-control-service","title":"Deploying the Flight Control Service","text":""},{"location":"user/getting-started/#standalone-flight-control-on-k8skind","title":"Standalone Flight Control on k8s/KIND","text":"<p>Start your k8s/KIND cluster. For KIND cluster you can use the example config file <code>deploy/kind.yaml</code> from the repository.</p> <pre><code>kind create cluster --config kind.yaml\n</code></pre> <p>Install a released version of the Flight Control Service into the cluster by running:</p> <pre><code>FC_NAMESPACE=flightctl\nhelm upgrade --install --version=&lt;version-to-install&gt; \\\n    --namespace $FC_NAMESPACE --create-namespace \\\n    flightctl oci://quay.io/flightctl/charts/flightctl \\\n    --set global.baseDomain=${YOUR_IP}.nip.io \\\n    --set global.exposeServicesMethod=nodePort\n</code></pre> <p>Optionally, you may change the deployed UI version adding <code>--set ui.image.tag=&lt;ui-version-to-install&gt;</code>. Available versions can be found in quay.io</p>"},{"location":"user/getting-started/#flight-control-on-openshift","title":"Flight Control on OpenShift","text":""},{"location":"user/getting-started/#standalone-flight-control-with-built-in-keycloak","title":"Standalone Flight Control with built-in Keycloak","text":"<p>Install a released version of the Flight Control Service into the cluster by running:</p> <pre><code>FC_NAMESPACE=flightctl\nhelm upgrade --install --version=&lt;version-to-install&gt; \\\n    --namespace $FC_NAMESPACE --create-namespace \\\n    flightctl oci://quay.io/flightctl/charts/flightctl\n</code></pre> <p>Verify your Flight Control Service is up and running:</p> <pre><code>kubectl get pods -n flightctl\n</code></pre>"},{"location":"user/getting-started/#standalone-flight-control-with-external-oidc","title":"Standalone Flight Control with external OIDC","text":"<p>Create a values.yaml file with the following content</p> <pre><code>global:\n  auth:\n    type: oidc\n    oidc:\n      oidcAuthority: https://oidc/realms/your_realm \n      externalOidcAuthority: https://external.oidc/realms/your_realm\n</code></pre> <p>Install a released version of the Flight Control Service into the cluster by running:</p> <pre><code>helm upgrade --install --version=&lt;version-to-install&gt; \\\n    --namespace flightctl --create-namespace \\\n    flightctl oci://quay.io/flightctl/charts/flightctl \\\n    --values values.yaml\n</code></pre> <p>Verify your Flight Control Service is up and running:</p> <pre><code>kubectl get pods -n flightctl\n</code></pre>"},{"location":"user/getting-started/#flight-control-in-acm","title":"Flight Control in ACM","text":"<p>To install a released version of the Flight Control Service into the cluster, first ensure you have a <code>values.acm.yaml</code> file.</p> <p>If you are not running helm from the base directory of this repository, you can find it at <code>deploy/helm/flightctl/values.acm.yaml</code>, otherwise you will need to create it.</p> <p>Then run the following command, making sure to specify the correct path to <code>values.acm.yaml</code>:</p> <pre><code>helm upgrade --install --version=&lt;version-to-install&gt; \\\n    --namespace flightctl --create-namespace \\\n    flightctl oci://quay.io/flightctl/charts/flightctl \\\n    --values deploy/helm/flightctl/values.acm.yaml\n</code></pre> <p>Optionally, you may change the deployed UI version adding <code>--set ui.image.tag=&lt;ui-version-to-install&gt;</code>. Available versions can be found in quay.io Verify your Flight Control Service is up and running:</p> <pre><code>kubectl get pods -n flightctl\n</code></pre> <p>After deploying the Flight Control ACM UI plugin, it needs to be manually enabled. Open your OpenShift Console -&gt; Home -&gt; Overview -&gt; Status card -&gt; Dynamic plugins and enable the Flight Control ACM UI plugin. After enabling the plugin, you will need to wait for the Console operator to rollout a new deployment.</p>"},{"location":"user/getting-started/#gathering-deployment-information","title":"Gathering deployment information","text":"<p>After the helm install command succeeded, it will print out a block of helpful information. It will look similar to:</p> <pre><code>Thank you for installing Flight Control.\n\n\nYou can access the Flight Control UI at &lt;UI_URL&gt;\nYou can access the Flight Control API at &lt;API_URL&gt;\n\nYou can login using the following CLI command:\n\n    flightctl login &lt;API_URL&gt; --insecure-skip-tls-verify --web\n</code></pre> <p>Lets store the API_URL as environment variable for later use.</p> <pre><code>FC_API_URL=&lt;API_URL&gt;\n</code></pre>"},{"location":"user/getting-started/#installing-the-flight-control-cli","title":"Installing the Flight Control CLI","text":"<p>In a terminal, select the appropriate Flight Control CLI binary for your OS (linux or darwin) and CPU architecture (amd64 or arm64), for example:</p> <pre><code>FC_CLI_BINARY=flightctl-linux-amd64\n</code></pre> <p>Download the <code>flightctl</code> binary to your machine:</p> <pre><code>$ curl -LO https://github.com/flightctl/flightctl/releases/latest/download/${FC_CLI_BINARY}\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 29.9M  100 29.9M    0     0  5965k      0  0:00:05  0:00:05 --:--:-- 7341k\n</code></pre> <p>Verify the downloaded binary has the correct checksum:</p> <pre><code>$ echo \"$(curl -L -s https://github.com/flightctl/flightctl/releases/download/latest/${FC_CLI_BINARY}-sha256.txt)  ${FC_CLI_BINARY}\" | shasum --check\n\nflightctl-linux-amd64: OK\n</code></pre> <p>If the checksum is correct, rename it to <code>flightctl</code> and make it executable:</p> <pre><code>mv \"${FC_CLI_BINARY}\" flightctl &amp;&amp; chmod +x flightctl\n</code></pre> <p>Finally, move it into a location within your shell's search path.</p>"},{"location":"user/getting-started/#logging-into-the-flight-control-service-from-the-cli","title":"Logging into the Flight Control Service from the CLI","text":""},{"location":"user/getting-started/#standalone-deployment","title":"Standalone deployment","text":"<p>Retrieve the password for the \"demouser\" account that's been automatically generated for you during installation:</p> <pre><code>FC_PASS=$(kubectl get secret/keycloak-demouser-secret -n $FC_NAMESPACE -o=jsonpath='{.data.password}' | base64 -d)\n</code></pre> <p>Headless login:</p> <pre><code>flightctl login ${FC_API_URL} -u demouser -p ${FC_PASS}\n</code></pre> <p>\ud83d\udccc For headless login to work, the OIDC provider of your choice needs to have Direct Access grant enabled</p> <p>Login using web browser:</p> <pre><code>flightctl login ${FC_API_URL} --web\n</code></pre>"},{"location":"user/getting-started/#acm-deployment","title":"ACM deployment","text":"<p>Login using a user token:</p> <pre><code>flightctl login ${FC_API_URL} -t $(oc whoami -t)\n</code></pre> <p>\ud83d\udccc You can also login with your ACM login credentials using the <code>--web</code> or <code>--username</code> and <code>--password</code> flags</p>"},{"location":"user/getting-started/#self-signed-certificates","title":"Self-signed certificates","text":"<p>The CLI uses the host's certificate authority (CA) pool to verify the Flight Control service's identity. When using self-signed certificates, this can lead to a TLS verification error if you have not added your CA's certificate to that pool. You can:</p> <ul> <li>add the path for the CA certificate via the <code>--certificate-authority=&lt;path_to_ca_crt&gt;</code> flag to your command</li> <li>or bypass the server verification (insecure!) by adding the <code>--insecure-skip-tls-verify</code> flag to your command</li> </ul>"},{"location":"user/getting-started/#building-a-bootable-container-image-including-the-flight-control-agent","title":"Building a Bootable Container Image including the Flight Control Agent","text":"<p>Next, we will use Podman to build a bootable container image (bootc) that includes the Flight Control Agent binary and configuration. The configuration contains the connection details and credentials required by the agent to discover the service and send an enrollment request to the service.</p> <p>Retrieve the agent configuration with enrollment credentials by running:</p> <pre><code>flightctl certificate request --signer=enrollment --expiration=365d --output=embedded &gt; agentconfig.yaml\n</code></pre> <p>The returned <code>agentconfig.yaml</code> should look similar to this:</p> <pre><code>$ cat agentconfig.yaml\nenrollment-service:\n  service:\n    server: https://agent-api.flightctl.127.0.0.1.nip.io:7443\n    certificate-authority-data: LS0tLS1CRUdJTiBD...\n  authentication:\n    client-certificate-data: LS0tLS1CRUdJTiBD...\n    client-key-data: LS0tLS1CRUdJTiBF...\n  enrollment-ui-endpoint: https://ui.flightctl.127.0.0.1.nip.io:8081\n</code></pre> <p>Create a <code>Containerfile</code> with the following content:</p> <pre><code>$ cat Containerfile\n\nFROM quay.io/centos-bootc/centos-bootc:stream9\n\nRUN dnf -y copr enable @redhat-et/flightctl &amp;&amp; \\\n    dnf -y install flightctl-agent; \\\n    dnf -y clean all; \\\n    systemctl enable flightctl-agent.service\n\n# Optional: to enable podman-compose application support uncomment below\u201d\n# RUN dnf -y install epel-release epel-next-release &amp;&amp; \\\n#    dnf -y install podman-compose &amp;&amp; \\\n#    systemctl enable podman.service\n\nADD agentconfig.yaml /etc/flightctl/config.yaml\n</code></pre> <p>Note this is a regular <code>Containerfile</code> that you're used to from Docker/Podman, with the difference that the base image referenced in the <code>FROM</code> directive is bootable. This means you can use standard container build tools and workflows.</p> <p>For example, as a user of Quay who has the privileges to push images into the <code>quay.io/${YOUR_QUAY_ORG}/centos-bootc-flightctl</code> repository, build the bootc image like this:</p> <pre><code>sudo podman build -t quay.io/${YOUR_QUAY_ORG}/centos-bootc-flightctl:v1 .\n</code></pre> <p>Log in to your Quay account:</p> <pre><code>$ sudo podman login quay.io\n\nUsername: ******\nPassword: ******\nLogin Succeeded!\n</code></pre> <p>Push your bootc image to Quay:</p> <pre><code>sudo podman push quay.io/${YOUR_QUAY_ORG}/centos-bootc-flightctl:v1\n</code></pre>"},{"location":"user/getting-started/#provisioning-a-device-with-a-bootable-container-image","title":"Provisioning a Device with a Bootable Container Image","text":"<p>A bootc image is a file system image, i.e. it contains the files to be written into an existing file system, but not the disk layout and the file system itself. To provision a device, you need to generate a full disk image containing the bootc image.</p> <p>Use the <code>bootc-image-builder</code> tool to generate that disk image as follows:</p> <pre><code>mkdir -p output &amp;&amp; \\\n  sudo podman run --rm -it --privileged --pull=newer --security-opt label=type:unconfined_t \\\n    -v ${PWD}/output:/output -v /var/lib/containers/storage:/var/lib/containers/storage \\\n    quay.io/centos-bootc/bootc-image-builder:latest \\\n    --type raw quay.io/${YOUR_QUAY_ORG}/centos-bootc-flightctl:v1\n</code></pre> <p>Once <code>bootc-image-builder</code> completes, you'll find the raw disk image under <code>output/image/disk.raw</code>. Now you can flash this image to a device using standard tools like arm-image-installer, Etcher, or <code>dd</code>.</p> <p>For other image types like QCoW2 or VMDK or ways to install via USB stick or network, see Building Images.</p>"},{"location":"user/getting-started/#enrolling-a-device","title":"Enrolling a Device","text":"<p>When the Flight Control Agent first starts, it sends an enrollment request to the Flight Control Service. You can see the list of requests pending approval with:</p> <pre><code>$ flightctl get enrollmentrequests\n\nNAME                                                  APPROVAL  APPROVER  APPROVED LABELS\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  Pending   &lt;none&gt;    &lt;none&gt;    \n</code></pre> <p>You can approve an enrollment request and optionally add labels to the device:</p> <pre><code>$ flightctl approve -l region=eu-west-1 -l site=factory-berlin er/54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg\n\nSuccess.\n\n$ flightctl get enrollmentrequests\n\nNAME                                                  APPROVAL  APPROVER  APPROVED LABELS\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  Approved  demouser  region=eu-west-1,site=factory-berlin\n</code></pre> <p>After the enrollment completes, you can find the device in the list of devices:</p> <pre><code>$ flightctl get devices\n\nNAME                                                  OWNER   SYSTEM  UPDATED     APPLICATIONS  LAST SEEN\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  &lt;none&gt;  Online  Up-to-date  &lt;none&gt;        3 seconds ago\n</code></pre>"},{"location":"user/getting-started/#where-to-go-from-here","title":"Where to go from here","text":"<p>Now that you have a Flight Control-managed device, refer to Managing Devices and Managing Fleets for how to configure and update individual or fleets of devices.</p>"},{"location":"user/install-cli/","title":"Installing the Flight Control CLI","text":"<p>To install <code>flightctl</code> on Linux, macOS and Windows operating systems you have to download and install the <code>flightctl</code> binary file.</p>"},{"location":"user/install-cli/#download-archive","title":"Download archive","text":"<ol> <li> <p>Click the \u2754 (question mark) icon in the upper part of the web console page and select \"Command Line Tools\" to be taken to the CLI downloads page.</p> </li> <li> <p>Choose a downloadable archive using proper architecture and OS. Click the file to download it.</p> </li> </ol>"},{"location":"user/install-cli/#installation","title":"Installation","text":"<ol> <li> <p>Install <code>flightctl</code></p> </li> <li> <p>For Linux OS</p> </li> <li> <p>Decompress the archive file</p> <pre><code>tar -xvf &lt;flightctl-os-arch&gt;.tar.gz\n</code></pre> </li> <li> <p>Run the following command to make the <code>flightctl</code> binary executable</p> <pre><code>chmod +x flightctl\n</code></pre> </li> <li> <p>Move the <code>flightctl</code> binary to a directory in your <code>PATH</code> environment variable. Usually it would be <code>/usr/local/bin</code> or <code>~/bin</code>.</p> <p>Don't forget to update <code>PATH</code> in the case you want to move the binary to another directory.</p> <p>To check <code>PATH</code> use:</p> <pre><code>echo $PATH\n</code></pre> </li> <li> <p>For Windows OS</p> <ul> <li> <p>Decompress the archive file</p> </li> <li> <p>Move the <code>flightctl.exe</code> binary to a directory in your <code>PATH</code> environment variable. Usually it would be <code>C:\\Program Files\\flightctl\\</code>.</p> </li> </ul> <p>Don't forget to update <code>PATH</code> in the case you want to move it to another directory.</p> <p>To check <code>PATH</code> use:</p> <pre><code>path\n</code></pre> </li> <li> <p>For macOS</p> <ul> <li> <p>Decompress the archive file</p> </li> <li> <p>Move the <code>flightctl</code> binary to a directory in your <code>PATH</code> environment variable. Usually it would be <code>/usr/local/bin</code> or <code>~/bin</code>.</p> </li> </ul> <p>Don't forget to update <code>PATH</code> in the case you want to move the binary to another directory.</p> <p>To check <code>PATH</code> use:</p> <pre><code>echo $PATH\n</code></pre> </li> </ol>"},{"location":"user/install-cli/#verification","title":"Verification","text":"<p>After installation, verify that <code>flightctl</code> is working correctly:</p> <pre><code>flightctl version\n</code></pre> <p>Note: If you get a \"command not found\" error, ensure the binary is in your <code>PATH</code>.</p>"},{"location":"user/introduction/","title":"Introduction","text":""},{"location":"user/introduction/#project-vision","title":"Project Vision","text":"<p>Flight Control aims to provide simple, scalable, and secure management of edge devices and applications. Users declare the operating system version, host configuration, and set of applications they want to run on an individual device or a whole fleet of devices, and Flight Control will roll out the target configuration to devices where a device agent will automatically apply them and report progress and health status back up.</p> <p>Flight Control is designed for modern, container-centric toolchains and operational best practices. It works best on image-based Linux operating systems running bootc or ostree and with container workloads running on Podman/Docker or Kubernetes.</p> <p>Features and use cases Flight Control aims to support:</p> <ul> <li>Declarative APIs well-suited for GitOps management.</li> <li>APIs are Kubernetes-like, so they should instantly feel familiar to Kubernetes users and allow them to reuse tools and toolchains.</li> <li>APIs do not depend on Kubernetes, though, and target a shallow learning curve for non-Kubernetes users.</li> <li>Web UI to manage and monitor devices and applications for ClickOps management.</li> <li>Fleet-level Management, allowing users to define a device template and management policy for a fleet that the system automatically applies to all current and future member devices.</li> <li>Container or VM workloads on Podman using docker-compose or Quadlets, Kubernetes services on MicroShift using kustomize or Helm.</li> <li>Agent-based architecture, allowing:</li> <li>scalable and robust management under adverse networking conditions (agent \"calls home\" when the device has connectivity),</li> <li>autonomous and safe OTA updates (agent downloads and verifies assets before updating, then transactionally updates or rolls back), and</li> <li>timely yet resource-unintensive monitoring of devices and applications (agent notifies service on update progress and alarms).</li> <li>A secure yet friction-free device lifecycle (enrollment, certificate rotation, attestation, and decommissioning) based on hardware root-of-trust.</li> <li>Pluggable identity/authentication providers (initially Keycloak / Generic OIDC Providers and OpenShift Authentication API)</li> <li>Pluggable authorization providers (initially SpiceDB and Kubernetes RBAC)</li> <li>Pluggable certificate providers (initially built-in CA and Kubernetes Cert-Manager)</li> </ul>"},{"location":"user/introduction/#concepts","title":"Concepts","text":"<p>Device - A combination of a (real or virtual) machine, operating system, and application workload(s) that function together to serve a specific purpose.</p> <p>Device Spec - A specification of the state (e.g. configuration) the user wants a Device to have.</p> <p>Device Status - A record of the state (e.g. configuration) that the Device is reported to actually have.</p> <p>Device Template - A template for Device Specs that serves to control drift between the configurations of Devices.</p> <p>Fleet - A group of Devices governed by a common Device Template and common management policies.</p> <p>Labels - A way for users to organize their Devices and other resources, for example to record their location (\"region=emea\", \"site=factory-berlin\"), hardware type (\"hw-model=jetson\", \"hw-generation=orin\"), or purpose (\"device-type=autonomous-forklift\").</p> <p>Label Selector - A way for users to group or filter their devices and other resources based on their assigned labels, e.g. \"all devices having 'site=factory-berlin' and 'device-type=autonomous-forklift').</p> <p>Field Selector - A way for users to filter and select Flight Control objects based on the values of specific resource fields. Field selectors follow the same syntax, principles, and support the same operators as Kubernetes Field and Label selectors.</p> <p>Service -  The Flight Control Service handles user and agent authentication and authorization, device enrollment and inventory, rolling out updates to devices, and rolling up status from devices.</p> <p>Agent - The Flight Control Agent runs on each device and is responsible for securely enrolling into the Service, querying the Service for updates, autonomously applying these updates, and reporting status on the updates and the health of devices back to the Service.</p>"},{"location":"user/introduction/#high-level-architecture","title":"High-Level Architecture","text":"<p>Flight Control consists of the highlighted components show in the following high-level architecture diagram:</p> <p> </p> <p>The Flight Control Service consists of an API server, worker processes (not shown), and a PostgreSQL database for storing inventory and runtime information such as the current target configuration and the reported actual configuration. The API server exposes two endpoints:</p> <ul> <li>The user-facing API endpoint is for users to connect to, typically from the CLI or web UI. Users on this endpoint must authenticate with the configured external authentication service to obtain a JWT token. They can then use this token when making requests via HTTPS.</li> <li>The agent-facing API endpoint is for agents to connect to and is mTLS-protected. That is, the service authenticates the device based on its X.509 client certificates. The device's unique certificate is bootstrapped during enrollment based on hardware root-of-trust, meaning the private key is protected by the TPM and so the client certificate cannot be used by another entity. Certificates are automatically rotated before they expire.</li> </ul> <p>The Flight Control Service talks to various external systems to authenticate and authorize users, get mTLS certificates signed, or query configuration for managed devices.</p> <p>The Flight Control Agent is a process running on each managed device. It always \"calls home\" to the Service, so the device can be on a private network or have a dynamic IP address. The agent handles the enrollment process with the service and periodically polls the Service for a new target configuration. It also periodically sends a heartbeat to the Service and notifies the Service when the device or application status changes relative to the desired target configuration.</p> <p>When the Agent receives a new target configuration from the Service, it</p> <ol> <li>downloads all required assets (OS image, application container images, etc.) over the network to disk, so it doesn't depend on network connectivity during the update,</li> <li>updates the OS image by delegating to bootc (or rpm-ostree),</li> <li>updates configuration files on the device's file system by overlaying a set of files sent to it by the Service,</li> <li>if necessary, reboots into the new OS, otherwise signals services to reload the updated configuration, and</li> <li>updates applications running on Podman or MicroShift by running the necessary commands.</li> </ol> <p>If applying any of these changes fails or the system does not return online after reboot (detected greenboot health-checks and optionally user-defined logic), the agent will rollback to the previous OS image and configuration.</p> <p>As the target configuration for devices and device fleets is declarative, users can store it in a Git repository that the Flight Control Service can periodically poll for updates or can receive updates from a webhook.</p>"},{"location":"user/kubernetes-auth/","title":"Authorization with Kubernetes","text":"<p>Flight control Kubernetes authorization uses a Role Based Access Control (RBAC) to control authorization for flight control API endpoints. Some <code>helm</code> configuration values are needed to be modified (see values.yaml global/auth section)</p> <p>The following variables need to be set:</p> <ul> <li>Set global.auth.type to k8s</li> <li>Optionally set global.auth.caCert, global.auth.insecureSkipTlsVerify</li> </ul> <p>With these settings, the k8s cluster on which Flight Control will be deployed, will be used as auth authority.</p> <p>If you want to use a different cluster as auth authority, the following variables need to be set too:</p> <ul> <li>Set global.auth.k8s.apiUrl to API URL of the external k8s cluster</li> <li>Set global.auth.k8s.externalApiToken to a token which has permission to CREATE <code>authentication.k8s.io/tokenreview</code> resource in the external k8s cluster</li> </ul> <p>If the k8s cluster is an OpenShift cluster, you can also set global.auth.k8s.externalOpenShiftApiUrl which enables interactive login for the CLI (<code>flightctl login &lt;fctl_url&gt; --web</code>)</p> <p>If deploying on ACM  (by global.target: acm), the k8s auth values are automatically calculated.</p>"},{"location":"user/kubernetes-auth/#kubernetes-rbac-authorization","title":"Kubernetes RBAC authorization","text":"<p>To use Kubernetes RBAC authorization either Role and RoleBinding or ClusterRole and ClusterRoleBinding must be used.</p> <p>Note: Role/RoleBinding are used for namespace based authorization.  ClusterRole/ClusterRoleBinding are used for cluster wide authorization (all namespaces in a cluster).</p> <p>API objects Role or ClusterRole, should be used to define the allowed API resources and verbs for a particular role.</p> <p>API objects RoleBinding or ClusterRoleBinding provide association between subjects (example users) to a specific role.</p>"},{"location":"user/kubernetes-auth/#api-endpoints","title":"API endpoints","text":"<p>API endpoints are documented in Authentication resources.  The resources and verbs in this document should be used for creating API objects Role or ClusterRole.</p>"},{"location":"user/managing-devices/","title":"Managing Devices","text":""},{"location":"user/managing-devices/#enrolling-devices","title":"Enrolling Devices","text":"<p>The first time the Flight Control Agent runs, it generates a cryptographic key pair that serves as the device's unique cryptographic identity. The pair's private key never leaves the device, so that the device cannot be duplicated or impersonated. The cryptographic identity is registered with the Flight Control Service during enrollment and gets wiped during device decommissioning.</p> <p>When the device is not yet enrolled, the agent performs service discovery to find its Flight Control Service instance. It then establishes a secure, mTLS-protected network connection to the Service using the X.509 enrollment certificate it has been provided with during image building or device provisioning. Next, it submits an Enrollment Request to the service that includes a description of the device's hardware and operating system as well as an X.509 Certificate Signing Request (CSR) including its cryptographic identity to obtain its initial management certificate. At this point, the device is not yet considered trusted and therefore remains quarantined in a \"device lobby\" until its Enrollment Request has been approved or denied by an authorized user (e.g. a administrator, an installer persona, or an auto-approver process).</p>"},{"location":"user/managing-devices/#enrolling-using-the-web-ui","title":"Enrolling using the Web UI","text":""},{"location":"user/managing-devices/#enrolling-using-the-cli","title":"Enrolling using the CLI","text":"<p>You can list all devices currently waiting to be approved by running the following command:</p> <pre><code>flightctl get enrollmentrequests\n</code></pre> <p>The output should look similar to this:</p> <pre><code>NAME                                                  APPROVAL  APPROVER  APPROVED LABELS\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  Pending   &lt;none&gt;    &lt;none&gt;    \n</code></pre> <p>The unique device name is generated by the agent and cannot be changed. By default, the agent chooses the \"device fingerprint\", a base32-encoded hash of the agent's public key, as device name.</p> <p>You can approve an Enrollment Request using the <code>flightctl approve</code> command and the name of the Enrollment Request to be approved. You can optionally also add labels to the device (see Organizing Devices) using the <code>--label</code> or <code>-l</code> flag. For example:</p> <pre><code>flightctl approve -l region=eu-west-1 -l site=factory-berlin enrollmentrequest/54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg\n</code></pre> <p>When listing devices waiting to be approved once more using the <code>flightctl get enrollmentrequests</code> command, the output should look similar to this:</p> <pre><code>NAME                                                  APPROVAL  APPROVER  APPROVED LABELS\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  Approved  demouser  region=eu-west-1,site=factory-berlin\n</code></pre> <p>Once approved, the device will get issued its initial management certificate and get registered to the device inventory and is now ready to be managed.</p>"},{"location":"user/managing-devices/#viewing-and-customizing-the-device-system-information","title":"Viewing and Customizing the Device System Information","text":"<p>Flight Control automatically gathers system information from each device to help identify its hardware, OS, and environment. This data is shown in the <code>status.systemInfo</code> field. Fields can optionally be promoted to labels during the enrollment process, this must be done manually or through external automation. Promoting fields to labels enables powerful grouping and querying capabilities, such as filtering devices by region or OS version. You can also define your own fields in <code>status.systemInfo.customInfo</code>, allowing the agent to collect user-defined metadata through custom commands.</p>"},{"location":"user/managing-devices/#considerations-for-system-information","title":"Considerations for System Information","text":"<p>Here are key considerations when using this feature:</p> <ul> <li> <p>What\u2019s Collected: By default, the agent collects basic system information such as hostname, kernel version, OS distribution, product identifiers, and default network interface details. Additional fields such as BIOS data, GPU info, memory, and CPU details can be enabled through configuration. See configuring agent for a full list of supported fields and how to customize collection.</p> </li> <li> <p>Custom Fields: You can configure the agent to collect additional custom attributes specific to your environment. These are displayed under <code>systemInfo.customInfo</code> and can be used for labeling or grouping devices. See configuring agent for example usage.</p> </li> <li> <p>Collection Timing: System info is collected during process bootstrap and then cached. It refreshes only if the agent restarts or receives a reload signal (SIGHUP). This avoids unnecessary overhead during regular status updates.</p> </li> <li> <p>Reboot Awareness: The agent tracks boot time and boot ID, allowing Flight Control to detect whether the device has rebooted. This is useful for update coordination and lifecycle monitoring.</p> </li> <li> <p>Partial Data: Not all fields may be available on every device or on every process start. Collection is best-effort missing values errors or timeouts will result in empty values.</p> </li> </ul>"},{"location":"user/managing-devices/#viewing-using-the-web-ui","title":"Viewing using the Web UI","text":""},{"location":"user/managing-devices/#viewing-using-the-cli","title":"Viewing using the CLI","text":"<p>You can see the devices in the device inventory by running the following command:</p> <pre><code>flightctl get devices\n</code></pre> <p>The output will be a table similar to this:</p> <pre><code>NAME                                                  ALIAS    OWNER   SYSTEM  UPDATED     APPLICATIONS  LAST SEEN\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  &lt;none&gt;   &lt;none&gt;  Online  Up-to-date  &lt;none&gt;        3 seconds ago\n</code></pre> <p>You can see the details of this device in YAML format by running the following command:</p> <pre><code>flightctl get device/54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg -o yaml\n</code></pre> <p>The output will look similar to this:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: 54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg\n  labels:                                    # &lt;-- user-defined labels assigned to this device\n    region: eu-west-1\n    site: factory-berlin\nspec:\n  os:\n    image: quay.io/flightctl/rhel:9.5        # &lt;-- the device's target OS image version\n  config:\n  - name: my-os-configuration                # &lt;-- the device's target OS configuration (here: read from a git repo)\n    configType: GitConfigProviderSpec\n    gitRef:\n      path: /configuration\n      repository: my-configuration-repo\n      targetRevision: production\nstatus:\n  os:\n    image: quay.io/flightctl/rhel:9.5        # &lt;-- the device's current OS image version\n  config:\n    renderedVersion: \"1\"                     # &lt;-- the device's current OS configuration version\n  applications:\n    data: {}                                 # &lt;-- the device's current list of deployed applications\n    summary:\n      status: Unknown                        # &lt;-- health status of applications on the device\n  resources:                                 # &lt;-- whether sufficient CPU/disk/memory resources are available\n    cpu: Healthy\n    disk: Healthy\n    memory: Healthy\n  systemInfo:                                # &lt;-- basic information about the system\n    architecture: amd64\n    bootID: 037750f7-f293-4c5b-b06e-481eef4e883f\n    operatingSystem: linux\n  summary:\n    info: \"\"\n    status: Online                           # &lt;-- online status of the device\n  updated:\n    status: UpToDate                         # &lt;-- update status of the device\n  lastSeen: \"2024-08-28T11:45:34.812851905Z\" # &lt;-- when the device last checked-in\n[...]\n</code></pre>"},{"location":"user/managing-devices/#organizing-devices","title":"Organizing Devices","text":"<p>You can organize your devices by assigning them labels, for example to record their location ( (\"region=emea\", \"site=factory-berlin\"), hardware type (\"hw-model=jetson\", \"hw-generation=orin\"), or purpose (\"device-type=autonomous-forklift\"). This then allows you select devices by these labels when viewing the device inventory or applying operations to them.</p> <p>As good practice, labels should take the form of <code>key=value</code> pairs, whereby the key is the criterion you want to group by. However, labels that only consist of keys are also allowed.</p> <p>Labels must follow certain rules to be valid (in fact, these are the same as for Kubernetes):</p> <ul> <li>Keys and value must each be 63 characters or less. Value may be omitted.</li> <li>Keys and values may consist of alphanumeric characters (<code>a-z</code>, <code>A-Z</code>, <code>0-9</code>). They may also contain dashes (<code>-</code>), underscores (<code>_</code>), dots (<code>.</code>), but not as the first or last character.</li> </ul> <p>Once devices are labeled, you can select a subset of devices by writing a \"label selector\". Label selectors can select based on equality, inequality, or set operators:</p> Example label selector Devices it selects <code>site=factory-berlin</code> All devices with a label key <code>site</code> and a label value <code>factory-berlin</code>. <code>site!=factory-berlin</code> All devices with a label key <code>site</code> and not a label value <code>factory-berlin</code>. <code>site in (factory-berlin,factory-madrid)</code> All devices with a label key <code>site</code> and a label value of either <code>factory-berlin</code> or <code>factory-madrid</code> <p>You can specify multiple label selectors in a comma-separated list, for example <code>site=factory-berlin,device-type=autonomous-forklift</code>, to have a device selected only if all selectors in the list match.</p> <p>There are multiple ways when and how to apply labels to devices:</p> <ul> <li>You can define a set of default labels during image building that get automatically applied to all devices deploying that image.</li> <li>You can assign initial labels during enrollment (see Enrolling Devices).</li> <li>You can edit labels post-enrollment, which is described in the following sections.</li> </ul>"},{"location":"user/managing-devices/#using-labels-on-the-web-ui","title":"Using Labels on the Web UI","text":""},{"location":"user/managing-devices/#using-labels-on-the-cli","title":"Using Labels on the CLI","text":"<p>You can view devices in your inventory including their labels by using the <code>-o wide</code> option:</p> <pre><code>flightctl get devices -o wide\n</code></pre> <pre><code>NAME                                                  ALIAS    OWNER   SYSTEM  UPDATED     APPLICATIONS  LAST SEEN      LABELS\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  &lt;none&gt;   &lt;none&gt;  Online  Up-to-date  &lt;none&gt;        3 seconds ago  region=eu-west-1,site=factory-berlin\nhnsu33339f8m5pjqrbh5ak704jjp92r95a83sd5ja8cjnsl7qnrg  &lt;none&gt;   &lt;none&gt;  Online  Up-to-date  &lt;none&gt;        1 minute ago   region=eu-west-1,site=factory-madrid\n</code></pre> <p>You can view devices in your inventory with a specific label or set of labels by using the <code>-l key=value</code> option one or more times:</p> <pre><code>flightctl get devices -l site=factory-berlin -o wide\n</code></pre> <pre><code>NAME                                                  ALIAS    OWNER   SYSTEM  UPDATED     APPLICATIONS  LAST SEEN      LABELS\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  &lt;none&gt;   &lt;none&gt;  Online  Up-to-date  &lt;none&gt;        3 seconds ago  region=eu-west-1,site=factory-berlin\n</code></pre> <p>You can update the labels of a given device by exporting the device's current definition into a file, editing the specification to update the labels, and then applying the updated definition. To export the device's current definition into a file called <code>my_device.yaml</code>, run the <code>flightctl get device</code> command with the device's name and the <code>-o yaml</code> output flag:</p> <pre><code>flightctl get device/54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg -o yaml &gt; my_device.yaml\n</code></pre> <p>Next, use your preferred editor to edit <code>my_device.yaml</code>, for example:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  labels:\n    some_key: some_value\n    some_other_key: some_other_value\n  name: 54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg\nspec:\n[...]\n</code></pre> <p>Save the edit, then apply the updated device definition using:</p> <pre><code>flightctl apply -f my_device.yaml\n</code></pre> <p>When you now view the device's labels using <code>flightctl get devices -o wide</code> once more, you should see your changes applied:</p> <pre><code>NAME                                                  ALIAS    OWNER   SYSTEM  UPDATED     APPLICATIONS  LAST SEEN      LABELS\n54shovu028bvj6stkovjcvovjgo0r48618khdd5huhdjfn6raskg  &lt;none&gt;   &lt;none&gt;  Online  Up-to-date  &lt;none&gt;        3 minutes ago  some_key=some_value,some_other_key=some_other_value\nhnsu33339f8m5pjqrbh5ak704jjp92r95a83sd5ja8cjnsl7qnrg  &lt;none&gt;   &lt;none&gt;  Online  Up-to-date  &lt;none&gt;        4 minutes ago  region=eu-west-1,site=factory-madrid\n</code></pre>"},{"location":"user/managing-devices/#updating-the-os","title":"Updating the OS","text":"<p>You can update a device's OS by updating the target OS image name or version in the device's specification. The next time the agent checks in, it learns of the requested update and automatically starts downloading and verifying the new OS version in the background. It then schedules the actual system update to be performed according to the update policy. When the time has come to update, it installs the new version in parallel and performs a reboot into the new version.</p> <p>Flight Control currently supports the following image types and image references formats:</p> Image Type Image Reference bootc An OCI image reference to a container registry. Example: <code>quay.io/flightctl-demos/rhel:9.5</code> <p>During the process, the agent sends status updates to the service. You can monitor the update progress by viewing the device status.</p>"},{"location":"user/managing-devices/#updating-the-os-on-the-web-ui","title":"Updating the OS on the Web UI","text":""},{"location":"user/managing-devices/#updating-the-os-on-the-cli","title":"Updating the OS on the CLI","text":"<p>To update a device using the CLI, get the device's current resource manifest, edit it to specify the new OS name and version target, then apply the updated resource.</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: some_device_name\nspec:\n[...]\n  os:\n    image: quay.io/flightctl/rhel:9.5\n[...]\n</code></pre>"},{"location":"user/managing-devices/#using-image-pull-secrets","title":"Using Image Pull Secrets","text":"<p>If your device relies on containers from a private repository, authentication credentials (pull secrets) must be placed in the appropriate system paths.</p> <ul> <li>OS Image: Uses <code>/etc/ostree/auth.json</code></li> <li>Container Images: Uses the system default for Podman, <code>/root/.config/containers/auth.json</code></li> </ul>"},{"location":"user/managing-devices/#auth-file-format","title":"Auth File Format","text":"<p>The authentication file should follow this format:</p> <pre><code>{\n  \"auths\": {\n    \"registry.example.com\": {\n      \"auth\": \"base64-encoded-credentials\"\n    }\n  }\n}\n</code></pre> <p>[!NOTE] Authentication must exist on the device before it can be consumed.</p>"},{"location":"user/managing-devices/#managing-os-configuration","title":"Managing OS Configuration","text":"<p>With image-based Linux OSes, it is best practice to include OS-level / host configuration into the OS image for maximum consistency and repeatability. To update configuration, a new OS image should be created and devices updated to the new image.</p> <p>However, there are scenarios where this is impractical, for example, when configuration is missing in the image, needs to be specific to a device, or needs to be update-able at runtime without updating the OS image and rebooting. For these cases, Flight Control allows users to declare a set of configuration files that shall be present on the device's file system.</p> <p>Conceptually, this set of configuration files can be thought of as an additional, dynamic layer on top of the OS image's layers. The Flight Control Agent applies updates to this layer transactionally, ensuring that either all files have been successfully updated in the file system or have been returned to their pre-update state. Further, if the user updates both a devices OS and configuration set at the same time, the Flight Control Agent will first update the OS, then apply the specified configuration set on top.</p> <p>[!Important] After the Flight Control Agent has updated the configuration on disk, this configuration still needs to be activated. That means, running services need to reload the new configuration into memory for it to become effective. If the update involves a reboot, services will be restarted by systemd in the right order with the new configuration automatically. If the update does not involve a reboot, many services can detect changes to their configuration files and automatically reload them. When a service does not support this, you use Device Lifecycle Hooks to specify rules like \"if configuration file X has changed, run command Y\". Also refer to this section for the set of default rules that the Flight Control Agent applies.</p> <p>Users can specify a list of configurations sets, in which case the Flight Control Agent applies the sets in sequence and on top of each other, such that in case of conflict the \"last one wins\".</p> <p>Configuration can come from multiple sources, called \"configuration providers\" in Flight Control. Flight Control currently supports the following configuration providers:</p> <ul> <li>Git Config Provider: Fetches device configuration files from a Git repository.</li> <li>Kubernetes Secret Provider: Fetches a Secret from a Kubernetes cluster and writes its content to the device's file system.</li> <li>HTTP Config Provider: Fetches device configuration files from an HTTP(S) endpoint.</li> <li>Inline Config Provider: Allows specifying device configuration files inline in the device manifest without querying external systems.</li> </ul> <p>These providers are described in the following.</p>"},{"location":"user/managing-devices/#getting-configuration-from-a-git-repository","title":"Getting Configuration from a Git Repository","text":"<p>You can store device configuration in a Git repository such as GitHub or GitLab and let Flight Control synchronize it to the device's file system by adding a Git Config Provider.</p> <p>The Git Config Provider takes the following parameters:</p> Parameter Description Repository The name of a Repository resource defined in Flight Control. TargetRevision The branch, tag, or commit of the repository to checkout. Path The subdirectory of the repository that contains the configuration. <p>The Repository resource definition tells Flight Control the Git repository to connect to and which protocol and access credentials to use. It needs to be set up once (see Setting Up Repositories) and can then be used to configure multiple devices or fleets.</p> <p>The subdirectory of the repository (pointed to by Path) will be mounted to the root of the device. When specifying a Path, make sure the directories in it already exist with writable access on the system (the application cannot write to the root). Using non-existent or read-only directories may result in errors due to insufficient permissions or read-only file systems.</p>"},{"location":"user/managing-devices/#example","title":"Example","text":"<p>A assume a Git repository <code>github.com/flightctl/flightctl-demos</code> that in its branch <code>production</code> stores device network and time server configuration organized by deployment site as follows:</p> <pre><code>.\n\u251c\u2500\u2500 factory-a\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 etc\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 chrony.conf\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 NetworkManager\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 system-connections\n\u2502\u00a0\u00a0             \u2514\u2500\u2500 wifi-access.nmconnection\n\u2514\u2500\u2500 factory-b\n    \u2514\u2500\u2500 etc\n        \u251c\u2500\u2500 chrony.conf\n        \u2514\u2500\u2500 NetworkManager\n            \u2514\u2500\u2500 system-connections\n                \u2514\u2500\u2500 wifi-access.nmconnection\n</code></pre> <p>First, create a new Repository resource. Give it a name that you can later reference in your configurations, for example \"site-settings\", and select the Repository type \"git\". Next, enter the URL of your git repository, in this case <code>https://github.com/flightctl/flightctl-demos.git</code>.</p> <p>You can now reference this Repository when you configure devices. For example, to apply the configuration files under <code>/factory-a</code> to a device, add a Git Config Provider to the device's specification using the following parameters:</p> Parameter Value Repository site-settings TargetRevision production Path /factory-a"},{"location":"user/managing-devices/#getting-secrets-from-a-kubernetes-cluster","title":"Getting Secrets from a Kubernetes Cluster","text":"<p>You can let Flight Control query the Kubernetes cluster it is running on for a Kubernetes Secret. The content of that Secret can then be written to a path on the device file system.</p> <p>The Kubernetes Secret Provider takes the following parameters:</p> Parameter Description Name The name of the Secret. NameSpace The namespace of the Secret. MountPath The directory in the device's file system to write the secret's content to. <p>Note that Flight Control needs to have the permissions access Secrets in that namespace, for example by creating a ClusterRole and ClusterRoleBinding allowing the <code>flightctl-worker</code> service account \"get\" and \"list\" Secrets in that namespace.</p>"},{"location":"user/managing-devices/#getting-configuration-from-an-http-server","title":"Getting Configuration from an HTTP Server","text":"<p>You can let Flight Control query an HTTP server for configuration. This HTTP server can then serve static or dynamically generated configuration for a device.</p> <p>The HTTP Config Provider takes the following parameters:</p> Parameter Description Repository The name of a Repository resource defined in Flight Control. Suffix The suffix to append to the base URL defined in the Repository resource. It can include path and query parameters such as <code>/path/to/endpoint?query=param</code> FilePath The path to the file on the device's file system in which to store the returned value of the HTTP Server. <p>The Repository resource definition tells Flight Control the HTTP server to connect to and which protocol and access credentials to use. It needs to be set up once (see Setting Up Repositories) and can then be used to configure multiple devices or fleets.</p>"},{"location":"user/managing-devices/#specifying-configuration-inline-in-the-device-spec","title":"Specifying Configuration Inline in the Device Spec","text":"<p>You specify configuration inline in a device's specification, so Flight Control does not need to connect to external systems to fetch configuration.</p> <p>The Inline Config Provider takes a list of file specifications, whereby each file specification takes the following parameters:</p> Parameter Description Path The absolute path to the file on the device. Note that any existing file will be overwritten. Content The plain text (UTF-8) or base64-encoded content of the file. ContentEncoding How the contents are encoded. Must be either \"plain\" or \"base64\". Defaults to \"plain\". Mode (Optional) The file\u2019s permission mode. You may specify the more familiar octal with a leading zero (e.g., 0644) or as a decimal without a leading zero (e.g., 420). Setuid/setgid/sticky bits are supported. If not specified the permission mode for files defaults to 0644. User (Optional) The file's owner, specified either as a name or numeric ID. Defaults to \"root\". Group (Optional) The file's group, specified either as a name or numeric ID."},{"location":"user/managing-devices/#managing-configuration-on-the-web-ui","title":"Managing Configuration on the Web UI","text":""},{"location":"user/managing-devices/#managing-configuration-on-the-cli","title":"Managing Configuration on the CLI","text":"<p>To implement the example from Getting Configuration from a Git Repository, first, create a file <code>site-settings-repo.yaml</code> that contains the following definition for a Repository resource named <code>site-settings</code>:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Repository\nmetadata:\n  name: site-settings\nspec:\n  type: git\n  url: https://github.com/flightctl/flightctl-demos.git\n</code></pre> <p>Create the Repository resource by applying the file:</p> <pre><code>flightctl apply -f site-settings-repo.yaml`\n</code></pre> <p>Verify the resource has been correctly created and is accessible by Fight Control by running:</p> <pre><code>flightctl get repository/site-settings\n</code></pre> <p>The output should look like this:</p> <pre><code>NAME           TYPE  REPOSITORY URL                                ACCESSIBLE\nsite-settings  git   https://github.com/flightctl/flightctl-demos  True\n</code></pre> <p>To apply the configuration for <code>factory-a</code> to a device, you would update the device's specification as follows:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: some_device_name\nspec:\n[...]\n  config:\n  - name: factory-a-settings\n    configType: GitConfigProviderSpec\n    gitRef:\n      repository: site-settings\n      targetRevision: production\n      path: /factory-a\n[...]\n</code></pre>"},{"location":"user/managing-devices/#managing-applications","title":"Managing Applications","text":"<p>You can deploy, update, or undeploy applications on a device by updating the list of applications in the device's specification. The next time the agent checks in, it learns of the change in the specification, downloads any new or updated application packages and images from an OCI-compatible registry, and deploys them to the appropriate application runtime or removes them from that runtime.</p> <p>The following table shows the application runtimes and formats supported by Flight Control:</p>"},{"location":"user/managing-devices/#runtime-podman","title":"Runtime: Podman","text":"Specification Format Source / Delivery Compose specification (via <code>podman-compose</code>) OCI image OCI registry Compose specification (via <code>podman-compose</code>) Unpackaged inline Inline in device specification <p>[!NOTE] Requires <code>podman-compose</code> to be installed on the device.</p> <p>[!TIP] Short image names (e.g., <code>nginx</code>) are not supported. Use fully qualified references like <code>docker.io/nginx</code> to avoid ambiguity.</p> <p>To deploy an application to a device, create a new entry in the \"applications\" section of the device's specification, specifying the following parameters:</p> Parameter Description Name A user-defined name for the application. This will be used when the web UI and CLI list applications. Image A reference to an application package in an OCI registry. AppType The application format type. Currently supported type: <code>compose</code>. EnvVars (Optional) A list of key/value-pairs that will be passed to the deployment tool as environment variables or command line flags. <p>For each application in the \"applications\" section of the device's specification, there exist a corresponding device status information that contains the following information:</p> Status Field Description Preparing Application deployed; containers initialized but not yet running. Starting Application started; at least one container running, awaiting results. Running All containers are running. Error All containers failed. Unknown Application started, no containers observed. Completed All containers have completed successfully."},{"location":"user/managing-devices/#managing-applications-on-the-web-ui","title":"Managing Applications on the Web UI","text":""},{"location":"user/managing-devices/#managing-applications-on-the-cli","title":"Managing Applications on the CLI","text":"<p>To deploy an application package from an OCI registry, specify it in the device's <code>spec.applications[]</code> as follows:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: some_device_name\nspec:\n[...]\n  applications:\n  - name: wordpress\n    image: quay.io/flightctl-demos/wordpress-app:latest\n    envVars:\n      WORDPRESS_DB_HOST: \"mysql\"\n      WORDPRESS_DB_USER: \"user\"\n      WORDPRESS_DB_PASSWORD: \"password\"\n[...]\n</code></pre>"},{"location":"user/managing-devices/#creating-applications","title":"Creating Applications","text":""},{"location":"user/managing-devices/#creating-oci-registry-application-package","title":"Creating OCI Registry Application Package","text":"<p>Define the application's functionality with the Compose specification and embed the compose file in a scratch container. Add the <code>appType=compose</code> label, then build and push the container to your OCI registry. Finally, reference the image in <code>spec.applications[]</code>.</p> <pre><code>FROM scratch\n\nCOPY podman-compose.yaml /podman-compose.yaml\n\n# required\nLABEL appType=\"compose\"\n</code></pre>"},{"location":"user/managing-devices/#specifying-applications-inline-in-the-device-spec","title":"Specifying Applications Inline in the Device Spec","text":"<p>Application manifests are specified inline in a device's specification, so building an OCI Registry Application Package is not required.</p> <p>The Inline Application Provider accepts a list of application content with the following parameters:</p> Parameter Description Path The relative path to the file on the device. Note that any existing file will be overwritten. Content (Optional) The plain text (UTF-8) or base64-encoded content of the file. ContentEncoding How the contents are encoded. Must be either \"plain\" or \"base64\". Defaults to \"plain\". <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: some_device_name\nspec:\n[...]\n  applications:\n    - name: my-app\n      appType: compose\n      inline:\n        - content: |\n            version: \"3.8\"\n            services:\n              service1:\n                image:  quay.io/flightctl-tests/alpine:v1\n                command: [\"sleep\", \"infinity\"]\n          path: podman-compose.yaml\n[...]\n</code></pre> <p>[!NOTE] Inline compose applications can have at most two paths. The first should be named <code>podman-compose.yaml</code>, and the second (override) must be named <code>podman-compose.override.yaml</code>.</p>"},{"location":"user/managing-devices/#adding-application-volumes","title":"Adding Application Volumes","text":"<p>[!NOTE] This feature requires the Flight Control Agent to run with Podman version 5.5 or higher.</p> <p>Applications can declare persistent data volumes that are populated from OCI artifacts. This allows delivering large datasets (such as ML models or static assets) as part of the application deployment.</p> <p>Volumes are declared under each application in the <code>volumes</code> field. These volumes are mounted into the application containers via the Compose <code>volumes</code> section.</p>"},{"location":"user/managing-devices/#specifying-volumes","title":"Specifying Volumes","text":"<p>Each volume definition includes:</p> Field Description <code>name</code> Logical volume name. Must match the volume name referenced in the Compose file. <code>image.reference</code> Fully qualified OCI artifact reference containing the volume contents. <code>image.pullPolicy</code> (Optional) Defines pull behavior: <code>Always</code>, <code>IfNotPresent</code>, or <code>Never</code>. Defaults to <code>IfNotPresent</code> if not specified. <p>[!IMPORTANT] In the Compose file, volumes must be declared as <code>external: true</code> to allow the agent to handle preparation and mounting.</p>"},{"location":"user/managing-devices/#example-inline-application-with-volume","title":"Example Inline Application with Volume","text":"<pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: some_device_name\n[...]\nspec:\n  applications:\n    - name: my-inline\n      appType: compose\n      inline:\n        - path: docker-compose.yaml\n          content: |\n            version: \"3.8\"\n            services:\n              service1:\n                image: quay.io/flightctl-tests/alpine:v1\n                command: [\"sleep\", \"infinity\"]\n                volumes:\n                  - my-data:/data\n            volumes:\n              my-data:\n                external: true\n      volumes:\n        - name: my-data\n          image:\n            reference: quay.io/flightctl-tests/models/gpt2\n            pullPolicy: IfNotPresent\n</code></pre>"},{"location":"user/managing-devices/#oci-artifact-requirements","title":"OCI Artifact Requirements","text":"<p>Volume images must follow the OCI artifact specification:</p> <ul> <li>Published as OCI images (media type: <code>application/vnd.oci.image.manifest.v1+json</code>).</li> <li>Contain one or more layers representing the volume file contents.</li> <li>Hosted on any OCI-compatible registry accessible by the device.</li> </ul> <p>[!TIP] If the artifact contains more than one layer, the mount path should be an already existing directory, into which the layers will each be copied as a separate file using the name specified in the layer's <code>org.opencontainers.image.title</code> field. For single layer archives if the mount path does not exist as a directory the single layer will be extracted as a file at that path, otherwise it will be placed into the existing directory using the file name in the name field for the layer.</p>"},{"location":"user/managing-devices/#device-requirements","title":"Device Requirements","text":"<p>The following are required on the device to support application volumes:</p> <ul> <li>Podman 5.5 or newer installed.</li> <li><code>podman-compose</code> installed.</li> <li>OCI registry authentication (if needed) must be configured prior to deployment.</li> </ul>"},{"location":"user/managing-devices/#using-device-lifecycle-hooks","title":"Using Device Lifecycle Hooks","text":"<p>You can use device lifecycle hooks to make the agent run user-defined commands at specific points in the device's lifecycle. For example, you can add a shell script to your OS images that backs up your application data and then specify that this script shall be run and complete successfully before the agent can start updating the system.</p> <p>The following device lifecycle hooks are supported:</p> Lifecycle Hook Description <code>beforeUpdating</code> This hook is called after the agent completed preparing for the update and before actually making changes to the system. If an action in this hook returns with failure, the agent aborts the update. <code>afterUpdating</code> This hook is called after the agent has written the update to disk. If an action in this hook returns with failure,the agent will abort and roll back the update. <code>beforeRebooting</code> This hook is called before the agent reboots the device. The agent will block the reboot until running the action has completed or timed out. If any action in this hook returns with failure, the agent will abort and roll back the update. <code>afterRebooting</code> This hook is called when the agent first starts after a reboot. If any action in this hook returns with failure, the agent will report this but continue starting up. <p>Refer to the Device API status reference a state diagram defining when each device lifecycle hook is called by the agent.</p> <p>Device lifecycle hooks can be defined by adding rule files to one of two locations in the device's filesystem, whereby <code>${lifecyclehook}</code> is the all-lower-case name of the hook to be defined:</p> <ul> <li>Rules in the <code>/usr/lib/flightctl/hooks.d/${lifecyclehook}/</code> drop-in directory are read-only and thus have to be added to the OS image during image building.</li> <li>Rules in the <code>/etc/flightctl/hooks.d/${lifecyclehook}/</code> drop-in directory are read-writable and can thus be updated at runtime using the methods described in Managing OS Configuration.</li> </ul> <p>If rules are defined in both locations they will be merged, whereby files under <code>/etc</code> take precedence over files of the same name under <code>/usr</code>. If multiple rule files are added to a hook's directory, they are processed in lexical order of their file names.</p> <p>A rule file is written in YAML format and contains a list of one or more actions. An action can be to run an external command (\"run action\"). When multiple actions are specified for a hook, these actions are performed in sequence, finishing one action before starting the next. If an action returns with failure, later actions will not be executed.</p> <p>A run action takes the following parameters:</p> Parameter Description Run The absolute path to the command to run, followed by any flags or arguments.Example: <code>/usr/bin/nmcli connection reload</code>.Note that the command is not executed in a shell, so you cannot use shell variables like <code>$FOO_PATH</code> or chain commands (<code>\\|</code> or <code>;</code>). However, it is possible to start a shell yourself if necessary by specifying the shell as command to run.Example: <code>/usr/bin/bash -c 'echo foo'</code> EnvVars (Optional) A list of key/value-pairs to set as environment variables for the command. WorkDir (Optional) The directory the command will be run from. Timeout (Optional) The maximum duration allowed for the action to complete. The duration must be be specified as a single positive integer followed by a time unit. Supported time units are <code>s</code> for seconds, <code>m</code> for minutes, and <code>h</code> for hours.Default: 10s If (Optional) A list of conditions that must be true for the action to be run (see below). If not provided, actions will run unconditionally. <p>[!NOTE] When using a shell with <code>run</code>, the executed environment does not inherit the system environment, any required environment variables must be provided explicitly via the <code>envVars</code> field in the API.</p> <pre><code>- run: /usr/bin/bash -c \"until [ -f $KUBECONFIG ]; do sleep 1; done\"\n   timeout: 5m\n   envVars:\n     KUBECONFIG: \"/var/lib/microshift/resources/kubeadmin/kubeconfig\"\n</code></pre> <p>By default, actions are performed every time the hook is triggered. However, for the <code>afterUpdating</code> hook you can use the <code>If</code> parameter to add conditions that must be true for an action to be performed, otherwise the action will be skipped.</p> <p>In particular, to only run an action if a given file or directory has changed during the update, you can define a \"path condition\" that takes the following parameters:</p> Parameter Description Path An absolute path to a file or directory that must have changed during the update as condition for the action to be performed. Paths must be specified using forward slashes (<code>/</code>) and if the path is to a directory it must terminate with a forward slash <code>/</code>.If you specify a path to a file, the file must have changed to satisfy the condition.If you specify a path to a directory, a file in that directory or any of its subdirectories must have changed to satisfy the condition. Op A list of file operations (<code>created</code>, <code>updated</code>, <code>removed</code>) to further limit the kind of changes to the specified path as condition for the action to be performed. <p>If you have specified a \"path condition\" for an action in the <code>afterUpdating</code> hook, you have the following variables that you can include in arguments to your command and that will be replaced with the absolute path(s) to the changed files:</p> Variable Description <code>${ Path }</code> The absolute path to the file or directory specified in the path condition. <code>${ Files }</code> A space-separated list of absolute paths of the files that were changed (created, updated, or removed) during the update and are covered by the path condition. <code>${ CreatedFiles }</code> A space-separated list of absolute paths of the files that were changed (created, updated, or removed) during the update and are covered by the path condition. <code>${ UpdatedFiles }</code> A space-separated list of absolute paths of the files that were updated during the update and are covered by the path condition. <code>${ RemovedFiles }</code> A space-separated list of absolute paths of the files that were removed during the update and are covered by the path condition. <p>The Flight Control Agent comes with a built-in set of rules defined in <code>/usr/lib/flightctl/hooks.d/afterupdating/00-default.yaml</code>:</p> If files changed below then the agent runs Description <code>/etc/systemd/system/</code> <code>systemctl daemon-reload</code> Changes to systemd units will be activated by signaling the systemd daemon to reload the systemd manager configuration. This will rerun all generators, reload all unit files, and recreate the entire dependency tree. <code>/etc/NetworkManager/system-connections/</code> <code>nmcli conn reload</code> Changes to Network Manager system connections will be activated by signaling Network Manager to reload all connections. <code>/etc/firewalld/</code> <code>firewall-cmd --reload</code> Changes to firewalld's permanent configuration will be activated by signaling firewalld to reload firewall rules as new runtime configuration."},{"location":"user/managing-devices/#monitoring-device-resources","title":"Monitoring Device Resources","text":"<p>You can set up monitors for device resources and define alerts when the utilization of these resources crosses a defined threshold. When the agent alerts the Flight Control service, the service sets the device status to \"degraded\" or \"error\" (depending on the severity level) and may suspend the rollout of updates and alarm the user as a result.</p> <p>Note this is not meant to replace an observability solution. If your use case requires streaming logs and metrics from devices into an observability stack and the device's network bandwidth allows this, see Service Observability and Standalone Observability for ways to approach that.</p> <p>Resource monitors take the following parameters:</p> Parameter Description MonitorType The resource to monitor. Currently supported resources are \"CPU\", \"Memory\", and \"Disk\". [TODO: Check whether the \"Custom\" resource type is implemented.] SamplingInterval The interval in which the monitor samples utilization, specified as positive integer followed by a time unit ('s' for seconds, 'm' for minutes, 'h' for hours). AlertRules A list of alert rules. Path (Disk monitor only) The absolute path to the directory to monitor. Utilization reflects the filesystem containing the path, similar to df, even if it\u2019s not a mount point. <p>Alert rules take the following parameters:</p> Parameter Description Severity The alert rule's severity level out of \"Info\", \"Warning\", or \"Critical\". Only one alert rule is allowed per severity level and monitor. Duration The duration that resource utilization is measured and averaged over when sampling, specified as positive integer followed by a time unit ('s' for seconds, 'm' for minutes, 'h' for hours). Must be smaller than the sampling interval. Percentage The utilization threshold that triggers the alert, as percentage value (range 0 to 100 without the \"%\" sign). Description A human-readable description of the alert. This is useful for adding details about the alert that might help with debugging. By default it populates the alert as :  load is above &gt;% for more than"},{"location":"user/managing-devices/#monitoring-device-resources-on-the-web-ui","title":"Monitoring Device Resources on the Web UI","text":""},{"location":"user/managing-devices/#monitoring-device-resources-on-the-cli","title":"Monitoring Device Resources on the CLI","text":"<p>To monitor resource utilization, add resource monitors in the <code>resources:</code> section of the device's specification.</p> <p>For example, to monitor disk utilization on the filesystem associated with the path /applications, which can trigger a warning alert if the average utilization exceeds 75% for more than 30 minutes and a critical alert if it exceeds 90% for over 10 minutes with a sampling interval of 5 seconds.</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Device\nmetadata:\n  name: some_device_name\nspec:\n[...]\n  resources:\n  - monitorType: Disk\n    samplingInterval: 5s\n    path: /application_data\n    alertRules:\n    - severity: Warning\n      duration: 30m\n      percentage: 75\n      description: Disk space for application data is &gt;75% full for over 30m.\n    - severity: Critical\n      duration: 10m\n      percentage: 90\n      description: Disk space for application data is &gt;90% full over 10m.\n[...]\n</code></pre>"},{"location":"user/managing-devices/#accessing-devices-remotely","title":"Accessing Devices Remotely","text":"<p>For troubleshooting an edge device, a user with the appropriate authorization (<code>get</code> permission on the <code>devices/console</code> resource) can remotely connect to the device's console through the agent. This does not require an SSH connection and so works even if that device is on a private network (behind a NAT), has a dynamic IP address, or has its SSH service disabled.</p>"},{"location":"user/managing-devices/#accessing-devices-on-the-web-ui","title":"Accessing Devices on the Web UI","text":""},{"location":"user/managing-devices/#accessing-devices-on-the-cli","title":"Accessing Devices on the CLI","text":"<p>To connect, use the <code>flightctl console</code> command specifying the device's name, and the agent will establish the console connection the next time it calls home:</p> <pre><code>flightctl console device/&lt;some_device_name&gt;\n</code></pre> <p>To disconnect, enter \"exit\" on the console. To force-disconnect, press newline followed by <code>~.</code> (tilde period).</p> <p>The console can be used to run commands on the device, for example to check the status of the flightctl-agent service:</p> <pre><code>flightctl console device/&lt;some_device_name&gt; -- systemctl status flightctl-agent\n</code></pre> <p>The console can be used to download a file from the device to your local machine, for example to download the systemd journal log:</p> <pre><code>flightctl console device/&lt;some_device_name&gt; -- journalctl -o short-precise --no-pager &gt; journal.log\n</code></pre>"},{"location":"user/managing-devices/#decommissioning-devices","title":"Decommissioning Devices","text":"<p>Decommissioning a device is the proper way to unenroll it and permanently remove it from Flight Control management. When a user requests the decommissioning of a device, the Flight Control service signals to the Flight Control agent to run a decommissioning process. This process includes erasing the agent's management certificate and key and with it the device's Flight Control identity. This is an action that cannot be undone. Decommissioning should be performed before deleting a device.</p> <p>To decommission a device:</p> <pre><code>flightctl decommission devices/&lt;some_device_name&gt;\n</code></pre> <p>You can see that the decommissioning request was properly received by the Flight Control service when it includes a decommissioning target in its device specification and its lifecycle status (<code>status.lifecycle.status</code>) moves to Decommissioning:</p> <pre><code>$ flightctl get devices/&lt;some_device_name&gt; -o yaml\n\n...\nspec:\n  decommissioning:\n    target: Unenroll\n...\nstatus:\n  ...\n  lifecycle:\n    status: Decommissioning\n...\n</code></pre> <p>Once the device receives the decommissioning request from the server, it will acknowledge the request with a decommissioning <code>Condition</code> that can also be seen in the device info:</p> <pre><code>$ flightctl get devices/&lt;some_device_name&gt; -o yaml\n\n...\nstatus:\n...\n  conditions:\n  ...\n    - lastTransitionTime: \"2025-03-05T20:40:48.443917332Z\"\n    message: The device has completed decommissioning and will wipe its management\n      certificate\n    reason: Completed\n    status: \"True\"\n    type: DeviceDecommissioning\n</code></pre> <p>When the device has completed its decommissioning steps, the <code>status.lifecycle.status</code> field will show the value <code>Decommissioned</code>. At this point, it is safe to delete the device with:</p> <pre><code>flightctl delete devices/&lt;some_device_name&gt;\n</code></pre>"},{"location":"user/managing-devices/#scheduling-updates-and-downloads","title":"Scheduling Updates and Downloads","text":"<p>The Flight Control agent supports time-based scheduling for update and download operations using cron style expressions. This allows you to restrict system modifications to defined maintenance windows or operational periods.</p> <p>Each device can define two independent schedules in the <code>updatePolicy</code> section of the <code>DeviceSpec</code>:</p> <ul> <li><code>downloadSchedule</code>: Defines when the device is allowed to download update artifacts such as OS image layers.</li> <li><code>updateSchedule</code>: Defines when the device is allowed to apply updates.</li> </ul> <p>Each schedule supports:</p> Parameter Description <code>at</code> A cron expression specifying valid run times. <code>timeZone</code> (Optional) The time zone used to evaluate the schedule. Defaults to the device\u2019s local system time zone. Must be a valid IANA time zone. <code>startGraceDuration</code> (Optional) A duration string that extends the allowed start time window after a schedule trigger. Follows the Go duration format, such as <code>\"1h\"</code> or <code>\"45m\"</code>. <p>The Flight Control agent evaluates these schedules during its control loop to determine whether each policy is currently allowed to proceed. While the device waits for the update window the device status will read <code>OutOfDate</code>. For more details please see Device API Statuses.</p> <p>[!TIP] Use crontab guru to create and test cron expressions interactively.</p>"},{"location":"user/managing-devices/#examples","title":"Examples","text":"<pre><code>updatePolicy:\n  downloadSchedule:\n    at: \"0 2 * * *\"               # every day at 2:00 AM\n    timeZone: \"America/New_York\"\n    startGraceDuration: \"30m\"     # allow downloads until 2:30 AM\n  updateSchedule:\n    at: \"0 4 * * 1\"               # every Monday at 4:00 AM\n    timeZone: \"America/New_York\"\n    startGraceDuration: \"1h\"      # allow update until 5:00 AM\n</code></pre> <pre><code>updatePolicy:\n  updateSchedule:\n    at: \"0 5 14 5 *\"              # May 15th at 5:00 AM\n    timeZone: \"America/New_York\"\n    startGraceDuration: \"2h\"      # allow update until 7:00 AM\n</code></pre> <p>[!NOTE] It\u2019s best practice to define a <code>startGraceDuration</code> to allow for potential delays in agent execution. Without it, the update window may be missed. Once an update begins within the allowed window, there is no enforced timeout the update may continue running beyond the grace period.</p>"},{"location":"user/managing-fleets/","title":"Managing Device Fleets","text":""},{"location":"user/managing-fleets/#understanding-fleets","title":"Understanding Fleets","text":"<p>Flight Control simplifies management of a large number of devices and workloads through the concept of \"fleets\". A fleet is a grouping of devices that get managed as one: When you push an operating system update to the fleet, all devices in the fleet will be updated. When you deploy an application to the fleet, all devices in the fleet will have the application deployed. Instead of observing the status of a large number of individual devices, you can observe the fleet's status that summarizes the statuses of all individual devices in the fleet.</p> <p>Fleet-level management has several advantages:</p> <ul> <li>It scales your operations, because you perform operations only once per fleet instead of once per device.</li> <li>It minimizes the risk of configuration mistakes and configuration drift (differences between the desired and the target configuration that accumulate over time).</li> <li>It automatically applies the right configuration when you add devices to the fleet or replace devices in the fleet in the future.</li> </ul> <p>There are scenarios in which fleet-level management may not be your best option:</p> <ul> <li>If your device configurations have very little in common.</li> <li>If you need tight control over the order and timing of updates.</li> </ul> <p>Advantageously, you can have a mix of individually-managed and fleet-managed devices at the same time. You can join a device to a fleet, remove it from the fleet, or join it to another fleet later if needed. At any given time, a device cannot be member of more than one fleet, though (the device is said to be \"owned\" by the fleet).</p> <p>Fleets are resources in Flight Control just like device, enrollment request, and others. You can give a fleet a name when you create it, but you cannot change that name later. You can organize your fleets using labels, just as described in Organizing Devices.</p> <p>Most importantly, though, a fleet's specification consists of three parts that are detailed in later sections:</p> <ol> <li>A label selector that determines which devices are part of the fleet (see Selecting Devices into a Fleet).</li> <li>A device template that is the template for the device specifications of all devices in the fleet (see Defining Device Templates).</li> <li>A set of policies that govern how devices are managed, for example how changes to the device template are rolled out to devices (see Defining Rollout Policies).</li> </ol> <p>When a user updates a fleet's device template to a new version, a component called \"fleet controller\" starts the process of rolling out this version to all of the fleet's devices over time. When the controller has selected a device for update, it copies the new device template to the device's specification. The next time the device's agent checks in, it learns of the new specification and begins the update process.</p> <p>The same thing happens when an individually managed device joins a fleet or a device changes fleets: The device template is copied to the device's specification and if that specification differs from the previous one as a result, the agent will perform an \"update\".</p>"},{"location":"user/managing-fleets/#selecting-devices-into-a-fleet","title":"Selecting Devices into a Fleet","text":"<p>In Flight Control, devices are not explicitly assigned to a fleet. Instead, each fleet has a \"selector\" that defines which labels a device must have to be selected into the fleet. This allows decoupling the concerns of organizing devices from operating them.</p> <p>Let us have a look at a practical example. Assume the following list of point-of-sales (PoS) terminal devices and their labels:</p> Device Labels A type: pos-terminal, region: east, stage: production B type: pos-terminal, region: east, stage: development C type: pos-terminal, region: west, stage: production D type: pos-terminal, region: west, stage: development <p>If all PoS terminals used more or less the same configuration and were managed by the same operations team, it could make sense to define a single fleet <code>pos-terminals</code> with a label selector <code>type=pos-terminal</code>. The result is that the fleet would contain all devices A, B, C, and D.</p> <p>Often, though, you would have separate organizations developing solutions and deploying and operating them. In this case, it could make sense to define two fleets <code>development-pos-terminals</code> with label selector <code>type=pos-terminal, stage=development</code> that selects devices C and D and similar for the production PoS terminals. This way, fleets can be managed independently.</p> <p>Note that you have to define selectors so that no two fleets select the same device. Say you had one fleet select <code>region=east</code> and another <code>stage=production</code>, then both would select device A. When Flight Control detects this situation, it keeps the device in the fleet it is currently assigned to (if any) and signals the conflict by setting the \"MultipleOwners\" condition on affected devices to \"true\".</p>"},{"location":"user/managing-fleets/#selecting-devices-into-a-fleet-on-the-web-ui","title":"Selecting Devices into a Fleet on the Web UI","text":""},{"location":"user/managing-fleets/#selecting-devices-into-a-fleet-on-the-cli","title":"Selecting Devices into a Fleet on the CLI","text":"<p>Before adding a label selector to a fleet, you can test it by getting the list of devices matching that selector. To test the selector <code>type=pos-terminal, stage=development</code> in the above example, you would run:</p> <pre><code>flightctl get devices -l type=pos-terminal -l stage=development\n</code></pre> <p>If the list of returned devices is OK, you could then define a <code>development-pos-terminals</code> fleet selecting these like this:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Fleet\nmetadata:\n  name: development-pos-terminals\nspec:\n  selector:\n    matchLabels:\n      type: pos-terminal\n      stage: development\n[...]\n</code></pre>"},{"location":"user/managing-fleets/#defining-device-templates","title":"Defining Device Templates","text":"<p>A fleet's device template contains a device specification that gets applied to all devices in the fleet when the template gets updated. In other words, you could take an existing device's specification and create a new fleet whose template is a copy of that specification. You can then join that device to the fleet and join additional devices to the fleet and Flight Control would enforce that they all eventually have the exact same specification.</p> <p>For example, you could specify in a fleet's device template that all devices in the fleet shall run the OS image <code>quay.io/flightctl/rhel:9.5</code>. The Flight Control service would then roll out this specification to all devices in the fleet and the Flight Control agents would update the devices accordingly. The same would apply to the other specification items described in Managing Devices.</p> <p>However, it would be impractical if all of a fleet's devices had to have the exact same specification. Flight Control therefore allows templates to contain placeholders that get filled in based on a device's name or label values. The syntax for these placeholders matches that of Go templates, but you may only use simple text or actions (no conditionals or loops, for example). You may reference anything under a device's metadata such as <code>{{ .metadata.labels.key }}</code> or <code>{{ .metadata.name }}</code>.</p> <p>We also provide some helper functions:</p> <ul> <li><code>upper</code>: Change to upper case. For example, <code>{{ upper .metadata.name }}</code>.</li> <li><code>lower</code>: Change to lower case. For example, <code>{{ lower .metadata.labels.key }}</code>.</li> <li><code>replace</code>: Replace all occurrences of a substring with another string. For example, <code>{{ replace \"old\" \"new\" .metadata.labels.key }}</code>.</li> <li><code>getOrDefault</code>: Return a default value if accessing a missing label. For example, <code>{{ getOrDefault .metadata.labels \"key\" \"default\" }}</code>.</li> </ul> <p>You can also combine helpers in pipelines, for example <code>{{ getOrDefault .metadata.labels \"key\" \"default\" | upper | replace \" \" \"-\" }}</code>.</p> <p>Note: Always make sure to use proper Go template syntax. For example, <code>{{ .metadata.labels.target-revision }}</code> is not valid because of the hyphen, and you would need to use something like <code>{{ index .metadata.labels \"target-revision\" }}</code> instead.</p> <p>Here are some examples of what you can do with placeholders in device templates:</p> <ul> <li>You can label devices by their deployment stage (say, <code>stage: testing</code> and <code>stage: production</code>) and then use the label with the key <code>stage</code> as placeholder when referencing the OS image to use (say, <code>quay.io/myorg/myimage:latest-{{ .metadata.labels.stage }}</code>) or when referencing a folder with configuration in a Git repository.</li> <li>You can label devices by deployment site (say, <code>site: factory-berlin</code> and <code>site: factory-madrid</code>) and then use the label with the key <code>site</code> as parameter when referencing the secret with network access credentials in Kubernetes.</li> </ul> <p>The following fields in device templates support placeholders (including within values, unless otherwise noted):</p> Field Placeholders supported in OS Image repository name, image name, image tag Git Config Provider targetRevision, path HTTP Config Provider URL suffix, path Inline Config Provider content, path"},{"location":"user/managing-fleets/#defining-rollout-policies","title":"Defining Rollout Policies","text":"<p>You can define policies that govern how a change to a fleet's device template gets rolled out across devices of the fleet. This gives you control over</p> <ul> <li>groups of devices to update together (e.g. \"one deployment site at a time\"),</li> <li>the order in which groups are updated (e.g. \"first sites in country A, then in country B\"),</li> <li>the number or ratio of devices updating at a given time (e.g. \"first 1%, then 10%, then the rest\"), and</li> <li>the service availability during the rollout (e.g. \"update no more than two devices per site at a time\").</li> </ul> <p>Rollout policies in Flight Control build on label selection of devices (see Organizing Devices) and are thus adaptable to a wide range of use cases.</p>"},{"location":"user/managing-fleets/#defining-a-device-selection-strategy","title":"Defining a Device Selection Strategy","text":"<p>Currently, Flight Control only supports the <code>BatchSequence</code> strategy for device selection. This strategy defines a stepwise rollout process where devices are grouped into batches based on specific criteria.</p> <p>Batches are updated sequentially. After each batch completes, the rollout proceeds to the next batch, but only if the success ratio of the previous batch meets or exceeds the specified success threshold:</p> <pre><code># of successful updates in the batch\n------------------------------------  * 100% &gt;= success threshold [%]\n     # of devices in the batch\n</code></pre> <p>In a batch sequence, the final batch is an implicit batch. It is not specified in the batch sequence. It selects all devices in a fleet that have not been selected by the explicit batches in the sequence.</p> <p>To roll out updates in a sequence of batches, add a rollout policy to your fleet specification that defines a device selection strategy. Select the strategy <code>BatchSequence</code> and add a list of batch definitions. A device selection strategy uses the following parameters:</p> Parameter Description Strategy The device selection strategy. Must be <code>BatchSequence</code>. Sequence A list of explicit batch definitions that will be processed in sequence. <p>A batch definition takes the following parameters, of which at least one must be defined:</p> Parameter Description Selector (Optional) A label selector that selects devices to be included into the batch. Label selection works analogous to Selecting Devices into a Fleet, but limited to the device population of all devices in the fleet. Limit (Optional) Defines how many devices should be included in a batch at most. The limit can be specified either as an absolute number of devices or as percentage of the device population. If a selector is specified as well, that device population is the devices in the fleet that match the selector, otherwise it is all devices in the fleet."},{"location":"user/managing-fleets/#defining-a-device-selection-strategy-on-the-cli","title":"Defining a Device Selection Strategy on the CLI","text":"<p>To define a device selection strategy for the rollout, add a <code>rolloutPolicy</code> section to the fleet's specification that defines a <code>deviceSelection</code> strategy and a <code>successThreshold</code>.</p> <p>The following example defines a rollout policy with 5 batches (4 explicit and 1 implicit), so that updates are rolled out across the fleet as follows:</p> <ol> <li>Update 1 device from the set of devices labeled <code>stage: canary</code>.</li> <li>Update 10% of devices from the set of devices labeled <code>region: emea</code>.</li> <li>Update all remaining devices from the set of devices labeled <code>region: emea</code>.</li> <li>Update 10% of all devices in the fleet (might be none, if the previous batch already updated 10% of the total population of the fleet).</li> <li>(Implicit) Update all remaining devices in the fleet (might be none).</li> </ol> <pre><code>apiVersion: v1alpha1\nkind: Fleet\nmetadata:\n  name: default\nspec:\n  selector:\n    [...]\n  template:\n    [...]\n  rolloutPolicy:\n    deviceSelection:\n      strategy: 'BatchSequence'\n      sequence:\n        - selector:\n            matchLabels:\n              stage: canary\n          limit: 1\n        - selector:\n            matchLabels:\n              region: emea\n          limit: 1%\n        - selector:\n            matchLabels:\n              region: emea\n        - limit: 10%\n    successThreshold: 95%\n</code></pre>"},{"location":"user/managing-fleets/#defining-a-disruption-budget","title":"Defining a Disruption Budget","text":"<p>You can define a disruption budget to limit the number of devices that may be updated in parallel, ensuring a minimal level of service availability.</p> <p>A disruption budget takes the following parameters:</p> Parameter Description GroupBy Defines how devices are grouped when applying the disruption budget. The grouping is done by label keys. MinAvailable (Optional) Specifies the minimum number of devices per group that must remain available during a rollout. MaxUnavailable (Optional) Limits the number of devices per group that can be unavailable at the same time."},{"location":"user/managing-fleets/#defining-a-disruption-budget-on-the-cli","title":"Defining a Disruption Budget on the CLI","text":"<p>To define a disruption budget for the rollout, add a <code>rolloutPolicy</code> section to the fleet's specification that defines a <code>disruptionBudget</code> section.</p> <p>The following example assumes a fleet of smart displays in retail stores that are labeled with the store they are located in (<code>store: some-store-location</code>). To ensure a minimum of 2 displays in each store remain available during a rollout, define a disruption budget that groups displays store (<code>groupBy: [\"store\"]</code>), each group having <code>minAvailable: 2</code>:</p> <pre><code>apiVersion: v1alpha1\nkind: Fleet\nmetadata:\n  name: smart-display-fleet\nspec:\n  selector:\n    [...]\n  template:\n    [...]\n  rolloutPolicy:\n    disruptionBudget:\n      groupBy: [\"store\"]\n      minAvailable: 2\n</code></pre>"},{"location":"user/network-requirements/","title":"Flight Control Network Requirements","text":"<p>This document outlines the network requirements, port configurations, and firewall settings necessary for deploying and operating Flight Control.</p>"},{"location":"user/network-requirements/#overview","title":"Overview","text":"<p>Flight Control is a distributed system consisting of multiple services that communicate over the network. This document provides the information needed to configure firewalls, load balancers, and network policies to ensure proper operation.</p>"},{"location":"user/network-requirements/#network-architecture-diagram","title":"Network Architecture Diagram","text":"<p>The following diagram illustrates the Flight Control network architecture, showing all services, their ports, and communication flows:</p> <pre><code>graph TB\n    %% External Networks\n    subgraph \"External Networks\"\n        AGENTS[Flight Control Agents&lt;br/&gt;on Managed Devices]\n        USERS[Users/Administrators&lt;br/&gt;CLI, Web Browsers]\n        REGISTRIES[Container Registries&lt;br/&gt;quay.io, registry.redhat.io]\n        AUTH_EXT[External Auth Providers&lt;br/&gt;OIDC, AAP, OpenShift]\n        GIT[Git Repositories&lt;br/&gt;GitOps Config]\n    end\n\n    %% DMZ / Edge Network\n    subgraph \"DMZ / Edge Network\"\n        subgraph \"Load Balancers\"\n            LB_USER[User Load Balancer&lt;br/&gt;:443 \u2192 :3443]\n            LB_AGENT[Agent Load Balancer&lt;br/&gt;:7443 \u2192 :7443]\n        end\n    end\n\n    %% Internal Service Network\n    subgraph \"Internal Service Network\"\n        subgraph \"Flight Control Services\"\n            API[API Server&lt;br/&gt;:3443 - User API&lt;br/&gt;:7443 - Agent API&lt;br/&gt;:15690 - Metrics&lt;br/&gt;:15691 - DB Metrics]\n            WORKER[Worker Processes&lt;br/&gt;Background Tasks]\n            PERIODIC[Periodic Tasks&lt;br/&gt;Scheduled Jobs]\n            UI[Web UI&lt;br/&gt;:8080/:9000]\n            CLI_ARTIFACTS[CLI Artifacts&lt;br/&gt;:8090]\n        end\n\n        subgraph \"Authentication\"\n            KEYCLOAK[Keycloak&lt;br/&gt;:8081]\n        end\n\n        subgraph \"Data Layer\"\n            DB[PostgreSQL&lt;br/&gt;:5432]\n            KV[Redis&lt;br/&gt;:6379]\n        end\n\n        subgraph \"Observability\"\n            PROMETHEUS[Prometheus&lt;br/&gt;:9090]\n            ALERTMANAGER[Alertmanager&lt;br/&gt;:9093]\n            ALERT_PROXY[Alertmanager Proxy&lt;br/&gt;:8443]\n            ALERT_EXPORTER[Alert Exporter&lt;br/&gt;:8081]\n            GRAFANA[Grafana&lt;br/&gt;:3000]\n            OTEL[OpenTelemetry&lt;br/&gt;:4317 gRPC&lt;br/&gt;:4318 HTTP]\n            JAEGER[Jaeger&lt;br/&gt;:16686]\n            USERINFO[UserInfo Proxy&lt;br/&gt;:8080]\n        end\n    end\n\n    %% Agent Communication Flow\n    AGENTS -.-&gt;|\"HTTPS/mTLS&lt;br/&gt;Port 7443&lt;br/&gt;Every 60s\"| LB_AGENT\n    LB_AGENT --&gt; API\n\n    %% User Communication Flow\n    USERS -.-&gt;|\"HTTPS&lt;br/&gt;Port 443\"| LB_USER\n    LB_USER --&gt; API\n    USERS -.-&gt;|\"HTTP/HTTPS&lt;br/&gt;Port 9000\"| UI\n    USERS -.-&gt;|\"HTTP/HTTPS&lt;br/&gt;Port 8090\"| CLI_ARTIFACTS\n    USERS -.-&gt;|\"HTTP&lt;br/&gt;Port 8081\"| KEYCLOAK\n\n    %% Internal Service Communication\n    API --&gt; DB\n    API --&gt; KV\n    WORKER --&gt; API\n    WORKER --&gt; DB\n    PERIODIC --&gt; API\n    PERIODIC --&gt; DB\n    UI --&gt; API\n    CLI_ARTIFACTS --&gt; API\n\n    %% Authentication Flow\n    API --&gt; KEYCLOAK\n    API -.-&gt;|\"HTTPS&lt;br/&gt;Port 443\"| AUTH_EXT\n\n    %% Observability Flow\n    API --&gt; PROMETHEUS\n    WORKER --&gt; PROMETHEUS\n    PERIODIC --&gt; PROMETHEUS\n    ALERT_EXPORTER --&gt; ALERTMANAGER\n    ALERT_PROXY --&gt; ALERTMANAGER\n    PROMETHEUS --&gt; ALERTMANAGER\n    GRAFANA --&gt; PROMETHEUS\n    GRAFANA --&gt; USERINFO\n\n    %% External Dependencies\n    API -.-&gt;|\"HTTPS&lt;br/&gt;Port 443\"| REGISTRIES\n    API -.-&gt;|\"HTTPS&lt;br/&gt;Port 443\"| GIT\n    AGENTS -.-&gt;|\"HTTPS&lt;br/&gt;Port 443\"| REGISTRIES\n\n    %% External Access to Observability\n    USERS -.-&gt;|\"HTTPS&lt;br/&gt;Port 8443\"| ALERT_PROXY\n    USERS -.-&gt;|\"HTTP&lt;br/&gt;Port 3000\"| GRAFANA\n    USERS -.-&gt;|\"gRPC :4317&lt;br/&gt;HTTP :4318\"| OTEL\n\n    %% Styling\n    classDef external fill:#e1f5fe,stroke:#0277bd,stroke-width:2px\n    classDef dmz fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px\n    classDef service fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px\n    classDef data fill:#fff3e0,stroke:#ef6c00,stroke-width:2px\n    classDef observability fill:#fce4ec,stroke:#c2185b,stroke-width:2px\n    classDef auth fill:#f1f8e9,stroke:#558b2f,stroke-width:2px\n\n    class AGENTS,USERS,REGISTRIES,AUTH_EXT,GIT external\n    class LB_USER,LB_AGENT dmz\n    class API,WORKER,PERIODIC,UI,CLI_ARTIFACTS service\n    class DB,KV data\n    class PROMETHEUS,ALERTMANAGER,ALERT_PROXY,ALERT_EXPORTER,GRAFANA,OTEL,JAEGER,USERINFO observability\n    class KEYCLOAK auth</code></pre>"},{"location":"user/network-requirements/#diagram-legend","title":"Diagram Legend","text":"<ul> <li>Blue (External): External networks and services</li> <li>Purple (DMZ): Load balancers and edge services</li> <li>Green (Service): Core Flight Control services</li> <li>Orange (Data): Database and storage services</li> <li>Pink (Observability): Monitoring and observability services</li> <li> <p>Light Green (Auth): Authentication services</p> </li> <li> <p>Solid arrows: Internal network communication</p> </li> <li>Dashed arrows: External network communication with ports specified</li> </ul>"},{"location":"user/network-requirements/#core-service-ports","title":"Core Service Ports","text":""},{"location":"user/network-requirements/#flight-control-api-server","title":"Flight Control API Server","text":"<ul> <li>Port 3443 (TCP) - HTTPS - Main API endpoint for users, CLI, and web UI</li> <li>Port 7443 (TCP) - HTTPS with mTLS - Agent-facing API endpoint for device communication</li> <li>Port 15690 (TCP) - HTTP - Prometheus metrics endpoint (internal)</li> <li>Port 15691 (TCP) - HTTP - Database metrics endpoint (internal)</li> </ul>"},{"location":"user/network-requirements/#database-services","title":"Database Services","text":"<ul> <li>Port 5432 (TCP) - PostgreSQL - Database connection (internal)</li> <li>Port 6379 (TCP) - Redis - Key-value store for caching (internal)</li> </ul>"},{"location":"user/network-requirements/#web-user-interface","title":"Web User Interface","text":"<ul> <li>Port 8080 (TCP) - HTTP/HTTPS - Web UI (exposed via reverse proxy)</li> <li>Port 9000 (TCP) - HTTP - Web UI (development/nodePort deployments)</li> </ul>"},{"location":"user/network-requirements/#authentication-services","title":"Authentication Services","text":"<ul> <li>Port 8081 (TCP) - HTTP - Keycloak authentication server (when using built-in auth)</li> </ul>"},{"location":"user/network-requirements/#observability-and-monitoring","title":"Observability and Monitoring","text":"<ul> <li>Port 9090 (TCP) - HTTP - Prometheus server (internal)</li> <li>Port 9093 (TCP) - HTTP - Alertmanager (internal)</li> <li>Port 8443 (TCP) - HTTPS - Alertmanager proxy (authenticated access)</li> <li>Port 8081 (TCP) - HTTP - Alert exporter metrics (internal)</li> <li>Port 3000 (TCP) - HTTP - Grafana dashboard (when enabled)</li> <li>Port 4317 (TCP) - gRPC - OpenTelemetry collector (gRPC)</li> <li>Port 4318 (TCP) - HTTP - OpenTelemetry collector (HTTP)</li> <li>Port 8080 (TCP) - HTTP - UserInfo proxy (internal, AAP integration)</li> </ul>"},{"location":"user/network-requirements/#additional-services","title":"Additional Services","text":"<ul> <li>Port 8090 (TCP) - HTTP/HTTPS - CLI artifacts server</li> <li>Port 16686 (TCP) - HTTP - Jaeger tracing UI (development)</li> </ul>"},{"location":"user/network-requirements/#network-communication-patterns","title":"Network Communication Patterns","text":""},{"location":"user/network-requirements/#agent-to-service-communication","title":"Agent-to-Service Communication","text":"<ul> <li>Source: Flight Control agents on managed devices</li> <li>Destination: Flight Control API server port 7443</li> <li>Protocol: HTTPS with mutual TLS (mTLS)</li> <li>Direction: Outbound from agents, inbound to service</li> <li>Frequency: Periodic (default: every 60 seconds)</li> </ul>"},{"location":"user/network-requirements/#user-to-service-communication","title":"User-to-Service Communication","text":"<ul> <li>Source: Users, CLI tools, web browsers</li> <li>Destination: Flight Control API server port 3443</li> <li>Protocol: HTTPS with JWT authentication</li> <li>Direction: Inbound to service</li> </ul>"},{"location":"user/network-requirements/#internal-service-communication","title":"Internal Service Communication","text":"<ul> <li>Database: Services connect to PostgreSQL (port 5432) and Redis (port 6379)</li> <li>Metrics: Services expose Prometheus metrics on various ports</li> <li>Alerting: Alert exporter connects to Alertmanager (port 9093)</li> </ul>"},{"location":"user/network-requirements/#firewall-configuration","title":"Firewall Configuration","text":""},{"location":"user/network-requirements/#inbound-rules-service-host","title":"Inbound Rules (Service Host)","text":""},{"location":"user/network-requirements/#required-for-agent-communication","title":"Required for Agent Communication","text":"<pre><code>ACCEPT tcp port 7443 from any (agents can be on any network)\n</code></pre>"},{"location":"user/network-requirements/#required-for-user-access","title":"Required for User Access","text":"<pre><code>ACCEPT tcp port 3443 from trusted networks/users\nACCEPT tcp port 9000 from trusted networks/users (UI - nodePort deployments)\nACCEPT tcp port 8090 from trusted networks/users (CLI artifacts)\n</code></pre>"},{"location":"user/network-requirements/#required-for-authentication-if-using-built-in-keycloak","title":"Required for Authentication (if using built-in Keycloak)","text":"<pre><code>ACCEPT tcp port 8081 from trusted networks/users\n</code></pre>"},{"location":"user/network-requirements/#required-for-observability-if-externally-accessible","title":"Required for Observability (if externally accessible)","text":"<pre><code>ACCEPT tcp port 8443 from trusted networks/users (Alertmanager proxy)\nACCEPT tcp port 3000 from trusted networks/users (Grafana)\nACCEPT tcp port 4317 from monitoring systems (OpenTelemetry gRPC)\nACCEPT tcp port 4318 from monitoring systems (OpenTelemetry HTTP)\n</code></pre>"},{"location":"user/network-requirements/#optional-for-developmenttesting","title":"Optional for Development/Testing","text":"<pre><code>ACCEPT tcp port 5432 from trusted networks (PostgreSQL - development only)\nACCEPT tcp port 9090 from trusted networks (Prometheus - development only)\nACCEPT tcp port 16686 from trusted networks (Jaeger - development only)\n</code></pre>"},{"location":"user/network-requirements/#outbound-rules-service-host","title":"Outbound Rules (Service Host)","text":""},{"location":"user/network-requirements/#required-for-external-dependencies","title":"Required for External Dependencies","text":"<pre><code>ACCEPT tcp port 443 to container registries (quay.io, registry.redhat.io, etc.)\nACCEPT tcp port 443 to external authentication providers (OIDC, AAP, etc.)\nACCEPT tcp port 443 to Git repositories (if using GitOps)\nACCEPT tcp port 53 to DNS servers\n</code></pre>"},{"location":"user/network-requirements/#required-for-container-operations","title":"Required for Container Operations","text":"<pre><code>ACCEPT tcp port 443 to container registries for image pulls\nACCEPT tcp port 80 to container registries (if using insecure registries)\n</code></pre>"},{"location":"user/network-requirements/#outbound-rules-agent-hosts","title":"Outbound Rules (Agent Hosts)","text":""},{"location":"user/network-requirements/#required-for-agent-operation","title":"Required for Agent Operation","text":"<pre><code>ACCEPT tcp port 7443 to Flight Control service\nACCEPT tcp port 443 to container registries (for OS and app image pulls)\nACCEPT tcp port 53 to DNS servers\n</code></pre>"},{"location":"user/network-requirements/#optional-for-container-operations","title":"Optional for Container Operations","text":"<pre><code>ACCEPT tcp port 80 to container registries (if using insecure registries)\n</code></pre>"},{"location":"user/network-requirements/#load-balancer-configuration","title":"Load Balancer Configuration","text":""},{"location":"user/network-requirements/#production-deployments","title":"Production Deployments","text":"<p>For production deployments, configure load balancers as follows:</p>"},{"location":"user/network-requirements/#user-facing-load-balancer","title":"User-Facing Load Balancer","text":"<ul> <li>Frontend: Port 443 (HTTPS)</li> <li>Backend: Port 3443 (Flight Control API)</li> <li>Health Check: <code>/api/v1/fleets</code> (requires authentication)</li> <li>Session Affinity: None required</li> </ul>"},{"location":"user/network-requirements/#agent-facing-load-balancer","title":"Agent-Facing Load Balancer","text":"<ul> <li>Frontend: Port 7443 (HTTPS with mTLS)</li> <li>Backend: Port 7443 (Flight Control API)</li> <li>Health Check: TCP check or <code>/api/v1/fleets</code> (requires valid client cert)</li> <li>Session Affinity: None required</li> <li>Client Certificate: Must be configured for mTLS passthrough</li> </ul>"},{"location":"user/network-requirements/#kubernetes-network-policies","title":"Kubernetes Network Policies","text":""},{"location":"user/network-requirements/#namespace-communication","title":"Namespace Communication","text":"<p>When deployed in Kubernetes, Flight Control services require communication between:</p> <ul> <li>Service namespace (default: <code>flightctl</code>)</li> <li>Internal namespace (default: <code>flightctl-internal</code>)</li> <li>External namespace (for external services)</li> </ul>"},{"location":"user/network-requirements/#pod-to-pod-communication","title":"Pod-to-Pod Communication","text":"<ul> <li>API server needs access to database pods</li> <li>Worker processes need access to API server and database</li> <li>Monitoring services need access to all service pods</li> </ul>"},{"location":"user/network-requirements/#gateway-configuration","title":"Gateway Configuration","text":""},{"location":"user/network-requirements/#kubernetes-gateway-api","title":"Kubernetes Gateway API","text":"<p>When using Gateway API for ingress:</p>"},{"location":"user/network-requirements/#tls-gateway-port-443","title":"TLS Gateway (Port 443)","text":"<pre><code>- name: api\n  hostname: '*.flightctl.example.com'\n  port: 443\n  protocol: TLS\n  tls:\n    mode: Passthrough\n</code></pre>"},{"location":"user/network-requirements/#http-gateway-port-80","title":"HTTP Gateway (Port 80)","text":"<pre><code>- name: ui\n  hostname: 'ui.flightctl.example.com'\n  port: 80\n  protocol: HTTP\n</code></pre>"},{"location":"user/network-requirements/#container-registry-requirements","title":"Container Registry Requirements","text":""},{"location":"user/network-requirements/#required-registries","title":"Required Registries","text":"<p>Flight Control needs access to the following container registries:</p>"},{"location":"user/network-requirements/#public-registries","title":"Public Registries","text":"<ul> <li>quay.io - Flight Control images</li> <li>registry.redhat.io - RHEL-based images</li> <li>docker.io - Base images and dependencies</li> </ul>"},{"location":"user/network-requirements/#private-registries","title":"Private Registries","text":"<ul> <li>Configure authentication credentials as needed</li> <li>Ensure TLS certificates are trusted</li> </ul>"},{"location":"user/network-requirements/#dns-requirements","title":"DNS Requirements","text":""},{"location":"user/network-requirements/#service-discovery","title":"Service Discovery","text":"<ul> <li>Flight Control services use DNS for service discovery</li> <li>Kubernetes: Services use cluster DNS</li> <li>Podman: Services use container names within networks</li> </ul>"},{"location":"user/network-requirements/#external-dependencies","title":"External Dependencies","text":"<ul> <li>Container registry hostnames must resolve</li> <li>Authentication provider hostnames must resolve</li> <li>Git repository hostnames must resolve (if using GitOps)</li> </ul>"},{"location":"user/network-requirements/#security-considerations","title":"Security Considerations","text":""},{"location":"user/network-requirements/#network-segmentation","title":"Network Segmentation","text":"<ul> <li>Separate networks for management traffic vs. device traffic</li> <li>Isolate database and internal services from external access</li> <li>Use network policies to restrict pod-to-pod communication</li> </ul>"},{"location":"user/network-requirements/#certificate-management","title":"Certificate Management","text":"<ul> <li>Agent communication uses mTLS with client certificates</li> <li>Certificates are automatically rotated</li> <li>Ensure proper CA certificate distribution</li> </ul>"},{"location":"user/network-requirements/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<ul> <li>Monitor network connectivity between services</li> <li>Set up alerts for certificate expiration</li> <li>Monitor for unusual traffic patterns</li> </ul>"},{"location":"user/network-requirements/#troubleshooting-network-issues","title":"Troubleshooting Network Issues","text":""},{"location":"user/network-requirements/#common-network-problems","title":"Common Network Problems","text":"<ol> <li>Agent Connection Failures</li> <li>Check port 7443 accessibility</li> <li>Verify certificate validity</li> <li> <p>Check DNS resolution</p> </li> <li> <p>User Access Issues</p> </li> <li>Verify port 3443 accessibility</li> <li>Check authentication service connectivity</li> <li> <p>Verify load balancer configuration</p> </li> <li> <p>Service Communication Issues</p> </li> <li>Check internal network connectivity</li> <li>Verify service discovery</li> <li>Check network policies</li> </ol>"},{"location":"user/network-requirements/#network-diagnostic-commands","title":"Network Diagnostic Commands","text":"<pre><code># Test API connectivity\ncurl -k https://api.flightctl.example.com:3443/api/v1/fleets\n\n# Test agent endpoint\ncurl -k https://agent-api.flightctl.example.com:7443/api/v1/fleets\n\n# Test DNS resolution\nnslookup api.flightctl.example.com\n\n# Test port connectivity\ntelnet api.flightctl.example.com 3443\n</code></pre>"},{"location":"user/network-requirements/#environment-specific-configurations","title":"Environment-Specific Configurations","text":""},{"location":"user/network-requirements/#development-environment","title":"Development Environment","text":"<ul> <li>Uses NodePort services (ports 3443, 7443, 9000, 8081)</li> <li>May expose internal services for debugging</li> <li>Less restrictive firewall rules</li> </ul>"},{"location":"user/network-requirements/#production-environment","title":"Production Environment","text":"<ul> <li>Uses LoadBalancer or Ingress controllers</li> <li>Restricts internal service access</li> <li>Implements network policies and security groups</li> </ul>"},{"location":"user/network-requirements/#air-gapped-environment","title":"Air-Gapped Environment","text":"<ul> <li>Requires local container registry</li> <li>May need proxy configuration</li> <li>Ensure all required images are mirrored locally</li> </ul>"},{"location":"user/network-requirements/#port-reference-table","title":"Port Reference Table","text":"Service Port Protocol Access Description API Server 3443 HTTPS External Main API endpoint API Server 7443 HTTPS/mTLS External Agent endpoint Web UI 8080 HTTP/HTTPS External Web interface Web UI 9000 HTTP External Development UI PostgreSQL 5432 TCP Internal Database Redis 6379 TCP Internal Key-value store Keycloak 8081 HTTP External Authentication Prometheus 9090 HTTP Internal Metrics Alertmanager 9093 HTTP Internal Alerting Alertmanager Proxy 8443 HTTPS External Authenticated alerts Grafana 3000 HTTP External Dashboards OTel Collector 4317 gRPC External Telemetry OTel Collector 4318 HTTP External Telemetry CLI Artifacts 8090 HTTP/HTTPS External CLI downloads Alert Exporter 8081 HTTP Internal Metrics UserInfo Proxy 8080 HTTP Internal AAP integration Jaeger 16686 HTTP Internal Tracing (dev)"},{"location":"user/network-requirements/#summary","title":"Summary","text":"<p>This document provides comprehensive network requirements for Flight Control. The key points are:</p> <ol> <li>Agent communication requires port 7443 (HTTPS/mTLS) to be accessible from device networks</li> <li>User access requires port 3443 (HTTPS) for API and appropriate UI ports</li> <li>Internal services use various ports that should be restricted to internal networks</li> <li>External dependencies require outbound HTTPS access to container registries and auth providers</li> <li>Monitoring and observability services have additional port requirements</li> </ol> <p>For specific deployment configurations, adjust firewall rules and load balancer settings according to your environment's security requirements.</p>"},{"location":"user/provisioning-devices/","title":"Provisioning Devices","text":"<p>This section describes how to provision an OS image or disk image to a physical or virtual device, depending on your target environment.</p>"},{"location":"user/provisioning-devices/#testing-an-os-image-on-a-developer-machine","title":"Testing an OS image on a developer machine","text":"<p>You can inspect the content of your bootc OS image by running the following command, which starts a container with an interactive shell:</p> <pre><code>podman run -it --rm &lt;your_bootc_image&gt; bash\n</code></pre> <p>For testing, you can also \"boot\" the OS image in the sense of running a container that launches systemd, which is the default for bootc images if you do not specify a command to run explicitly.</p> <p>[!IMPORTANT]</p> <ul> <li>This does not boot the kernel inside the image but relies on the host kernel.</li> <li>Expect that not all services start and run correctly when containerized and without full system access. They may still run correctly when deployed on a physical or virtual machine.</li> <li>Do not run the container <code>--privileged</code> without restrictions, as services inside the container may interfere with the host (see the bootc documentation).</li> </ul> <p>Start the container by running the following command:</p> <pre><code>sudo podman run -it --rm --name=my-bootc-container \\\n  --hostname=my-bootc-host \\\n  --privileged -v /sys:/sys:ro --userns=auto \\\n  &lt;your_bootc_image&gt;\n</code></pre> <p>You will see the messages generated by the systemd services starting up and typically end up at a login prompt. To detach from the console, type <code>&lt;ctrl+p&gt;</code> and <code>&lt;ctrl+q&gt;</code> in sequence.</p> <p>You can <code>exec</code> into the running container by running:</p> <pre><code>sudo podman exec -it my-bootc-container bash\n</code></pre>"},{"location":"user/provisioning-devices/#provisioning-physical-devices","title":"Provisioning Physical Devices","text":"<p>After building an ISO disk image from an OS image (bootc) by using <code>bootc-image-builder</code> tool, the resulting image is a system similar to the RHEL ISOs available for download, except that your OS image content is embedded in the ISO disk image. You do not need to have access to the network during installation. You can install the resulting ISO disk image to a bare metal system. See Building and Publishing OS Images and Disk Images.</p> <p>Prerequisites</p> <ul> <li>You have created an ISO disk image with your bootc image embedded.</li> </ul> <p>To provision a physical device from that ISO disk image, perform the following steps:</p> <ul> <li> <p>Copy your ISO disk image to a USB flash drive.</p> </li> <li> <p>Install your physical device from the USB flash drive.</p> </li> </ul> <p>For installing the ISO over the network, see the RHEL documentation.</p>"},{"location":"user/provisioning-devices/#provisioning-on-red-hat-openshift-virtualization","title":"Provisioning on Red Hat OpenShift Virtualization","text":"<p>You can provision a virtual machine on OpenShift Virtualization from a QCoW2 disk image hosted on an OCI container registry (see Image Building for OpenShift Virtualization).</p> <p>If your OS image does not already contain the agent enrollment configuration, you can inject this configuration through <code>cloud-init</code> user data at provisioning-time (late binding).</p> <p>Prerequisites:</p> <ul> <li>You have installed the Flight Control <code>flightctl</code> CLI and logged in to your Flight Control service instance.</li> <li>You have installed the OpenShift <code>oc</code> CLI, used it to log in to your OpenShift cluster instance, and have changed to the project in which you want to create your VM.</li> </ul> <p>To create the cloud-init configuration, perform the following steps:</p> <ul> <li>Request a new agent enrollment configuration, storing it in a file called \"config.yaml\":</li> </ul> <pre><code>flightctl certificate request --signer=enrollment --expiration=365d --output=embedded &gt; config.yaml\n</code></pre> <ul> <li>Create cloud config user data file called \"cloud-config.yaml\" that places the agent configuration in the right location on first boot:</li> </ul> <pre><code>cat &lt;&lt; END &gt; cloud-config.yaml\n#cloud-config\nwrite_files:\n- path: /etc/flightctl/config.yaml\n  content: $(cat config.yaml | base64 -w0)\n  encoding: b64\nEND\n</code></pre> <ul> <li>Finally, create a Kubernetes Secret that contains this cloud config user data file:</li> </ul> <pre><code>oc create secret generic enrollment-secret --from-file=userdata=cloud-config.yaml\n</code></pre> <p>To create a virtual machine that has its primary disk populated from your QCoW2 container disk image and a cloud-init config drive populated from your enrollment secret, perform the following steps:</p> <ul> <li>Create a file containing a virtual machine resource manifest following this example:</li> </ul> <pre><code>cat &lt;&lt; END &gt; my-bootc-vm.yaml\napiVersion: kubevirt.io/v1\nkind: VirtualMachine\nmetadata:\n  name: my-bootc-vm\nspec:\n  runStrategy: RerunOnFailure\n  template:\n    spec:\n      domain:\n        cpu:\n          cores: 1\n        memory:\n          guest: 1024M\n        devices:\n          disks:\n            - name: containerdisk\n              disk:\n                bus: virtio\n            - name: cloudinitdisk\n              disk:\n                bus: virtio\n      volumes:\n        - name: containerdisk\n          containerDisk:\n            image: &lt;your_container_disk_repo_and_tag&gt;\n        - name: cloudinitdisk\n          cloudInitConfigDrive:\n            secretRef:\n              name: enrollment-secret\nEND\n</code></pre> <ul> <li>Apply this resource manifest to your cluster:</li> </ul> <pre><code>oc apply -f my-bootc-vm.yaml\n</code></pre>"},{"location":"user/provisioning-devices/#provisioning-on-vmware-vsphere","title":"Provisioning on VMware vSphere","text":"<p>You can provision a virtual machine on VMware vSphere from a VMDK disk image (see Image Building for VMware vSphere). See this blog post for a detailed explanation integrating a VMDK produced from OS images into vSphere.</p> <p>If your OS image does not already contain the agent enrollment configuration, you can inject this configuration through <code>cloud-init</code> user data at provisioning-time (late binding).</p> <p>Prerequisites:</p> <ul> <li>You have installed the Flight Control <code>flightctl</code> CLI and logged in to your Flight Control service instance.</li> <li>You have installed the VMware <code>govc</code> CLI and logged in to your remote vSphere environment (see the installation guide).</li> <li>You have built a VMDK disk image called \"disk.vmdk\" and have it available on the machine running the following commands.</li> </ul> <p>To create the cloud-init configuration, perform the following steps:</p> <ul> <li>Request a new agent enrollment configuration, storing it in a file called \"config.yaml\":</li> </ul> <pre><code>flightctl certificate request --signer=enrollment --expiration=365d --output=embedded &gt; config.yaml\n</code></pre> <ul> <li>Create cloud config user data file called \"cloud-config.yaml\" that places the agent configuration in the right location on first boot:</li> </ul> <pre><code>cat &lt;&lt;EOF &gt; cloud-config.yaml\n#cloud-config\nwrite_files:\n- path: /etc/flightctl/config.yaml\n  content: $(cat config.yaml | base64 -w0)\n  encoding: b64\nEOF\n</code></pre> <p>To upload your VMDK disk image and create a virtual machine from it, perform the following steps:</p> <ul> <li>Upload the disk.vmdk file to a desired directory in vSphere.</li> </ul> <pre><code>govc import.vmdk \\\n  -dc=\"${DATACENTER}\" -ds=\"${DATASTORE}\" -pool=\"${DATACENTER_POOL}\" \\\n  disk.vmdk ${DESTINATION_FOLDER}\n</code></pre> <ul> <li>Confirm the file has been uploaded by listing files within the datastore directory.</li> </ul> <pre><code>govc datastore.ls \\\n  -dc=\"${DATACENTER}\" -ds=\"${DATASTORE}\" \\\n  ${DESTINATION_FOLDER}\n</code></pre> <p>You should see two files, \"disk.vmdk\" and \"disk-flat.vmdk\".</p> <ul> <li>Create the virtual machine.</li> </ul> <pre><code>govc vm.create \\\n  -dc=\"${DATACENTER}\" \\\n  -ds=\"${DATASTORE}\" \\\n  -pool=\"${DATACENTER_POOL}\" \\\n  -net=\"${NETWORK}\" \\\n  -disk.controller=pvscsi \\\n  -on=false \\\n  -c=1 -m=1024 \\\n  -g=\"rhel9_64Guest\" \\\n  -firmware=\"${FIRMWARE}\" \\\n  my-bootc-vm\n</code></pre> <ul> <li>Copy the uploaded disk to the folder of the VM you created.</li> </ul> <pre><code>govc datastore.cp \\\n  -ds=${DATASTORE} ${DESTINATION_FOLDER}/disk.vmdk my-bootc-vm/disk.vmdk\n</code></pre> <ul> <li>Attach the VMDK disk image to the newly created virtual machine.</li> </ul> <pre><code>govc vm.disk.attach \\\n  -dc=\"${DATACENTER}\" -ds=\"${DATASTORE}\" \\\n  -link=false \\\n  -vm=\"my-bootc-vm\" \\\n  -disk=\"my-bootc-vm/disk.vmdk\"\n</code></pre> <ul> <li>Attach the cloud-init user data to the virtual machine.</li> </ul> <pre><code>govc vm.change \\\n  -dc=\"${DATACENTER}\" \\\n  -vm=\"my-bootc-vm\" \\\n  -e guestinfo.userdata=\"$(gzip -c9 &lt;cloud-config.yaml | { base64 -w0 2&gt;/dev/null || base64; })\" \\\n  -e guestinfo.userdata.encoding=\"gzip+base64\"\n</code></pre> <ul> <li>Power on the virtual machine.</li> </ul> <pre><code>govc vm.power -dc=\"${DATACENTER}\" -on=true my-bootc-vm\n</code></pre>"},{"location":"user/registering-microshift-devices-acm/","title":"Auto-Registering Devices with MicroShift into ACM","text":"<p>If you have fleets of devices running an OS image that includes MicroShift, you can configure these fleets to auto-register MicroShift clusters with Red Hat Advanced Cluster Management (ACM).</p> <p>Auto-registration relies on ACM's agent registration method for importing clusters. That method allows fetching the Kubernetes resource manifests to install ACM's klusterlet agent and registering the agent through calls to a REST API. This REST API can be set up as configuration source for devices by creating a Repository resource and referencing that resource from the fleet's device template.</p>"},{"location":"user/registering-microshift-devices-acm/#auto-registering-a-fleets-devices-using-the-web-ui","title":"Auto-Registering a Fleet's Devices using the Web UI","text":""},{"location":"user/registering-microshift-devices-acm/#auto-registering-a-fleets-devices-using-the-cli","title":"Auto-Registering a Fleet's Devices using the CLI","text":""},{"location":"user/registering-microshift-devices-acm/#creating-the-acm-registration-repository","title":"Creating the ACM Registration Repository","text":"<p>[!NOTE] When using ACM with integrated Flight Control, the creation of this repository happens automatically when the Flight Control service is deployed, so this section can be skipped.</p> <p>To set up auto-registration using the CLI, follow the procedure for \"Importing a managed cluster by using agent registration\" in ACM's documentation to configure the necessary Role-Based Access Control (RBAC) policies for your user and obtain the required registration information. Skip the last step of the actual cluster import, which will be handled by auto-registration.</p> <p>After following the procedure, you should have the following information available and stored in shell variables:</p> <ul> <li><code>${agent_registration_host}</code>: The hostname part of ACM's agent registration server URL.</li> <li><code>${cacert}</code>: The path to the <code>ca.crt</code> file for ACM's agent registration server.</li> <li><code>${token}</code>: The bearer token for accessing ACM's agent registration server.</li> </ul> <p>With these variables defined, create a Repository resource manifest file <code>acm-registration-repo.yaml</code> for accessing the agent registration server by running the following command:</p> <pre><code>cat &lt;&lt;- EOF &gt; acm-registration-repo.yaml\n  apiVersion: flightctl.io/v1alpha1\n  kind: Repository\n  metadata:\n    name: acm-registration\n  spec:\n    httpConfig:\n      token: ${token}\n      ca.crt: $(base64 -w0 &lt; ${cacert})\n    type: http\n    url: https://${agent_registration_host}\n    validationSuffix: /agent-registration/crds/v1\nEOF\n</code></pre> <p>Create the Repository resource by applying the file:</p> <pre><code>flightctl apply -f acm-registration-repo.yaml\n</code></pre>"},{"location":"user/registering-microshift-devices-acm/#adding-auto-registration-configuration-to-a-fleets-device-template","title":"Adding Auto-Registration Configuration to a Fleet's Device Template","text":"<p>To enable auto-registration in a fleet, add configuration items to the fleet's device template as shown in the following example:</p> <pre><code>apiVersion: flightctl.io/v1alpha1\nkind: Fleet\nmetadata:\n  name: fleet-acm\nspec:\n  template:\n    spec:\n      os:\n        image: quay.io/someorg/someimage-with-microshift:v1\n      config:\n      - name: acm-crd\n        httpRef:\n          filePath: /var/local/acm-import/crd.yaml\n          repository: acm-registration\n          suffix: /agent-registration/crds/v1\n      - name: acm-import\n        httpRef:\n          filePath: /var/local/acm-import/import.yaml\n          repository: acm-registration\n          suffix: /agent-registration/manifests/{{.metadata.name}}\n      - name: pull-secret\n        inline:\n        - path: \"/etc/crio/openshift-pull-secret\"\n          content: \"{\\\"auths\\\":{...}}\"\n      - name: apply-acm-manifests\n        inline:\n        - path: \"/etc/flightctl/hooks.d/afterupdating/50-acm-registration.yaml\"\n          content: |\n            - run: /usr/bin/bash -c \"until [ -f $KUBECONFIG ]; do sleep 1; done\"\n              timeout: 5m\n              envVars:\n                KUBECONFIG: /var/lib/microshift/resources/kubeadmin/kubeconfig\n            - run: kubectl wait --for=condition=Ready pods --all --all-namespaces --timeout=300s\n              timeout: 5m\n              envVars:\n                KUBECONFIG: /var/lib/microshift/resources/kubeadmin/kubeconfig\n            - if:\n              - path: /var/local/acm-import/crd.yaml\n                op: [created]\n              run: kubectl apply -f /var/local/acm-import/crd.yaml\n              envVars:\n                KUBECONFIG: /var/lib/microshift/resources/kubeadmin/kubeconfig\n            - if:\n              - path: /var/local/acm-import/import.yaml\n                op: [created]\n              run: kubectl apply -f /var/local/acm-import/import.yaml\n              envVars:\n                KUBECONFIG: /var/lib/microshift/resources/kubeadmin/kubeconfig\n</code></pre> <p>The added items under <code>.spec.template.spec.config</code> have the following functions:</p> <ul> <li><code>acm-crd</code> uses the HTTP Configuration Provider to query the ACM agent-registration server for the Kubernetes manifests containing the custom resource definition (CRD) for ACM's klusterlet agent. These manifests are stored in the device's filesystem in the file <code>/var/local/acm-import/crd.yaml</code>.</li> <li><code>acm-import</code> queries the server once more to receive the import manifests for a cluster whose name is the same as the device's name, so both can be more easily correlated later. This is achieved by using the templating variable <code>{{ .metadata.name }}</code>. The returned manifests are stored in the same location on the device's filesystem as <code>import.yaml</code>.</li> <li><code>pull-secret</code> optionally adds your OpenShift pull secret to the device, so MicroShift can pull the ACM agent's images from the container registry. You can download your pull secret from the OpenShift installation page. This item is not necessary if you've already provisioned your pull secret in another way, for example by embedding it into the OS image. Also, you can use other configuration providers to add this secret.</li> <li><code>apply-acm-manifests</code> installs an <code>afterUpdating</code> device lifecycle hook (see Using Device Lifecycle Hooks). This hook gets called once after the agent has created the <code>crd.yaml</code> and <code>import.yaml</code> files and applies the manifests to the MicroShift cluster using the <code>kubectl</code> CLI.</li> </ul>"},{"location":"user/security-guidelines/","title":"Flight Control Security Guidelines","text":"<p>This document provides comprehensive security guidelines for deploying and operating Flight Control in production environments. It covers authentication mechanisms, data protection, insecure settings, and security best practices.</p>"},{"location":"user/security-guidelines/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Authentication and Authorization</li> <li>Data Protection</li> <li>Network Security</li> <li>Device Security</li> <li>Database Security</li> <li>Logging and Auditing</li> <li>Insecure Settings and Default Configurations</li> </ul>"},{"location":"user/security-guidelines/#overview","title":"Overview","text":"<p>Flight Control is a device management platform that provides secure enrollment, configuration management, and monitoring of edge devices. The system uses hardware root-of-trust, mutual TLS authentication, and certificate-based identity management to ensure secure device operations.</p>"},{"location":"user/security-guidelines/#security-architecture","title":"Security Architecture","text":"<p>Flight Control implements a multi-layered security approach:</p> <ul> <li>Hardware Root-of-Trust: TPM-based device identity and attestation</li> <li>Certificate-Based Authentication: X.509 certificates for all communications</li> <li>Mutual TLS (mTLS): Bidirectional certificate verification</li> <li>Role-Based Access Control: Granular permissions for users and devices</li> <li>Encrypted Communications: TLS 1.3 for all network communications</li> </ul>"},{"location":"user/security-guidelines/#authentication-and-authorization","title":"Authentication and Authorization","text":""},{"location":"user/security-guidelines/#user-authentication","title":"User Authentication","text":"<p>Flight Control supports multiple authentication providers:</p>"},{"location":"user/security-guidelines/#kubernetes-authentication","title":"Kubernetes Authentication","text":"<ul> <li>Type: <code>k8s</code></li> <li>Description: Uses Kubernetes service account tokens for authentication</li> </ul> <pre><code>auth:\n  type: k8s\n  k8s:\n    serviceAccountToken: \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n</code></pre>"},{"location":"user/security-guidelines/#oidc-authentication","title":"OIDC Authentication","text":"<ul> <li>Type: <code>oidc</code></li> <li>Description: OpenID Connect authentication with external providers</li> </ul> <pre><code>auth:\n  type: oidc\n  oidc:\n    issuerURL: \"https://your-oidc-provider.com\"\n    clientID: \"flightctl-client\"\n    clientSecret: \"your-client-secret\"\n</code></pre>"},{"location":"user/security-guidelines/#aap-ansible-automation-platform-authentication","title":"AAP (Ansible Automation Platform) Authentication","text":"<ul> <li>Type: <code>aap</code></li> <li>Description: Integration with Ansible Automation Platform</li> </ul> <pre><code>auth:\n  type: aap\n  aap:\n    serverURL: \"https://your-aap-server.com\"\n    username: \"your-username\"\n    password: \"your-password\"\n</code></pre>"},{"location":"user/security-guidelines/#device-authentication","title":"Device Authentication","text":"<p>Devices authenticate using X.509 client certificates:</p>"},{"location":"user/security-guidelines/#enrollment-process","title":"Enrollment Process","text":"<ol> <li>Hardware Identity: Device generates cryptographic key pair using TPM</li> <li>Certificate Signing Request: Device submits CSR with hardware fingerprint</li> <li>Manual Approval: Administrator approves enrollment request</li> <li>Certificate Issuance: Service issues device-specific management certificate</li> <li>Secure Communication: Device uses management certificate for all subsequent communications</li> </ol>"},{"location":"user/security-guidelines/#certificate-management","title":"Certificate Management","text":"<ul> <li>Enrollment Certificates: Used only for initial enrollment (configurable validity)</li> <li>Management Certificates: Device-specific certificates for ongoing operations</li> <li>Hardware Protection: Private keys are protected by TPM when available</li> <li>Automatic Rotation: Certificates are currently NOT rotated</li> </ul>"},{"location":"user/security-guidelines/#authorization","title":"Authorization","text":""},{"location":"user/security-guidelines/#user-permissions","title":"User Permissions","text":"<p>Flight Control implements role-based access control:</p> <ul> <li>Device Management: Create, read, update, delete devices</li> <li>Fleet Management: Manage fleets and templates</li> <li>Enrollment Approval: Approve or deny device enrollment requests</li> <li>System Administration: Access to system configuration and monitoring</li> </ul>"},{"location":"user/security-guidelines/#device-permissions","title":"Device Permissions","text":"<ul> <li>Self-Management: Devices can only modify their own configuration</li> <li>Status Reporting: Devices can report their status and health</li> <li>Template Application: Devices can apply approved configuration templates</li> </ul>"},{"location":"user/security-guidelines/#data-protection","title":"Data Protection","text":""},{"location":"user/security-guidelines/#data-in-transit","title":"Data in Transit","text":"<p>All communications are encrypted using TLS 1.3:</p>"},{"location":"user/security-guidelines/#api-communications","title":"API Communications","text":"<ul> <li>User API: HTTPS with TLS 1.3, minimum version enforced</li> <li>Agent API: Mutual TLS with client certificate verification</li> <li>Database Connections: TLS encryption for PostgreSQL connections</li> <li>Redis Communications: TLS encryption for key-value store</li> </ul>"},{"location":"user/security-guidelines/#certificate-configuration","title":"Certificate Configuration","text":"<pre><code># Server certificate configuration\nservice:\n  srvCertFile: \"/path/to/server.crt\"\n  srvKeyFile: \"/path/to/server.key\"\n  altNames: [\"flightctl.example.com\", \"localhost\"]\n\n# Client certificate configuration\nauth:\n  clientCertificate: \"/path/to/client.crt\"\n  clientKey: \"/path/to/client.key\"\n</code></pre>"},{"location":"user/security-guidelines/#data-at-rest","title":"Data at Rest","text":""},{"location":"user/security-guidelines/#database-encryption","title":"Database Encryption","text":"<ul> <li>PostgreSQL: Supports full database encryption, but this is NOT enabled by default</li> <li>Connection Encryption: TLS for all database connections</li> <li>Credential Storage: Database credentials are stored in plain text or base64 encoding (NOT encrypted) - in Kubernetes Secrets when deployed on k8s, and in Podman secrets when deployed with quadlets</li> </ul>"},{"location":"user/security-guidelines/#file-system-security","title":"File System Security","text":"<ul> <li>Certificate Storage: Certificates stored with 0600 permissions</li> <li>Configuration Files: Configuration files stored with 0600 permissions</li> <li>Log Files: Log files stored with appropriate permissions</li> </ul>"},{"location":"user/security-guidelines/#data-privacy","title":"Data Privacy","text":""},{"location":"user/security-guidelines/#data-collection","title":"Data Collection","text":"<p>Flight Control collects the following data:</p> <ul> <li>Device Information: Hardware specifications, operating system details</li> <li>System Status: Health metrics, application status, resource usage</li> <li>Configuration: Applied configuration templates and settings</li> <li>Events: User actions, system events, security events</li> </ul>"},{"location":"user/security-guidelines/#data-retention","title":"Data Retention","text":"<ul> <li>Event Logs: Configurable retention period (default: 7 days)</li> <li>Device Status: Retained for device lifecycle</li> </ul>"},{"location":"user/security-guidelines/#data-access-controls","title":"Data Access Controls","text":"<ul> <li>Organization Isolation: Data is isolated by organization</li> <li>Role-Based Access: Users can only access authorized data</li> </ul>"},{"location":"user/security-guidelines/#network-security","title":"Network Security","text":"<p>Flight Control requires specific network ports and firewall configuration. For detailed network requirements, see Network Requirements.</p>"},{"location":"user/security-guidelines/#service-endpoints","title":"Service Endpoints","text":"<ul> <li>User API: Port 3443 (HTTPS)</li> <li>Agent API: Port 7443 (mTLS)</li> <li>Database: Port 5432 (TLS)</li> <li>Redis: Port 6379 (TLS)</li> <li>Monitoring: Port 15690 (Prometheus metrics)</li> </ul>"},{"location":"user/security-guidelines/#network-security-features","title":"Network Security Features","text":""},{"location":"user/security-guidelines/#tls-configuration","title":"TLS Configuration","text":"<ul> <li>Minimum Version: TLS 1.3</li> <li>Cipher Suites: Strong cipher suites only</li> <li>Certificate Verification: Strict certificate validation</li> <li>SNI Support: Server Name Indication for proper certificate selection</li> </ul>"},{"location":"user/security-guidelines/#network-isolation","title":"Network Isolation","text":"<ul> <li>Internal Services: Services communicate over internal network</li> <li>External Access: Limited external access to required endpoints only</li> </ul>"},{"location":"user/security-guidelines/#device-security","title":"Device Security","text":""},{"location":"user/security-guidelines/#device-security-features","title":"Device Security Features","text":""},{"location":"user/security-guidelines/#hardware-security","title":"Hardware Security","text":"<ul> <li>TPM Integration: Hardware root-of-trust using TPM 2.0</li> <li>Secure Boot: Compatible with secure boot implementations</li> <li>Hardware Binding: Device identity bound to specific hardware</li> <li>SELinux Support: Agent supports SELinux for mandatory access control</li> <li>FIPS Compliance: Agent is FIPS 140-2 compliant for cryptographic operations</li> </ul>"},{"location":"user/security-guidelines/#device-authentication_1","title":"Device Authentication","text":"<p>Devices authenticate using X.509 client certificates:</p>"},{"location":"user/security-guidelines/#enrollment-process_1","title":"Enrollment Process","text":"<ol> <li>Hardware Identity: Device generates cryptographic key pair using TPM</li> <li>Certificate Signing Request: Device submits CSR with hardware fingerprint</li> <li>Manual Approval: Administrator approves enrollment request</li> <li>Certificate Issuance: Service issues device-specific management certificate</li> <li>Secure Communication: Device uses management certificate for all subsequent communications</li> </ol>"},{"location":"user/security-guidelines/#certificate-management_1","title":"Certificate Management","text":"<ul> <li>Enrollment Certificates: Used only for initial enrollment (configurable validity)</li> <li>Management Certificates: Device-specific certificates for ongoing operations</li> <li>Hardware Protection: Private keys are protected by TPM when available</li> <li>Automatic Rotation: Certificates are currently NOT rotated</li> </ul>"},{"location":"user/security-guidelines/#authorization_1","title":"Authorization","text":""},{"location":"user/security-guidelines/#user-permissions_1","title":"User Permissions","text":"<p>Flight Control implements role-based access control:</p> <ul> <li>Device Management: Create, read, update, delete devices</li> <li>Fleet Management: Manage fleets and templates</li> <li>Enrollment Approval: Approve or deny device enrollment requests</li> <li>System Administration: Access to system configuration and monitoring</li> </ul>"},{"location":"user/security-guidelines/#device-permissions_1","title":"Device Permissions","text":"<ul> <li>Self-Management: Devices can only modify their own configuration</li> <li>Status Reporting: Devices can report their status and health</li> <li>Template Application: Devices can apply approved configuration templates</li> </ul>"},{"location":"user/security-guidelines/#database-security","title":"Database Security","text":""},{"location":"user/security-guidelines/#database-access-control","title":"Database Access Control","text":"<p>Flight Control implements a three-user database model for security. For detailed database configuration and migration information, see Database Migration.</p>"},{"location":"user/security-guidelines/#user-roles","title":"User Roles","text":"<ol> <li>Admin User: Full database administration privileges</li> <li>Migration User: Schema changes and migrations only</li> <li>Application User: Runtime data operations only</li> </ol>"},{"location":"user/security-guidelines/#database-security-features","title":"Database Security Features","text":""},{"location":"user/security-guidelines/#connection-security","title":"Connection Security","text":"<ul> <li>TLS Encryption: All database connections use TLS</li> <li>Certificate Authentication: Optional client certificate authentication</li> <li>Connection Pooling: Secure connection pooling with proper cleanup</li> </ul>"},{"location":"user/security-guidelines/#logging-and-auditing","title":"Logging and Auditing","text":""},{"location":"user/security-guidelines/#logging","title":"Logging","text":"<p>Flight Control provides structured logging for operational monitoring:</p>"},{"location":"user/security-guidelines/#logged-events","title":"Logged Events","text":"<ul> <li>Service Events: Service startup, shutdown, configuration changes</li> <li>Device Events: Enrollment, configuration changes, decommissioning</li> <li>Error Events: Application errors and failures</li> <li>Performance Events: System performance metrics</li> </ul>"},{"location":"user/security-guidelines/#log-format","title":"Log Format","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"level\": \"info\",\n  \"component\": \"service\",\n  \"message\": \"Service started successfully\"\n}\n</code></pre>"},{"location":"user/security-guidelines/#log-security","title":"Log Security","text":""},{"location":"user/security-guidelines/#log-protection","title":"Log Protection","text":"<ul> <li>File Permissions: Log files stored with appropriate permissions</li> <li>Log Rotation: Handled by deployment platform (Kubernetes or systemd/journald)</li> </ul>"},{"location":"user/security-guidelines/#data-privacy_1","title":"Data Privacy","text":""},{"location":"user/security-guidelines/#personal-data-handling","title":"Personal Data Handling","text":""},{"location":"user/security-guidelines/#data-minimization","title":"Data Minimization","text":"<ul> <li>Required Data Only: Collect only necessary data</li> <li>Data Retention: Limited data retention periods</li> <li>Data Deletion: Automatic deletion of expired data</li> </ul>"},{"location":"user/security-guidelines/#privacy-protection","title":"Privacy Protection","text":"<ul> <li>Access Controls: Strict access controls on personal data</li> </ul>"},{"location":"user/security-guidelines/#insecure-settings-and-default-configurations","title":"Insecure Settings and Default Configurations","text":""},{"location":"user/security-guidelines/#default-security-settings","title":"Default Security Settings","text":""},{"location":"user/security-guidelines/#insecure-defaults","title":"Insecure Defaults","text":"<p>Flight Control has several insecure default settings that must be changed in production:</p> <pre><code># INSECURE DEFAULTS - CHANGE IN PRODUCTION\ndatabase:\n  password: \"adminpass\"  # Change to strong password\n  migrationPassword: \"adminpass\"  # Change to strong password\n\nkv:\n  password: \"adminpass\"  # Change to strong password\n\nservice:\n  # Self-signed certificates by default\n  srvCertFile: \"\"  # Use proper certificates in production\n  srvKeyFile: \"\"   # Use proper certificates in production\n</code></pre>"},{"location":"user/security-guidelines/#required-security-changes","title":"Required Security Changes","text":"<ol> <li>Database Passwords: Change all default database passwords</li> <li>Redis Password: Change default Redis password</li> <li>TLS Certificates: Replace self-signed certificates with proper certificates</li> <li>Authentication: Configure proper authentication provider</li> <li>Network Access: Restrict network access to required ports only</li> <li>Configure Firewall: Restrict network access</li> <li>Enable Logging: Configure logging</li> </ol>"},{"location":"user/security-guidelines/#development-vs-production","title":"Development vs Production","text":""},{"location":"user/security-guidelines/#development-settings","title":"Development Settings","text":"<pre><code># Development settings (INSECURE)\nauth:\n  insecureSkipTlsVerify: true  # Skip TLS verification\n\nservice:\n  # Self-signed certificates\n  srvCertFile: \"\"\n  srvKeyFile: \"\"\n</code></pre>"},{"location":"user/security-guidelines/#production-settings","title":"Production Settings","text":"<pre><code># Production settings (SECURE)\nauth:\n  insecureSkipTlsVerify: false  # Always verify TLS\n\nservice:\n  # Proper certificates\n  srvCertFile: \"/etc/flightctl/certs/server.crt\"\n  srvKeyFile: \"/etc/flightctl/certs/server.key\"\n</code></pre>"},{"location":"user/security-guidelines/#conclusion","title":"Conclusion","text":"<p>Flight Control provides a secure foundation for device management with comprehensive security features. However, proper configuration and ongoing security management are essential for maintaining security in production environments.</p>"},{"location":"user/security-guidelines/#key-security-recommendations","title":"Key Security Recommendations","text":"<ol> <li>Change Default Passwords: Immediately change all default passwords</li> <li>Use Proper Certificates: Replace self-signed certificates with proper certificates</li> <li>Configure Authentication: Set up proper authentication provider</li> <li>Regular Updates: Keep all components updated</li> <li>Security Training: Provide security training for staff</li> <li>Regular Audits: Conduct regular security audits</li> <li>Incident Response: Have incident response procedures</li> </ol>"},{"location":"user/service-observability/","title":"Service Observability","text":"<p>This guide explains how to enable and configure observability in a Flightctl deployment.</p> <p>Flightctl provides service-level observability to help operators:</p> <ul> <li>Trace inter-service and asynchronous workflows</li> <li>Debug errors and latency issues</li> <li>Monitor request flow and system behavior</li> </ul>"},{"location":"user/service-observability/#tracing","title":"Tracing","text":"<p>Flightctl supports distributed tracing via OpenTelemetry, providing comprehensive visibility into service interactions, database queries, and background task execution.</p>"},{"location":"user/service-observability/#enabling-tracing","title":"Enabling Tracing","text":"<p>Tracing is configured in your <code>config.yaml</code>:</p> <pre><code>tracing:\n  enabled: true\n  endpoint: localhost:4318  # optional\n  insecure: false           # optional\n</code></pre> <ul> <li><code>enabled</code> (required): Enables or disables tracing.</li> <li><code>endpoint</code> (optional): The OTLP HTTP endpoint for exporting traces. Defaults to <code>https://localhost:4318/v1/traces</code> if not specified.</li> <li><code>insecure</code> (optional): Set to true to allow HTTP (non-TLS) connections\u2014useful in development environments.</li> </ul> <p>[!NOTE] All OpenTelemetry-related configuration\u2014including endpoints, protocols, batching, and internal behavior\u2014can be defined or overridden using standard OpenTelemetry environment variables.</p>"},{"location":"user/service-observability/#viewing-traces-locally-with-jaeger-podman","title":"Viewing Traces Locally with Jaeger (Podman)","text":"<p>To inspect Flightctl traces visually, you can run a local Jaeger instance using Podman:</p> <pre><code># Jaeger UI: http://localhost:16686\n# OTLP HTTP receiver: http://localhost:4318\npodman run --rm --network host jaegertracing/all-in-one:latest\n</code></pre> <p>[!NOTE] You can use the default Flightctl tracing configuration with <code>insecure: true</code> to send traces to this Jaeger instance over HTTP.</p> <p>Once the container is running, open your browser and navigate to: http://localhost:16686</p> <p>This brings up the Jaeger web interface, where you can:</p> <ul> <li>Search for traces by service name</li> <li>View spans and their durations</li> <li>Inspect attributes, logs, and errors</li> <li>Analyze request flow and timing across services and queues</li> </ul>"},{"location":"user/standalone-observability/","title":"FlightCtl Standalone Observability Stack","text":"<p>This comprehensive guide covers the complete FlightCtl observability stack, including installation, configuration, management, and troubleshooting.</p>"},{"location":"user/standalone-observability/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Service Management \u26a0\ufe0f Required Reading</li> <li>Architecture</li> <li>Installation Scenarios</li> <li>Components</li> <li>Configuration</li> <li>Container Network Architecture</li> <li>Configuration Management</li> <li>Sample Configurations</li> </ol>"},{"location":"user/standalone-observability/#overview","title":"Overview","text":"<p>FlightCtl provides flexible observability solutions to meet different deployment scenarios. The system supports two main use cases:</p>"},{"location":"user/standalone-observability/#use-case-1-external-observability-stack-integration","title":"Use Case 1: External Observability Stack Integration","text":"<p>Scenario: You already have an existing observability stack (Prometheus, Grafana, Jaeger, etc.) and want to integrate FlightCtl telemetry into it.</p> <p>Solution: Deploy only the OpenTelemetry Collector as a bridge between FlightCtl and your external observability infrastructure.</p> <p>Benefits:</p> <ul> <li>Minimal resource footprint</li> <li>Integrates with existing monitoring workflows</li> <li>Centralized observability across multiple systems</li> <li>Flexible data routing and transformation</li> </ul>"},{"location":"user/standalone-observability/#use-case-2-standalone-observability-stack","title":"Use Case 2: Standalone Observability Stack","text":"<p>Scenario: You need a complete, self-contained observability solution for FlightCtl.</p> <p>Solution: Deploy the full observability stack including:</p> <ul> <li>Grafana for visualization and dashboards</li> <li>Prometheus for metrics collection and storage (internal only)</li> <li>OpenTelemetry Collector for telemetry data processing</li> <li>UserInfo Proxy for AAP OAuth integration (optional)</li> </ul> <p>Benefits:</p> <ul> <li>Complete out-of-the-box monitoring solution</li> <li>Pre-configured FlightCtl dashboards</li> <li>Integrated authentication with AAP</li> <li>No external dependencies</li> </ul> <p>All components run as Podman containers managed by systemd, providing enterprise-grade reliability and integration with existing infrastructure.</p> <p>Important: Both the standalone OpenTelemetry collector and the full observability stack can be installed and operated independently without requiring core FlightCtl services (flightctl-api, flightctl-worker, flightctl-db, flightctl-kv) to be running. This allows you to set up observability infrastructure before or alongside your main FlightCtl deployment.</p>"},{"location":"user/standalone-observability/#service-management","title":"Service Management","text":"<p>\ud83d\udd11 Service management uses native systemd targets:</p> <pre><code># For OpenTelemetry collector only (minimal setup)\nsudo systemctl start flightctl-otel-collector.target\nsudo systemctl stop flightctl-otel-collector.target\n\n# For full observability stack (includes collector + Grafana + Prometheus)\nsudo systemctl start flightctl-observability.target  \nsudo systemctl stop flightctl-observability.target\n\n# For automatic startup on boot\nsudo systemctl enable flightctl-observability.target\n</code></pre> <p>Configuration management is separate:</p> <pre><code># When you change /etc/flightctl/service-config.yaml\nsudo flightctl-render-observability      # Regenerate configs\nsudo systemctl restart flightctl-observability.target  # Apply changes\n</code></pre> <p>Systemd targets provide:</p> <ul> <li>\u2705 Proper dependency management and startup order</li> <li>\u2705 Network dependencies automatically handled  </li> <li>\u2705 Standard systemd enable/disable functionality</li> <li>\u2705 Integration with system boot process</li> <li>\u2705 Grouped start/stop: Stopping target stops all related services</li> </ul> <p>\u274c Do not use individual service commands:</p> <ul> <li><code>systemctl start flightctl-grafana.service</code> (use targets instead)</li> <li><code>systemctl start flightctl-prometheus.service</code> (use targets instead)</li> </ul> <p>Two-step process:</p> <ol> <li>Config changes: <code>sudo flightctl-render-observability</code> (renders templates)</li> <li>Service management: <code>sudo systemctl start/stop/restart flightctl-observability.target</code></li> </ol>"},{"location":"user/standalone-observability/#architecture","title":"Architecture","text":""},{"location":"user/standalone-observability/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    FlightCtl Observability Stack                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                 \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502   Grafana   \u2502    \u2502  Prometheus  \u2502    \u2502 OpenTelemetry       \u2502 \u2502\n\u2502  \u2502 Dashboard   \u2502\u25c4\u2500\u2500\u2500\u2524  Metrics     \u2502\u25c4\u2500\u2500\u2500\u2524 Collector           \u2502 \u2502\n\u2502  \u2502 (Port 3000) \u2502    \u2502  (Port 9090) \u2502    \u2502 (Internal)          \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502         \u2502                                                       \u2502\n\u2502         \u25bc                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                \u2502\n\u2502  \u2502 UserInfo    \u2502                                                \u2502\n\u2502  \u2502 Proxy       \u2502                                                \u2502\n\u2502  \u2502 (Internal)  \u2502                                                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                \u2502\n\u2502         \u2502                                                       \u2502\n\u2502         \u25bc                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                                                \u2502\n\u2502  \u2502 Identity    \u2502                                                \u2502\n\u2502  \u2502 Provider    \u2502                                                \u2502\n\u2502  \u2502 (External)  \u2502                                                \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user/standalone-observability/#container-network-architecture","title":"Container Network Architecture","text":"<p>All observability components communicate within the <code>flightctl-observability</code> Podman network:</p> <pre><code>flightctl-observability Network (Internal)\n\u251c\u2500\u2500 flightctl-grafana:3000\n\u251c\u2500\u2500 flightctl-prometheus:9090 (internal only)\n\u251c\u2500\u2500 flightctl-otel-collector:4317 (gRPC), 4318 (HTTP)\n\u2514\u2500\u2500 flightctl-userinfo-proxy:8080 (internal only)\n\nExternal Access (Published Ports)\n\u251c\u2500\u2500 &lt;host&gt;:3000 \u2192 flightctl-grafana:3000 (full stack only)\n\u251c\u2500\u2500 &lt;host&gt;:4317 \u2192 flightctl-otel-collector:4317 (gRPC)\n\u2514\u2500\u2500 &lt;host&gt;:4318 \u2192 flightctl-otel-collector:4318 (HTTP)\n</code></pre> <p>Key Design Principles:</p> <ul> <li>Internal Communication: Containers communicate via container names (e.g., <code>flightctl-prometheus:9090</code>)</li> <li>External Access: Only OpenTelemetry collector always exposes external ports; Grafana only in full stack mode</li> <li>Security: Prometheus and UserInfo proxy are internal-only for security</li> <li>Network Isolation: All components isolated within the flightctl-observability network</li> <li>Flexibility: OpenTelemetry collector can forward data to external systems or internal Prometheus</li> </ul> <p>Network Configuration:</p> <p>The observability services use a dedicated Podman network named <code>flightctl-observability</code> that is automatically created and managed by the system. This network:</p> <ul> <li>Provides isolation from other FlightCtl services</li> <li>Enables secure internal communication between observability components</li> <li>Allows containers to reference each other by name (e.g., <code>flightctl-prometheus:9090</code>)</li> <li>Is automatically created when the first observability service starts</li> <li>Is shared between all observability components whether you install standalone OpenTelemetry collector or the full stack</li> </ul>"},{"location":"user/standalone-observability/#installation-order","title":"Installation Order","text":"<p>With the removal of dependencies on core FlightCtl services, you now have full flexibility in installation order:</p>"},{"location":"user/standalone-observability/#option-1-observability-first","title":"Option 1: Observability First","text":"<ol> <li>Install observability services (<code>flightctl-otel-collector</code> or <code>flightctl-observability</code>)</li> <li>Configure and start observability services</li> <li>Later install and configure core FlightCtl services</li> <li>Core services will automatically send telemetry to existing observability infrastructure</li> </ol>"},{"location":"user/standalone-observability/#option-2-core-services-first","title":"Option 2: Core Services First","text":"<ol> <li>Install and configure core FlightCtl services</li> <li>Install observability services</li> <li>Observability services will automatically collect telemetry from running core services</li> </ol>"},{"location":"user/standalone-observability/#option-3-simultaneous-installation","title":"Option 3: Simultaneous Installation","text":"<ol> <li>Install both core services and observability services</li> <li>Configure and start all services in any order</li> </ol> <p>This flexibility allows you to set up monitoring infrastructure independently of your main FlightCtl deployment timeline.</p>"},{"location":"user/standalone-observability/#installation-scenarios","title":"Installation Scenarios","text":""},{"location":"user/standalone-observability/#scenario-1-external-observability-stack-integration","title":"Scenario 1: External Observability Stack Integration","text":"<p>When to Use: You already have an existing observability infrastructure (Prometheus, Grafana, Jaeger, etc.) and want to integrate FlightCtl telemetry into it.</p> <p>Components Included:</p> <ul> <li>OpenTelemetry collector only (external ports 4317, 4318)</li> </ul> <p>Prerequisites:</p> <ul> <li>Podman and systemd installed</li> <li>External observability stack configured to receive OTLP data</li> </ul> <p>Note: OpenTelemetry collector can be installed and run independently of core FlightCtl services</p> <p>Installation:</p> <pre><code># Install only the OpenTelemetry collector\nsudo dnf install flightctl-otel-collector\n\n# The package automatically:\n# 1. Checks prerequisites\n# 2. Generates collector configuration\n# 3. Configures systemd service (but does not start or enable it)\n\n# To start the collector service:\nsudo systemctl start flightctl-otel-collector.target\n\n# For automatic startup on boot:\nsudo systemctl enable flightctl-otel-collector.target\n\n**Note**: The installation process only configures the service but does not automatically start it. Use systemd targets to start the observability stack.\n</code></pre> <p>Configuration: Configure the collector to forward data to your external systems:</p> <pre><code># /etc/otelcol/otelcol-config.yaml\nexporters:\n  prometheus:\n    endpoint: \"your-prometheus.company.com:9090\"\n  jaeger:\n    endpoint: \"your-jaeger.company.com:14250\"\n</code></pre>"},{"location":"user/standalone-observability/#scenario-2-standalone-observability-stack","title":"Scenario 2: Standalone Observability Stack","text":"<p>When to Use: You need a complete, self-contained observability solution for FlightCtl without external dependencies.</p> <p>Components Included:</p> <ul> <li>Grafana dashboard (external port 3000)</li> <li>Prometheus metrics (internal only - accessed via Grafana)</li> <li>OpenTelemetry collector (external ports 4317, 4318)</li> <li>UserInfo proxy (internal only, optional for AAP integration)</li> </ul> <p>Prerequisites:</p> <ul> <li>Podman and systemd installed</li> </ul> <p>Note: Observability stack can be installed and run independently of core FlightCtl services</p> <p>Installation:</p> <pre><code># Install the full observability package\nsudo dnf install flightctl-observability\n\n# The package automatically:\n# 1. Checks prerequisites\n# 2. Generates initial configuration\n# 3. Configures systemd services (but does not start or enable them)\n\n# To start all observability services:\nsudo systemctl start flightctl-observability.target\n\n# For automatic startup on boot:\nsudo systemctl enable flightctl-observability.target\n\n**Note**: The installation process only configures the services but does not automatically start them. Use systemd targets to start the observability stack.\n</code></pre> <p>Access:</p> <ul> <li>Grafana dashboard: <code>http://&lt;host&gt;:3000</code> (default port, configurable)</li> <li>Prometheus metrics: Available through Grafana (internal only)</li> <li>OpenTelemetry collector: <code>&lt;host&gt;:4317</code> (gRPC), <code>&lt;host&gt;:4318</code> (HTTP)</li> </ul> <p>Access Methods:</p> <ul> <li>Local deployment: <code>http://localhost:3000</code></li> <li>Remote deployment: <code>http://server-ip:3000</code> or <code>http://server-hostname:3000</code></li> <li>Custom domain: <code>http://grafana.yourdomain.com:3000</code> (with proper DNS/proxy setup)</li> <li>Custom port: Configure <code>published_port</code> in service-config.yaml</li> </ul>"},{"location":"user/standalone-observability/#components","title":"Components","text":""},{"location":"user/standalone-observability/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Purpose: Web-based visualization and dashboards for metrics and logs.</p> <p>Key Features:</p> <ul> <li>Pre-configured FlightCtl dashboards</li> <li>OAuth integration with identity providers</li> <li>HTTPS support with custom certificates</li> <li>Automatic Prometheus data source configuration</li> </ul> <p>Configuration:</p> <ul> <li>Internal Address: <code>flightctl-grafana:3000</code></li> <li>External Access: <code>http://&lt;host&gt;:3000</code> (configurable port)</li> <li>Data Storage: <code>/var/lib/grafana</code></li> </ul> <p>Available Options in service-config.yaml:</p> <pre><code>observability:\n  grafana:\n    image: docker.io/grafana/grafana:latest\n    published_port: 3000\n    oauth:\n      enabled: false\n      client_id: your-oauth-client-id\n      auth_url: https://your-aap.com/o/authorize\n      token_url: https://your-aap.com/o/token\n      api_url: http://flightctl-userinfo-proxy:8080\n      tls_skip_verify: false\n      local_admin_user: admin\n      local_admin_password: secure-password\n    protocol: http  # or https\n    https:\n      cert_file: /etc/grafana/certs/grafana.crt\n      cert_key: /etc/grafana/certs/grafana.key\n</code></pre>"},{"location":"user/standalone-observability/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Purpose: Time-series database for metrics collection and storage.</p> <p>Key Features:</p> <ul> <li>Automatic FlightCtl service discovery</li> <li>Configurable retention policies</li> <li>Built-in query interface</li> <li>Integration with Grafana</li> </ul> <p>Configuration:</p> <ul> <li>Internal Address: <code>flightctl-prometheus:9090</code></li> <li>External Access: None (internal only - accessed via Grafana)</li> <li>Data Storage: <code>/var/lib/prometheus</code></li> </ul> <p>Available Options in service-config.yaml:</p> <pre><code>observability:\n  prometheus:\n    image: docker.io/prom/prometheus:latest\n    # No published_port - internal only\n</code></pre> <p>Note: Prometheus configuration is automatically generated to scrape FlightCtl services and the OpenTelemetry collector.</p>"},{"location":"user/standalone-observability/#opentelemetry-collector","title":"OpenTelemetry Collector","text":"<p>Purpose: Unified telemetry data collection, processing, and forwarding.</p> <p>Key Features:</p> <ul> <li>Multiple protocol support (OTLP, Jaeger, Zipkin)</li> <li>Data transformation and filtering</li> <li>Export to multiple backends</li> <li>Resource detection and enrichment</li> </ul> <p>Configuration:</p> <ul> <li>Internal Address: <code>flightctl-otel-collector:4317</code> (gRPC), <code>flightctl-otel-collector:4318</code> (HTTP)</li> <li>External Access: <code>&lt;host&gt;:4317</code> (gRPC), <code>&lt;host&gt;:4318</code> (HTTP) - configurable ports</li> <li>Data Storage: <code>/var/lib/otelcol</code></li> </ul> <p>Available Options in service-config.yaml:</p> <pre><code>observability:\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 4317  # External gRPC port\n    http_port: 4318  # External HTTP port\n</code></pre> <p>Note: OpenTelemetry collector configuration can be customized by editing <code>/etc/otelcol/otelcol-config.yaml</code> to configure receivers, processors, and exporters.</p>"},{"location":"user/standalone-observability/#userinfo-proxy","title":"UserInfo Proxy","text":"<p>Purpose: OAuth UserInfo endpoint proxy specifically designed for Ansible Automation Platform (AAP) integration with Grafana.</p> <p>Key Features:</p> <ul> <li>AAP-specific OAuth UserInfo endpoint translation</li> <li>Configurable TLS verification</li> <li>AAP user structure to OpenID Connect UserInfo transformation</li> <li>Grafana role mapping based on AAP permissions (is_superuser, is_platform_auditor)</li> </ul> <p>Configuration:</p> <ul> <li>Internal Address: <code>flightctl-userinfo-proxy:8080</code></li> <li>External Access: None (internal only)</li> </ul> <p>Available Options in service-config.yaml:</p> <pre><code>observability:\n  userinfo_proxy:\n    image: flightctl/userinfo-proxy:latest\n    upstream_url: https://your-aap-instance.com/api/gateway/v1/me/\n    skip_tls_verify: false  # Set to true for self-signed certificates\n</code></pre> <p>Note: UserInfo proxy is specifically designed for AAP (Ansible Automation Platform) integration and transforms AAP user API responses to OpenID Connect UserInfo format.</p>"},{"location":"user/standalone-observability/#configuration","title":"Configuration","text":"<p>All observability configuration is centralized in <code>/etc/flightctl/service-config.yaml</code> under the <code>observability</code> section.</p>"},{"location":"user/standalone-observability/#complete-configuration-reference","title":"Complete Configuration Reference","text":"<pre><code>observability:\n  # Grafana Configuration\n  grafana:\n    image: docker.io/grafana/grafana:latest\n    published_port: 3000  # External port - can be changed (e.g., 8080, 3001, etc.)\n\n    # OAuth Integration\n    oauth:\n      enabled: true\n      client_id: your-oauth-client-id\n      auth_url: https://your-idp.com/o/authorize\n      token_url: https://your-idp.com/o/token\n      api_url: http://flightctl-userinfo-proxy:8080  # Internal container communication\n      tls_skip_verify: false  # Skip TLS verification for OAuth endpoints\n      local_admin_user: admin\n      local_admin_password: secure-password\n\n    protocol: http  # or https\n\n    # HTTPS Configuration (Optional - only needed when protocol: https)\n    https:\n      cert_file: /etc/grafana/certs/grafana.crt\n      cert_key: /etc/grafana/certs/grafana.key\n\n  # Prometheus Configuration (internal only)\n  prometheus:\n    image: docker.io/prom/prometheus:latest\n\n  # OpenTelemetry Collector Configuration\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 4317  # External gRPC port - configurable\n    http_port: 4318  # External HTTP port - configurable\n\n  # UserInfo Proxy Configuration (Optional - AAP specific)\n  userinfo_proxy:\n    image: flightctl/userinfo-proxy:latest\n    upstream_url: https://your-aap-instance.com/api/gateway/v1/me/\n    skip_tls_verify: false  # Skip TLS verification for upstream calls\n</code></pre>"},{"location":"user/standalone-observability/#key-configuration-principles","title":"Key Configuration Principles","text":"<ol> <li>All configuration is in service-config.yaml: No need to edit individual container files or environment variables</li> <li>Automatic template generation: The system automatically generates container configurations from your service-config.yaml</li> <li>Hot configuration: Use <code>sudo flightctl-render-observability</code> then restart services with systemd targets</li> <li>Built-in validation: The system automatically validates your configuration and provides clear error messages</li> </ol>"},{"location":"user/standalone-observability/#configuration-management","title":"Configuration Management","text":""},{"location":"user/standalone-observability/#configuration-management-system","title":"Configuration Management System","text":"<p>FlightCtl separates configuration management from service management for better control.</p>"},{"location":"user/standalone-observability/#configuration-rendering","title":"Configuration Rendering","text":"<p>Render Configuration Templates:</p> <pre><code>sudo flightctl-render-observability\n</code></pre> <p>What it does:</p> <ol> <li>Validates prerequisites and configuration</li> <li>Automatically validates YAML syntax and configuration structure  </li> <li>Renders configuration templates from <code>/etc/flightctl/service-config.yaml</code></li> <li>Reloads systemd daemon</li> <li>Does NOT start or stop services</li> </ol>"},{"location":"user/standalone-observability/#service-management_1","title":"Service Management","text":"<p>Start/Stop Services:</p> <pre><code># Start services\nsudo systemctl start flightctl-observability.target       # Full stack\nsudo systemctl start flightctl-otel-collector.target      # OpenTelemetry only\n\n# Stop services  \nsudo systemctl stop flightctl-observability.target        # Full stack\nsudo systemctl stop flightctl-otel-collector.target       # OpenTelemetry only\n\n# Restart services (after config changes)\nsudo systemctl restart flightctl-observability.target     # Full stack\nsudo systemctl restart flightctl-otel-collector.target    # OpenTelemetry only\n\n# Enable automatic startup\nsudo systemctl enable flightctl-observability.target      # Full stack\nsudo systemctl enable flightctl-otel-collector.target     # OpenTelemetry only\n</code></pre> <p>These commands work whether you have the full observability stack, standalone OpenTelemetry collector, or any combination of components.</p>"},{"location":"user/standalone-observability/#configuration-workflow","title":"Configuration Workflow","text":"<ol> <li>Edit configuration:</li> </ol> <pre><code>sudo vim /etc/flightctl/service-config.yaml\n</code></pre> <ol> <li>Render updated configuration:</li> </ol> <pre><code>sudo flightctl-render-observability\n</code></pre> <ol> <li>Apply changes to running services:</li> </ol> <pre><code>sudo systemctl restart flightctl-observability.target\n</code></pre> <p>Stop services (when needed):</p> <pre><code>sudo systemctl stop flightctl-observability.target\n</code></pre> <p>Use this command when you need to stop all observability services for maintenance or troubleshooting.</p>"},{"location":"user/standalone-observability/#userinfo-proxy-setup-aap-integration","title":"UserInfo Proxy Setup (AAP Integration)","text":"<p>The UserInfo proxy enables Grafana OAuth integration specifically with Ansible Automation Platform (AAP) by translating AAP's user API responses to the standard OpenID Connect UserInfo format that Grafana expects.</p>"},{"location":"user/standalone-observability/#purpose-and-benefits","title":"Purpose and Benefits","text":"<p>Why Use UserInfo Proxy with AAP?</p> <ul> <li>AAP-Specific Translation: Converts AAP's user API responses to standard OAuth UserInfo format</li> <li>Permission Mapping: Maps AAP user permissions (is_superuser, is_platform_auditor) to Grafana roles</li> <li>TLS Management: Centralized TLS verification settings for AAP connections</li> <li>Grafana Integration: Optimized for Grafana's OAuth requirements with AAP</li> <li>Security: Internal-only service with no external exposure</li> </ul>"},{"location":"user/standalone-observability/#configuration_1","title":"Configuration","text":"<p>The UserInfo proxy runs as an internal service and requires minimal configuration:</p> <pre><code>observability:\n  grafana:\n    oauth:\n      enabled: true\n      client_id: your-oauth-client-id\n      auth_url: https://your-idp.com/o/authorize\n      token_url: https://your-idp.com/o/token\n      api_url: http://flightctl-userinfo-proxy:8080  # Points to internal proxy\n\n  userinfo_proxy:\n    upstream_url: https://your-aap-instance.com/api/gateway/v1/me/  # Your AAP instance's user API endpoint\n    skip_tls_verify: false  # Set to true for self-signed certificates\n</code></pre>"},{"location":"user/standalone-observability/#communication-flow","title":"Communication Flow","text":"<pre><code>User Authentication Flow with AAP:\n1. User \u2192 Grafana \u2192 AAP (OAuth login)\n2. Grafana receives OAuth token from AAP\n3. Grafana calls api_url \u2192 UserInfo Proxy (internal)\n4. UserInfo Proxy \u2192 AAP User API (with token)\n5. UserInfo Proxy transforms AAP response \u2192 Grafana\n6. Grafana creates user session with mapped roles\n</code></pre>"},{"location":"user/standalone-observability/#response-transformation","title":"Response Transformation","text":"<p>The proxy transforms AAP API responses to standard UserInfo format:</p> <p>Input (AAP API Response):</p> <pre><code>{\n  \"count\": 1,\n  \"results\": [{\n    \"id\": 123,\n    \"username\": \"john.doe\",\n    \"email\": \"john.doe@company.com\",\n    \"first_name\": \"John\",\n    \"last_name\": \"Doe\",\n    \"is_superuser\": true,\n    \"is_platform_auditor\": false\n  }]\n}\n</code></pre> <p>Output (UserInfo Standard):</p> <pre><code>{\n  \"sub\": \"123\",\n  \"preferred_username\": \"john.doe\",\n  \"email\": \"john.doe@company.com\",\n  \"email_verified\": true,\n  \"name\": \"John Doe\",\n  \"given_name\": \"John\",\n  \"family_name\": \"Doe\",\n  \"roles\": [\"Admin\"],\n  \"groups\": [\"admin\"],\n  \"updated_at\": 1640995200\n}\n</code></pre>"},{"location":"user/standalone-observability/#tls-configuration","title":"TLS Configuration","text":"<p>The proxy supports flexible TLS verification:</p> <pre><code>userinfo_proxy:\n  upstream_url: https://your-aap-instance.com/api/gateway/v1/me/\n  skip_tls_verify: false  # Default: strict TLS verification\n</code></pre> <p>When to use <code>skip_tls_verify: true</code>:</p> <ul> <li>Development environments</li> <li>Self-signed certificates</li> <li>Internal PKI that's not in system trust store</li> <li>Testing scenarios</li> </ul> <p>Production recommendation: Always use <code>skip_tls_verify: false</code> with proper certificates.</p>"},{"location":"user/standalone-observability/#sample-configurations","title":"Sample Configurations","text":""},{"location":"user/standalone-observability/#external-observability-integration","title":"External Observability Integration","text":"<p>Minimal configuration for integrating with existing observability stack:</p> <pre><code>observability:\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 4317\n    http_port: 4318\n</code></pre> <p>Note: Configure <code>/etc/otelcol/otelcol-config.yaml</code> to export to your external Prometheus, Jaeger, or other observability systems.</p> <p>Management Commands Available:</p> <p>Even when installing only the OpenTelemetry collector, you have access to the management commands:</p> <ul> <li><code>sudo flightctl-render-observability</code> - Render configuration templates from <code>service-config.yaml</code></li> <li><code>sudo systemctl start/stop/restart flightctl-observability.target</code> - Manage observability services</li> </ul> <p>Two-step process: First render configuration with <code>flightctl-render-observability</code>, then manage services with systemd targets. This separation provides better control and follows systemd best practices.</p>"},{"location":"user/standalone-observability/#standalone-stack-configuration-no-oauth","title":"Standalone Stack Configuration (No OAuth)","text":"<p>Complete standalone stack with local authentication only:</p> <pre><code>observability:\n  grafana:\n    image: docker.io/grafana/grafana:latest\n    published_port: 3000\n    oauth:\n      enabled: false\n      local_admin_user: admin\n      local_admin_password: secure-password\n\n  prometheus:\n    image: docker.io/prom/prometheus:latest\n\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 4317\n    http_port: 4318\n</code></pre>"},{"location":"user/standalone-observability/#oauth-integration-with-aap","title":"OAuth Integration with AAP","text":"<p>Complete OAuth setup with Ansible Automation Platform:</p> <pre><code>observability:\n  grafana:\n    image: docker.io/grafana/grafana:latest\n    published_port: 3000\n    oauth:\n      enabled: true\n      client_id: flightctl-grafana-client\n      auth_url: https://your-aap-instance.com/o/authorize\n      token_url: https://your-aap-instance.com/o/token\n      api_url: http://flightctl-userinfo-proxy:8080\n      tls_skip_verify: false\n      local_admin_user: admin\n      local_admin_password: fallback-password\n\n  prometheus:\n    image: docker.io/prom/prometheus:latest\n\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 4317\n    http_port: 4318\n\n  userinfo_proxy:\n    image: flightctl/userinfo-proxy:latest\n    upstream_url: https://your-aap-instance.com/api/gateway/v1/me/\n    skip_tls_verify: false\n</code></pre>"},{"location":"user/standalone-observability/#secure-grafana-with-custom-tls-certificates","title":"Secure Grafana with Custom TLS Certificates","text":"<p>Secure Grafana setup with custom TLS certificates:</p> <pre><code>observability:\n  grafana:\n    image: docker.io/grafana/grafana:latest\n    published_port: 3443\n    protocol: https\n    https:\n      cert_file: /etc/grafana/certs/grafana.crt\n      cert_key: /etc/grafana/certs/grafana.key\n    oauth:\n      enabled: true\n      client_id: flightctl-grafana-client\n      auth_url: https://your-aap-instance.com/o/authorize\n      token_url: https://your-aap-instance.com/o/token\n      api_url: http://flightctl-userinfo-proxy:8080\n      tls_skip_verify: false\n\n  prometheus:\n    image: docker.io/prom/prometheus:latest\n\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 4317\n    http_port: 4318\n\n  userinfo_proxy:\n    image: flightctl/userinfo-proxy:latest\n    upstream_url: https://your-aap-instance.com/api/gateway/v1/me/\n    skip_tls_verify: false\n</code></pre> <p>Certificate Setup:</p> <pre><code># Place certificates in the expected location\nsudo mkdir -p /etc/grafana/certs\nsudo cp your-grafana.crt /etc/grafana/certs/grafana.crt\nsudo cp your-grafana.key /etc/grafana/certs/grafana.key\nsudo chown 472:472 /etc/grafana/certs/grafana.*\nsudo chmod 600 /etc/grafana/certs/grafana.key\n</code></pre>"},{"location":"user/standalone-observability/#development-environment-with-self-signed-certificates","title":"Development Environment with Self-Signed Certificates","text":"<p>Development setup with relaxed TLS verification:</p> <pre><code>observability:\n  grafana:\n    image: docker.io/grafana/grafana:latest\n    published_port: 3000\n    oauth:\n      enabled: true\n      client_id: dev-grafana-client\n      auth_url: https://dev-auth.local/o/authorize\n      token_url: https://dev-auth.local/o/token\n      api_url: http://flightctl-userinfo-proxy:8080\n      tls_skip_verify: true  # OK for development\n      local_admin_user: admin\n      local_admin_password: dev-password\n\n  prometheus:\n    image: docker.io/prom/prometheus:latest\n\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n\n  userinfo_proxy:\n    image: flightctl/userinfo-proxy:latest\n    upstream_url: https://dev-aap-instance.local/api/gateway/v1/me/\n    skip_tls_verify: true  # OK for development with self-signed certs\n</code></pre>"},{"location":"user/standalone-observability/#external-integration-only","title":"External Integration Only","text":"<p>For integrating with existing observability infrastructure:</p> <pre><code>observability:\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 4317\n    http_port: 4318\n</code></pre> <p>Note: Customize <code>/etc/otelcol/otelcol-config.yaml</code> to export to your external Prometheus, Grafana, Jaeger, or other observability systems.</p>"},{"location":"user/standalone-observability/#custom-port-configuration","title":"Custom Port Configuration","text":"<p>Example with custom ports to avoid conflicts:</p> <pre><code>observability:\n  grafana:\n    image: docker.io/grafana/grafana:latest\n    published_port: 8080  # Use port 8080 instead of 3000\n    oauth:\n      enabled: false\n      local_admin_user: admin\n      local_admin_password: secure-password\n\n  prometheus:\n    image: docker.io/prom/prometheus:latest\n\n  otel_collector:\n    image: docker.io/otel/opentelemetry-collector-contrib:latest\n    grpc_port: 14317  # Use port 14317 instead of 4317\n    http_port: 14318  # Use port 14318 instead of 4318\n</code></pre> <p>Access with custom ports:</p> <ul> <li>Grafana: <code>http://&lt;host&gt;:8080</code></li> <li>OpenTelemetry collector: <code>&lt;host&gt;:14317</code> (gRPC), <code>&lt;host&gt;:14318</code> (HTTP)</li> </ul>"},{"location":"user/standalone-observability/#configuration-reference","title":"Configuration Reference","text":"<p>This section provides detailed documentation for every configuration variable available in the FlightCtl observability stack.</p>"},{"location":"user/standalone-observability/#grafana-configuration-variables","title":"Grafana Configuration Variables","text":""},{"location":"user/standalone-observability/#container-configuration","title":"Container Configuration","text":"<p><code>observability.grafana.image</code></p> <ul> <li>Type: String</li> <li>Default: <code>docker.io/grafana/grafana:latest</code></li> <li>Description: Container image for Grafana. Can specify a specific version tag for reproducible deployments.</li> <li>Example: <code>docker.io/grafana/grafana:10.2.0</code></li> </ul> <p><code>observability.grafana.published_port</code></p> <ul> <li>Type: Integer</li> <li>Default: <code>3000</code></li> <li>Description: External port where Grafana web interface will be accessible. Change this if port 3000 conflicts with other services.</li> <li>Example: <code>8080</code></li> </ul>"},{"location":"user/standalone-observability/#protocol-configuration","title":"Protocol Configuration","text":"<p><code>observability.grafana.protocol</code></p> <ul> <li>Type: String</li> <li>Default: <code>http</code></li> <li>Valid Values: <code>http</code>, <code>https</code></li> <li>Description: Protocol for Grafana web interface. Set to <code>https</code> to enable TLS encryption.</li> <li>Example: <code>https</code></li> </ul> <p><code>observability.grafana.https.cert_file</code></p> <ul> <li>Type: String</li> <li>Default: <code>/etc/grafana/certs/grafana.crt</code></li> <li>Description: Path to TLS certificate file. Only used when <code>protocol: https</code>. Certificate must be readable by Grafana container (UID 472).</li> <li>Required: When <code>protocol: https</code></li> <li>Example: <code>/etc/grafana/certs/my-grafana.crt</code></li> </ul> <p><code>observability.grafana.https.cert_key</code></p> <ul> <li>Type: String</li> <li>Default: <code>/etc/grafana/certs/grafana.key</code></li> <li>Description: Path to TLS private key file. Only used when <code>protocol: https</code>. Key must be readable by Grafana container (UID 472) and have restricted permissions (600).</li> <li>Required: When <code>protocol: https</code></li> <li>Example: <code>/etc/grafana/certs/my-grafana.key</code></li> </ul>"},{"location":"user/standalone-observability/#oauth-configuration","title":"OAuth Configuration","text":"<p><code>observability.grafana.oauth.enabled</code></p> <ul> <li>Type: Boolean</li> <li>Default: <code>false</code></li> <li>Description: Enable OAuth authentication. When enabled, users will authenticate through external identity provider instead of local Grafana accounts.</li> <li>Example: <code>true</code></li> </ul> <p><code>observability.grafana.oauth.client_id</code></p> <ul> <li>Type: String</li> <li>Default: Empty</li> <li>Description: OAuth client ID registered with your identity provider. Must match the client ID configured in your IdP.</li> <li>Required: When <code>oauth.enabled: true</code></li> <li>Example: <code>flightctl-grafana-client</code></li> </ul> <p><code>observability.grafana.oauth.auth_url</code></p> <ul> <li>Type: String (URL)</li> <li>Default: Empty</li> <li>Description: OAuth authorization endpoint URL. Users will be redirected here to authenticate.</li> <li>Required: When <code>oauth.enabled: true</code></li> <li>Example: <code>https://your-aap.com/o/authorize</code></li> </ul> <p><code>observability.grafana.oauth.token_url</code></p> <ul> <li>Type: String (URL)</li> <li>Default: Empty</li> <li>Description: OAuth token endpoint URL. Grafana exchanges authorization codes for access tokens here.</li> <li>Required: When <code>oauth.enabled: true</code></li> <li>Example: <code>https://your-aap.com/o/token</code></li> </ul> <p><code>observability.grafana.oauth.api_url</code></p> <ul> <li>Type: String (URL)</li> <li>Default: Empty</li> <li>Description: OAuth user info API endpoint. Grafana calls this to get user information. For AAP integration, use the UserInfo proxy: <code>http://flightctl-userinfo-proxy:8080</code></li> <li>Required: When <code>oauth.enabled: true</code></li> <li>Example: <code>http://flightctl-userinfo-proxy:8080</code></li> </ul> <p><code>observability.grafana.oauth.tls_skip_verify</code></p> <ul> <li>Type: Boolean</li> <li>Default: <code>false</code></li> <li>Description: Skip TLS certificate verification when connecting to OAuth endpoints. Only use <code>true</code> in development environments with self-signed certificates.</li> <li>Security: Always use <code>false</code> in production</li> <li>Example: <code>true</code> (development only)</li> </ul> <p><code>observability.grafana.oauth.local_admin_user</code></p> <ul> <li>Type: String</li> <li>Default: <code>admin</code></li> <li>Description: Username for local Grafana admin account. This account can be used as fallback when OAuth is unavailable.</li> <li>Example: <code>admin</code></li> </ul> <p><code>observability.grafana.oauth.local_admin_password</code></p> <ul> <li>Type: String</li> <li>Default: <code>defaultadmin</code></li> <li>Description: Password for local Grafana admin account. Change this from the default for security.</li> <li>Security: Use a strong password in production</li> <li>Example: <code>secure-admin-password-123</code></li> </ul>"},{"location":"user/standalone-observability/#prometheus-configuration-variables","title":"Prometheus Configuration Variables","text":"<p><code>observability.prometheus.image</code></p> <ul> <li>Type: String</li> <li>Default: <code>docker.io/prom/prometheus:latest</code></li> <li>Description: Container image for Prometheus. Prometheus runs as internal-only service with no external ports.</li> <li>Example: <code>docker.io/prom/prometheus:v2.45.0</code></li> </ul>"},{"location":"user/standalone-observability/#opentelemetry-collector-configuration-variables","title":"OpenTelemetry Collector Configuration Variables","text":"<p><code>observability.otel_collector.image</code></p> <ul> <li>Type: String</li> <li>Default: <code>docker.io/otel/opentelemetry-collector-contrib:latest</code></li> <li>Description: Container image for OpenTelemetry Collector. The contrib version includes additional receivers, processors, and exporters.</li> <li>Example: <code>docker.io/otel/opentelemetry-collector-contrib:0.88.0</code></li> </ul> <p><code>observability.otel_collector.grpc_port</code></p> <ul> <li>Type: Integer</li> <li>Default: <code>4317</code></li> <li>Description: External port for OpenTelemetry gRPC receiver. Agents send telemetry data to this port using OTLP/gRPC protocol.</li> <li>Example: <code>14317</code></li> </ul> <p><code>observability.otel_collector.http_port</code></p> <ul> <li>Type: Integer</li> <li>Default: <code>4318</code></li> <li>Description: External port for OpenTelemetry HTTP receiver. Agents send telemetry data to this port using OTLP/HTTP protocol.</li> <li>Example: <code>14318</code></li> </ul>"},{"location":"user/standalone-observability/#userinfo-proxy-configuration-variables","title":"UserInfo Proxy Configuration Variables","text":"<p><code>observability.userinfo_proxy.image</code></p> <ul> <li>Type: String</li> <li>Default: <code>flightctl/userinfo-proxy:latest</code></li> <li>Description: Container image for UserInfo proxy service. This service translates AAP user API responses to standard OAuth UserInfo format.</li> <li>Example: <code>flightctl/userinfo-proxy:v1.0.0</code></li> </ul> <p><code>observability.userinfo_proxy.upstream_url</code></p> <ul> <li>Type: String (URL)</li> <li>Default: Empty</li> <li>Description: URL of upstream identity provider's user API endpoint. For AAP integration, this should point to the AAP user API endpoint.</li> <li>Required: When using OAuth with AAP integration</li> <li>Example: <code>https://your-aap.com/api/gateway/v1/me/</code></li> </ul> <p><code>observability.userinfo_proxy.skip_tls_verify</code></p> <ul> <li>Type: Boolean</li> <li>Default: <code>false</code></li> <li>Description: Skip TLS certificate verification when connecting to upstream user API. Only use <code>true</code> in development environments with self-signed certificates.</li> <li>Security: Always use <code>false</code> in production</li> <li>Example: <code>true</code> (development only)</li> </ul>"},{"location":"user/standalone-observability/#configuration-validation-rules","title":"Configuration Validation Rules","text":""},{"location":"user/standalone-observability/#required-field-dependencies","title":"Required Field Dependencies","text":"<p>When certain features are enabled, additional fields become required:</p> <p>OAuth Authentication (<code>oauth.enabled: true</code>):</p> <ul> <li><code>oauth.client_id</code> - Must be configured in your IdP</li> <li><code>oauth.auth_url</code> - IdP authorization endpoint</li> <li><code>oauth.token_url</code> - IdP token endpoint  </li> <li><code>oauth.api_url</code> - User info endpoint (use UserInfo proxy for AAP)</li> </ul> <p>HTTPS Protocol (<code>protocol: https</code>):</p> <ul> <li><code>https.cert_file</code> - TLS certificate path</li> <li><code>https.cert_key</code> - TLS private key path</li> </ul> <p>AAP Integration (OAuth with UserInfo proxy):</p> <ul> <li><code>userinfo_proxy.upstream_url</code> - AAP user API endpoint</li> </ul>"},{"location":"user/standalone-observability/#default-behavior","title":"Default Behavior","text":"<ul> <li>All fields are optional unless explicitly marked as required</li> <li>System uses documented default values for unspecified fields</li> <li>Empty sections (e.g., <code>prometheus: {}</code>) use all defaults</li> <li>Services are only created if their configuration sections exist</li> </ul>"},{"location":"user/standalone-observability/#security-guidelines","title":"Security Guidelines","text":"<p>Production Recommendations:</p> <ul> <li>Change <code>local_admin_password</code> from default</li> <li>Use <code>tls_skip_verify: false</code> and <code>skip_tls_verify: false</code></li> <li>Use <code>protocol: https</code> with valid certificates</li> <li>Use specific image tags instead of <code>latest</code></li> <li>Use non-default ports if needed for security</li> </ul> <p>Development Allowances:</p> <ul> <li><code>tls_skip_verify: true</code> for self-signed certificates</li> <li><code>skip_tls_verify: true</code> for internal development IdPs</li> <li>Default passwords acceptable for local development</li> </ul>"},{"location":"user/troubleshooting/","title":"Troubleshooting","text":""},{"location":"user/troubleshooting/#verifying-the-effective-device-specification-received-by-the-device-agent","title":"Verifying the effective device specification received by the device agent","text":"<p>When viewing a device resource using the command</p> <pre><code>flightctl get device/${device_name} -o yaml\n</code></pre> <p>the output contains the device specification as specified by the user or the fleet controller based on the fleet's device template. That specification may contain references to configuration or secrets stored on external systems, such a Git or a Kubernetes cluster.</p> <p>Only when the device agent queries the service, the service replaces these references with the actual configuration and secret data. While this better protects potentially sensitive data, it also makes troubleshooting faulty configurations hard.</p> <p>Users with the <code>GetRenderedDevice</code> permission can run the following command to view the effective configuration as rendered by the service to the device agent:</p> <pre><code>flightctl get device/${device_name} -o yaml --rendered\n</code></pre>"},{"location":"user/troubleshooting/#generating-and-downloading-an-sos-report","title":"Generating and downloading an SOS report","text":"<p>SOS reports are a collection of system information that can be used to debug issues with the device agent. The SOS report is generated by the <code>sos report</code> command, which is included in the device image. To generate an SOS report, run the following console command on the device:</p> <pre><code>flightctl console device/${device_name} -- sos report --batch --quiet\n</code></pre> <p>The output is a tarball named <code>sosreport-$hostname-$timestamp-$random-sequence.tar.xz</code>, whereby <code>$hostname</code> is the device's hostname and <code>$timestamp</code> is the current date and time. The tarball contains system information, logs, and configuration files that can be used to debug issues with the device agent.</p> <p>Output example:</p> <pre><code>sos report (version 4.8.1)\n\n\nYour sos report has been generated and saved in:\n       /var/tmp/sosreport-localhost-2025-04-28-svjuich.tar.xz\n\n Size  11.83MiB\n Owner root\n sha256        918563a260c5d6a069e178e9ddce643b3b93ad2a4fdca9a3e431b63b2e82041d\n\nPlease send this file to your support representative.\n</code></pre> <p>To download the SOS report, run the following command on the device:</p> <pre><code>flightctl console device/${device_name} -- cat /var/tmp/sosreport-localhost-2025-04-28-svjuich.tar.xz &gt; sosreport.tar.xz \n</code></pre>"}]}